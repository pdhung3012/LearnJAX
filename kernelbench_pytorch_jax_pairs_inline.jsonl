{"kb_id": "kb_level_1_0000", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 68.07610993657505, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0000.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0000_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that computes Hinge Loss for binary classification tasks.\n\n    Parameters:\n        None\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n\n    def forward(self, predictions, targets):\n        return torch.mean(torch.clamp(1 - predictions * targets, min=0))\n\nbatch_size = 32768\ninput_shape = (32768,)\ndim = 1\n\ndef get_inputs():\n    return [torch.rand(batch_size, *input_shape), torch.randint(0, 2, (batch_size,)).float() * 2 - 1]\n\ndef get_init_inputs():\n    return []", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    A model that computes Hinge Loss for binary classification tasks.\n\n    Parameters:\n        None\n    \"\"\"\n    def __init__(self):\n        pass\n\n    def __call__(self, predictions, targets):\n        return jnp.mean(jnp.clip(1 - predictions * targets, a_min=0))\n\nbatch_size = 32768\ninput_shape = (32768,)\ndim = 1\n\ndef get_inputs():\n    predictions = jax.random.uniform(jax.random.PRNGKey(0), (batch_size, *input_shape))\n    targets = jax.random.randint(jax.random.PRNGKey(1), (batch_size,), 0, 2).astype(jnp.float32) * 2 - 1\n    return [predictions, targets]\n\ndef get_init_inputs():\n    return []"}
{"kb_id": "kb_level_1_0001", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0001.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0001_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs 3D tensor-matrix multiplication.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A, B):\n        \"\"\"\n        Performs 3D tensor-matrix multiplication.\n\n        Args:\n            A (torch.Tensor): Input 3D tensor of shape (N, M, K).\n            B (torch.Tensor): Input matrix of shape (K, L).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (N, M, L), resulting from the multiplication of A and B along the last dimension of A.\n        \"\"\"\n        return torch.matmul(A, B)\n\nN = 16\nM = 1024\nK = 2048\nL = 768\n\ndef get_inputs():\n    A = torch.rand(N, M, K)\n    B = torch.rand(K, L)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    Performs 3D tensor-matrix multiplication.\n    \"\"\"\n    def __init__(self):\n        pass\n\n    def __call__(self, A, B):\n        \"\"\"\n        Performs 3D tensor-matrix multiplication.\n\n        Args:\n            A (jnp.ndarray): Input 3D tensor of shape (N, M, K).\n            B (jnp.ndarray): Input matrix of shape (K, L).\n\n        Returns:\n            jnp.ndarray: Output tensor of shape (N, M, L), resulting from the multiplication of A and B along the last dimension of A.\n        \"\"\"\n        return jnp.matmul(A, B)\n\nN = 16\nM = 1024\nK = 2048\nL = 768\n\ndef get_inputs():\n    key1, key2 = jax.random.split(jax.random.PRNGKey(0))\n    A = jax.random.uniform(key1, (N, M, K))\n    B = jax.random.uniform(key2, (K, L))\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}
{"kb_id": "kb_level_1_0002", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0002.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0002_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs 4D tensor-matrix multiplication: \n        C[b, i, j, k] = sum_l A[b, i, j, l] * B[l, k]\n\n    Args:\n        A (torch.Tensor): Input 4D tensor of shape (b, i, j, l)\n        B (torch.Tensor): Input matrix of shape (l, k)\n\n    Returns:\n        torch.Tensor: Output 4D tensor of shape (b, i, j, k)\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n\n    def forward(self, A, B):\n        \"\"\"\n        Performs the 4D tensor-matrix multiplication.\n\n        Args:\n            A (torch.Tensor): Input 4D tensor of shape (b, i, j, l)\n            B (torch.Tensor): Input matrix of shape (l, k)\n\n        Returns:\n            torch.Tensor: Output 4D tensor of shape (b, i, j, k)\n        \"\"\"\n        return torch.einsum(\"bijl,lk->bijk\", A, B)\n\n# Test code\nb = 8\ni = 256\nj = 512\nl = 256\nk = 768\n\ndef get_inputs():\n    A = torch.rand(b, i, j, l)\n    B = torch.rand(l, k)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    Performs 4D tensor-matrix multiplication: \n        C[b, i, j, k] = sum_l A[b, i, j, l] * B[l, k]\n\n    Args:\n        A (jnp.ndarray): Input 4D tensor of shape (b, i, j, l)\n        B (jnp.ndarray): Input matrix of shape (l, k)\n\n    Returns:\n        jnp.ndarray: Output 4D tensor of shape (b, i, j, k)\n    \"\"\"\n    def __init__(self):\n        pass\n\n    def __call__(self, A, B):\n        \"\"\"\n        Performs the 4D tensor-matrix multiplication.\n\n        Args:\n            A (jnp.ndarray): Input 4D tensor of shape (b, i, j, l)\n            B (jnp.ndarray): Input matrix of shape (l, k)\n\n        Returns:\n            jnp.ndarray: Output 4D tensor of shape (b, i, j, k)\n        \"\"\"\n        return jnp.einsum(\"bijl,lk->bijk\", A, B)\n\n# Test code\nb = 8\ni = 256\nj = 512\nl = 256\nk = 768\n\ndef get_inputs():\n    key1, key2 = jax.random.split(jax.random.PRNGKey(0))\n    A = jax.random.uniform(key1, (b, i, j, l))\n    B = jax.random.uniform(key2, (l, k))\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}
{"kb_id": "kb_level_1_0003", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0003.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0003_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication of a diagonal matrix with another matrix.\n    C = diag(A) * B\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A, B):\n        \"\"\"\n        Performs the matrix multiplication.\n\n        Args:\n            A (torch.Tensor): A 1D tensor representing the diagonal of the diagonal matrix. Shape: (N,).\n            B (torch.Tensor): A 2D tensor representing the second matrix. Shape: (N, M).\n\n        Returns:\n            torch.Tensor: The result of the matrix multiplication. Shape: (N, M).\n        \"\"\"\n        return torch.diag(A) @ B\n\nM = 4096\nN = 4096\n\ndef get_inputs():\n    A = torch.rand(N)\n    B = torch.rand(N, M)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    Simple model that performs a matrix multiplication of a diagonal matrix with another matrix.\n    C = diag(A) * B\n    \"\"\"\n    def __init__(self):\n        pass\n\n    def __call__(self, A, B):\n        \"\"\"\n        Performs the matrix multiplication.\n\n        Args:\n            A (jnp.ndarray): A 1D array representing the diagonal of the diagonal matrix. Shape: (N,).\n            B (jnp.ndarray): A 2D array representing the second matrix. Shape: (N, M).\n\n        Returns:\n            jnp.ndarray: The result of the matrix multiplication. Shape: (N, M).\n        \"\"\"\n        # torch.diag(A) @ B is equivalent to (A[:, None] * B)\n        return A[:, None] * B\n\nM = 4096\nN = 4096\n\ndef get_inputs():\n    A = jax.random.uniform(jax.random.PRNGKey(0), (N,))\n    B = jax.random.uniform(jax.random.PRNGKey(1), (N, M))\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}
{"kb_id": "kb_level_1_0004", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0004.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0004_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B) with A and B being symmetric matrices.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A, B):\n        \"\"\"\n        Performs matrix multiplication of two symmetric matrices.\n\n        Args:\n            A (torch.Tensor): Input matrix A, shape (N, N), symmetric.\n            B (torch.Tensor): Input matrix B, shape (N, N), symmetric.\n\n        Returns:\n            torch.Tensor: Output matrix C, shape (N, N).\n        \"\"\"\n        return torch.matmul(A, B)\n\nN = 4096\n\ndef get_inputs():\n    \"\"\"\n    Generates a pair of random symmetric matrices for testing.\n\n    Returns:\n        list: List containing two symmetric tensors A and B.\n    \"\"\"\n    A = torch.rand(N, N)\n    A = (A + A.T) / 2  # Ensure symmetry\n    B = torch.rand(N, N)\n    B = (B + B.T) / 2  # Ensure symmetry\n    return [A, B]\n\ndef get_init_inputs():\n    \"\"\"\n    No specific initialization inputs needed for this model.\n\n    Returns:\n        list: Empty list.\n    \"\"\"\n    return []", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B) with A and B being symmetric matrices.\n    \"\"\"\n    def __init__(self):\n        pass\n\n    def __call__(self, A, B):\n        \"\"\"\n        Performs matrix multiplication of two symmetric matrices.\n\n        Args:\n            A (jnp.ndarray): Input matrix A, shape (N, N), symmetric.\n            B (jnp.ndarray): Input matrix B, shape (N, N), symmetric.\n\n        Returns:\n            jnp.ndarray: Output matrix C, shape (N, N).\n        \"\"\"\n        return jnp.matmul(A, B)\n\nN = 4096\n\ndef get_inputs():\n    \"\"\"\n    Generates a pair of random symmetric matrices for testing.\n\n    Returns:\n        list: List containing two symmetric arrays A and B.\n    \"\"\"\n    key1, key2 = jax.random.split(jax.random.PRNGKey(0))\n    A = jax.random.uniform(key1, (N, N))\n    A = (A + A.T) / 2  # Ensure symmetry\n    B = jax.random.uniform(key2, (N, N))\n    B = (B + B.T) / 2  # Ensure symmetry\n    return [A, B]\n\ndef get_init_inputs():\n    \"\"\"\n    No specific initialization inputs needed for this model.\n\n    Returns:\n        list: Empty list.\n    \"\"\"\n    return []"}
{"kb_id": "kb_level_1_0005", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0005.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0005_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs matrix multiplication (C = A * B) for upper triangular matrices.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A, B):\n        \"\"\"\n        Performs matrix multiplication for upper triangular matrices.\n\n        Args:\n            A (torch.Tensor): Upper triangular matrix of shape (N, N).\n            B (torch.Tensor): Upper triangular matrix of shape (N, N).\n\n        Returns:\n            torch.Tensor: The product of A and B, also an upper triangular matrix of shape (N, N).\n        \"\"\"\n        return torch.triu(torch.matmul(A, B))\n\nN = 4096\n\ndef get_inputs():\n    \"\"\"\n    Generates upper triangular matrices for testing.\n\n    Returns:\n        list: A list containing two upper triangular matrices of shape (N, N).\n    \"\"\"\n    A = torch.triu(torch.rand(N, N))\n    B = torch.triu(torch.rand(N, N))\n    return [A, B]\n\ndef get_init_inputs():\n    \"\"\"\n    No specific initialization inputs are needed for this model.\n\n    Returns:\n        list: An empty list.\n    \"\"\"\n    return []", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    Simple model that performs matrix multiplication (C = A * B) for upper triangular matrices.\n    \"\"\"\n    def __init__(self):\n        pass\n\n    def __call__(self, A, B):\n        \"\"\"\n        Performs matrix multiplication for upper triangular matrices.\n\n        Args:\n            A (jnp.ndarray): Upper triangular matrix of shape (N, N).\n            B (jnp.ndarray): Upper triangular matrix of shape (N, N).\n\n        Returns:\n            jnp.ndarray: The product of A and B, also an upper triangular matrix of shape (N, N).\n        \"\"\"\n        return jnp.triu(jnp.matmul(A, B))\n\nN = 4096\n\ndef get_inputs():\n    \"\"\"\n    Generates upper triangular matrices for testing.\n\n    Returns:\n        list: A list containing two upper triangular matrices of shape (N, N).\n    \"\"\"\n    key1, key2 = jax.random.split(jax.random.PRNGKey(0))\n    A = jnp.triu(jax.random.uniform(key1, (N, N)))\n    B = jnp.triu(jax.random.uniform(key2, (N, N)))\n    return [A, B]\n\ndef get_init_inputs():\n    \"\"\"\n    No specific initialization inputs are needed for this model.\n\n    Returns:\n        list: An empty list.\n    \"\"\"\n    return []"}
{"kb_id": "kb_level_1_0006", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0006.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0006_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication (C = A * B) where A and B are lower triangular matrices. \n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A, B):\n        \"\"\"\n        Performs matrix multiplication of lower triangular matrices A and B.\n\n        Args:\n            A (torch.Tensor): Lower triangular matrix of shape (N, N).\n            B (torch.Tensor): Lower triangular matrix of shape (N, N).\n\n        Returns:\n            torch.Tensor: The result of matrix multiplication C of shape (N, N).\n        \"\"\"\n        return torch.tril(torch.matmul(A, B))\n\nM = 4096\n\ndef get_inputs():\n    A = torch.rand(M, M)\n    B = torch.rand(M, M)\n    A = torch.tril(A)\n    B = torch.tril(B)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    Simple model that performs a matrix multiplication (C = A * B) where A and B are lower triangular matrices. \n    \"\"\"\n    def __init__(self):\n        pass\n\n    def __call__(self, A, B):\n        \"\"\"\n        Performs matrix multiplication of lower triangular matrices A and B.\n\n        Args:\n            A (jnp.ndarray): Lower triangular matrix of shape (N, N).\n            B (jnp.ndarray): Lower triangular matrix of shape (N, N).\n\n        Returns:\n            jnp.ndarray: The result of matrix multiplication C of shape (N, N).\n        \"\"\"\n        return jnp.tril(jnp.matmul(A, B))\n\nM = 4096\n\ndef get_inputs():\n    key1, key2 = jax.random.split(jax.random.PRNGKey(0))\n    A = jax.random.uniform(key1, (M, M))\n    B = jax.random.uniform(key2, (M, M))\n    A = jnp.tril(A)\n    B = jnp.tril(B)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}
{"kb_id": "kb_level_1_0007", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0007.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0007_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B)\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs matrix multiplication.\n\n        Args:\n            A: Input tensor of shape (M, K).\n            B: Input tensor of shape (K, N).\n\n        Returns:\n            Output tensor of shape (M, N).\n        \"\"\"\n        return torch.matmul(A.T, B)\n\nM = 1024 * 2\nK = 4096 * 2\nN = 2048 * 2\n\ndef get_inputs():\n    A = torch.rand(K, M)\n    B = torch.rand(K, N)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B)\n    \"\"\"\n    def __init__(self):\n        pass\n\n    def __call__(self, A: jnp.ndarray, B: jnp.ndarray) -> jnp.ndarray:\n        \"\"\"\n        Performs matrix multiplication.\n\n        Args:\n            A: Input array of shape (M, K).\n            B: Input array of shape (K, N).\n\n        Returns:\n            Output array of shape (M, N).\n        \"\"\"\n        return jnp.matmul(A.T, B)\n\nM = 1024 * 2\nK = 4096 * 2\nN = 2048 * 2\n\ndef get_inputs():\n    key1, key2 = jax.random.split(jax.random.PRNGKey(0))\n    A = jax.random.uniform(key1, (K, M))\n    B = jax.random.uniform(key2, (K, N))\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}
{"kb_id": "kb_level_1_0008", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0008.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0008_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B)\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs matrix multiplication.\n\n        Args:\n            A: Input tensor of shape (M, K).\n            B: Input tensor of shape (K, N).\n\n        Returns:\n            Output tensor of shape (M, N).\n        \"\"\"\n        return torch.matmul(A, B.T)\n\nM = 1024 * 2\nK = 4096 * 2\nN = 2048 * 2\n\ndef get_inputs():\n    A = torch.rand(M, K)\n    B = torch.rand(N, K)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B)\n    \"\"\"\n    def __init__(self):\n        pass\n\n    def __call__(self, A: jnp.ndarray, B: jnp.ndarray) -> jnp.ndarray:\n        \"\"\"\n        Performs matrix multiplication.\n\n        Args:\n            A: Input tensor of shape (M, K).\n            B: Input tensor of shape (N, K).\n\n        Returns:\n            Output tensor of shape (M, N).\n        \"\"\"\n        return jnp.matmul(A, B.T)\n\nM = 1024 * 2\nK = 4096 * 2\nN = 2048 * 2\n\ndef get_inputs():\n    A = jax.random.uniform(jax.random.PRNGKey(0), (M, K))\n    B = jax.random.uniform(jax.random.PRNGKey(1), (N, K))\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}
{"kb_id": "kb_level_1_0009", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0009.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0009_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B)\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs matrix multiplication.\n\n        Args:\n            A: Input tensor of shape (M, K).\n            B: Input tensor of shape (K, N).\n\n        Returns:\n            Output tensor of shape (M, N).\n        \"\"\"\n        return torch.matmul(A.T, B.T)\n\nM = 1024 * 2\nK = 4096 * 2\nN = 2048 * 2\n\ndef get_inputs():\n    A = torch.rand(K, M)\n    B = torch.rand(N, K)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B)\n    \"\"\"\n    def __init__(self):\n        pass\n\n    def __call__(self, A: jnp.ndarray, B: jnp.ndarray) -> jnp.ndarray:\n        \"\"\"\n        Performs matrix multiplication.\n\n        Args:\n            A: Input array of shape (M, K).\n            B: Input array of shape (K, N).\n\n        Returns:\n            Output array of shape (M, N).\n        \"\"\"\n        return jnp.matmul(A.T, B.T)\n\nM = 1024 * 2\nK = 4096 * 2\nN = 2048 * 2\n\ndef get_inputs():\n    A = jax.random.uniform(jax.random.PRNGKey(0), (K, M))\n    B = jax.random.uniform(jax.random.PRNGKey(1), (N, K))\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}
{"kb_id": "kb_level_1_0011", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0011.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0011_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a single square matrix multiplication (C = A * B)\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the matrix multiplication.\n\n        Args:\n            A (torch.Tensor): Input matrix A of shape (N, N).\n            B (torch.Tensor): Input matrix B of shape (N, N).\n\n        Returns:\n            torch.Tensor: Output matrix C of shape (N, N).\n        \"\"\"\n        return torch.matmul(A, B)\n\nN = 2048 * 2\n\ndef get_inputs():\n    A = torch.rand(N, N)\n    B = torch.rand(N, N)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    Simple model that performs a single square matrix multiplication (C = A * B)\n    \"\"\"\n    def __init__(self):\n        pass\n\n    def __call__(self, A: jnp.ndarray, B: jnp.ndarray) -> jnp.ndarray:\n        \"\"\"\n        Performs the matrix multiplication.\n\n        Args:\n            A (jnp.ndarray): Input matrix A of shape (N, N).\n            B (jnp.ndarray): Input matrix B of shape (N, N).\n\n        Returns:\n            jnp.ndarray: Output matrix C of shape (N, N).\n        \"\"\"\n        return jnp.matmul(A, B)\n\nN = 2048 * 2\n\ndef get_inputs():\n    key1, key2 = jax.random.split(jax.random.PRNGKey(0))\n    A = jax.random.uniform(key1, (N, N))\n    B = jax.random.uniform(key2, (N, N))\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}
{"kb_id": "kb_level_1_0013", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0013.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0013_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a Sigmoid activation.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Sigmoid activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of any shape.\n\n        Returns:\n            torch.Tensor: Output tensor with Sigmoid applied, same shape as input.\n        \"\"\"\n        return torch.sigmoid(x)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    Simple model that performs a Sigmoid activation.\n    \"\"\"\n    def __init__(self):\n        pass\n\n    def __call__(self, x):\n        \"\"\"\n        Applies Sigmoid activation to the input tensor.\n\n        Args:\n            x (jnp.ndarray): Input tensor of any shape.\n\n        Returns:\n            jnp.ndarray: Output tensor with Sigmoid applied, same shape as input.\n        \"\"\"\n        return jax.nn.sigmoid(x)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = jax.random.uniform(jax.random.PRNGKey(0), (batch_size, dim))\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}
{"kb_id": "kb_level_1_0015", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0015.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0015_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a Softmax activation.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Softmax activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, num_features).\n\n        Returns:\n            torch.Tensor: Output tensor with Softmax applied, same shape as input.\n        \"\"\"\n        return torch.softmax(x, dim=1)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    Simple model that performs a Softmax activation.\n    \"\"\"\n    def __init__(self):\n        pass\n\n    def __call__(self, x):\n        \"\"\"\n        Applies Softmax activation to the input tensor.\n\n        Args:\n            x (jnp.ndarray): Input tensor of shape (batch_size, num_features).\n\n        Returns:\n            jnp.ndarray: Output tensor with Softmax applied, same shape as input.\n        \"\"\"\n        return jax.nn.softmax(x, axis=1)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = jax.random.uniform(jax.random.PRNGKey(0), (batch_size, dim))\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}
{"kb_id": "kb_level_1_0016", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0016.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0016_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a LogSoftmax activation.\n    \"\"\"\n    def __init__(self, dim: int = 1):\n        super(Model, self).__init__()\n        self.dim = dim\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies LogSoftmax activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, dim).\n\n        Returns:\n            torch.Tensor: Output tensor with LogSoftmax applied, same shape as input.\n        \"\"\"\n        return torch.log_softmax(x, dim=self.dim)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    Simple model that performs a LogSoftmax activation.\n    \"\"\"\n    def __init__(self, dim: int = 1):\n        self.dim = dim\n\n    def __call__(self, x: jnp.ndarray) -> jnp.ndarray:\n        \"\"\"\n        Applies LogSoftmax activation to the input tensor.\n\n        Args:\n            x (jnp.ndarray): Input tensor of shape (batch_size, dim).\n\n        Returns:\n            jnp.ndarray: Output tensor with LogSoftmax applied, same shape as input.\n        \"\"\"\n        return jax.nn.log_softmax(x, axis=self.dim)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = jax.random.uniform(jax.random.PRNGKey(0), (batch_size, dim))\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}
{"kb_id": "kb_level_1_0018", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0018.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0018_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a GELU activation.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies GELU activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of any shape.\n\n        Returns:\n            torch.Tensor: Output tensor with GELU applied, same shape as input.\n        \"\"\"\n        return torch.nn.functional.gelu(x)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    Simple model that performs a GELU activation.\n    \"\"\"\n    def __init__(self):\n        pass\n\n    def __call__(self, x):\n        \"\"\"\n        Applies GELU activation to the input tensor.\n\n        Args:\n            x (jnp.ndarray): Input tensor of any shape.\n\n        Returns:\n            jnp.ndarray: Output tensor with GELU applied, same shape as input.\n        \"\"\"\n        return jax.nn.gelu(x)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = jax.random.uniform(jax.random.PRNGKey(0), (batch_size, dim))\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}
{"kb_id": "kb_level_1_0019", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.84815618221259, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0019.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0019_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a SELU activation.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies SELU activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of any shape.\n\n        Returns:\n            torch.Tensor: Output tensor with SELU applied, same shape as input.\n        \"\"\"\n        return torch.selu(x)\n    \nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    Simple model that performs a SELU activation.\n    \"\"\"\n    def __init__(self):\n        pass\n\n    def __call__(self, x):\n        \"\"\"\n        Applies SELU activation to the input tensor.\n\n        Args:\n            x (jnp.ndarray): Input tensor of any shape.\n\n        Returns:\n            jnp.ndarray: Output tensor with SELU applied, same shape as input.\n        \"\"\"\n        # SELU constants from the original paper\n        alpha = 1.6732632423543772\n        scale = 1.0507009873554805\n        return scale * jnp.where(x > 0, x, alpha * (jnp.exp(x) - 1))\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = jax.random.uniform(jax.random.PRNGKey(0), (batch_size, dim))\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}
{"kb_id": "kb_level_1_0022", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0022.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0022_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B)\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs matrix multiplication.\n\n        Args:\n            A: Input tensor of shape (M, K).\n            B: Input tensor of shape (K, N).\n\n        Returns:\n            Output tensor of shape (M, N).\n        \"\"\"\n        return torch.matmul(A, B)\n\nM = 1024 * 2\nK = 4096 * 2\nN = 2048 * 2\n\ndef get_inputs():\n    A = torch.rand(M, K)\n    B = torch.rand(K, N)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B)\n    \"\"\"\n    def __init__(self):\n        pass\n\n    def __call__(self, A: jnp.ndarray, B: jnp.ndarray) -> jnp.ndarray:\n        \"\"\"\n        Performs matrix multiplication.\n\n        Args:\n            A: Input tensor of shape (M, K).\n            B: Input tensor of shape (K, N).\n\n        Returns:\n            Output tensor of shape (M, N).\n        \"\"\"\n        return jnp.matmul(A, B)\n\nM = 1024 * 2\nK = 4096 * 2\nN = 2048 * 2\n\ndef get_inputs():\n    A = jax.random.uniform(jax.random.PRNGKey(0), (M, K))\n    B = jax.random.uniform(jax.random.PRNGKey(1), (K, N))\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}
{"kb_id": "kb_level_1_0023", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0023.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0023_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a Softsign activation.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Softsign activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of any shape.\n\n        Returns:\n            torch.Tensor: Output tensor with Softsign applied, same shape as input.\n        \"\"\"\n        return x / (1 + torch.abs(x))\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    Simple model that performs a Softsign activation.\n    \"\"\"\n    def __init__(self):\n        pass\n\n    def __call__(self, x):\n        \"\"\"\n        Applies Softsign activation to the input tensor.\n\n        Args:\n            x (jnp.ndarray): Input tensor of any shape.\n\n        Returns:\n            jnp.ndarray: Output tensor with Softsign applied, same shape as input.\n        \"\"\"\n        return x / (1 + jnp.abs(x))\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = jax.random.uniform(jax.random.PRNGKey(0), (batch_size, dim))\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}
{"kb_id": "kb_level_1_0025", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0025.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0025_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a HardTanh activation.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies HardTanh activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of any shape.\n\n        Returns:\n            torch.Tensor: Output tensor with HardTanh applied, same shape as input.\n        \"\"\"\n        return F.hardtanh(x, min_val=-1., max_val=1.)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    Simple model that performs a HardTanh activation.\n    \"\"\"\n    def __init__(self):\n        pass\n\n    def __call__(self, x):\n        \"\"\"\n        Applies HardTanh activation to the input tensor.\n\n        Args:\n            x (jnp.ndarray): Input tensor of any shape.\n\n        Returns:\n            jnp.ndarray: Output tensor with HardTanh applied, same shape as input.\n        \"\"\"\n        return jnp.clip(x, a_min=-1., a_max=1.)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = jax.random.uniform(jax.random.PRNGKey(0), (batch_size, dim))\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}
{"kb_id": "kb_level_1_0029", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 60.75471698113207, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0029.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0029_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs RMS Normalization.\n    \"\"\"\n    def __init__(self, num_features: int, eps: float = 1e-5):\n        \"\"\"\n        Initializes the RMSNorm layer.\n\n        Args:\n            num_features (int): Number of features in the input tensor.\n            eps (float, optional): A small value added to the denominator to avoid division by zero. Defaults to 1e-5.\n        \"\"\"\n        super(Model, self).__init__()\n        self.num_features = num_features\n        self.eps = eps\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies RMS Normalization to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, num_features, *).\n\n        Returns:\n            torch.Tensor: Output tensor with RMS Normalization applied, same shape as input.\n        \"\"\"\n        # Calculate the RMS along the feature dimension\n        rms = torch.sqrt(torch.mean(x ** 2, dim=1, keepdim=True) + self.eps)\n\n        # Normalize the input by dividing by the RMS\n        return x / rms\n\nbatch_size = 112\nfeatures = 64\ndim1 = 512\ndim2 = 512\n\ndef get_inputs():\n    x = torch.rand(batch_size, features, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [features]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs RMS Normalization.\n    \"\"\"\n    num_features: int\n    eps: float = 1e-5\n\n    @nn.compact\n    def __call__(self, x):\n        \"\"\"\n        Applies RMS Normalization to the input tensor.\n\n        Args:\n            x (jnp.ndarray): Input tensor of shape (batch_size, num_features, *).\n\n        Returns:\n            jnp.ndarray: Output tensor with RMS Normalization applied, same shape as input.\n        \"\"\"\n        # Calculate the RMS along the feature dimension\n        rms = jnp.sqrt(jnp.mean(x ** 2, axis=1, keepdims=True) + self.eps)\n        # Normalize the input by dividing by the RMS\n        return x / rms\n\nbatch_size = 112\nfeatures = 64\ndim1 = 512\ndim2 = 512\n\ndef get_inputs():\n    x = jax.random.uniform(jax.random.PRNGKey(0), (batch_size, features, dim1, dim2))\n    return [x]\n\ndef get_init_inputs():\n    return [features]"}
{"kb_id": "kb_level_1_0030", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0030.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0030_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs Frobenius norm normalization.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initializes the Frobenius norm normalization layer.\n        \"\"\"\n        super(Model, self).__init__()\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Frobenius norm normalization to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of arbitrary shape.\n\n        Returns:\n            torch.Tensor: Output tensor with Frobenius norm normalization applied, same shape as input.\n        \"\"\"\n        norm = torch.norm(x, p='fro')\n        return x / norm\n\nbatch_size = 112\nfeatures = 64\ndim1 = 512\ndim2 = 512\n\ndef get_inputs():\n    x = torch.rand(batch_size, features, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return []", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    Simple model that performs Frobenius norm normalization.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initializes the Frobenius norm normalization layer.\n        \"\"\"\n        pass\n\n    def __call__(self, x):\n        \"\"\"\n        Applies Frobenius norm normalization to the input tensor.\n\n        Args:\n            x (jnp.ndarray): Input tensor of arbitrary shape.\n\n        Returns:\n            jnp.ndarray: Output tensor with Frobenius norm normalization applied, same shape as input.\n        \"\"\"\n        norm = jnp.linalg.norm(x, ord='fro')\n        return x / norm\n\nbatch_size = 112\nfeatures = 64\ndim1 = 512\ndim2 = 512\n\ndef get_inputs():\n    x = jax.random.uniform(jax.random.PRNGKey(0), (batch_size, features, dim1, dim2))\n    return [x]\n\ndef get_init_inputs():\n    return []"}
{"kb_id": "kb_level_1_0031", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0031.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0031_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs L1 normalization.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initializes the L1 normalization layer.\n        \"\"\"\n        super(Model, self).__init__()\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies L1 normalization to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (..., dim, ...).\n\n        Returns:\n            torch.Tensor: Output tensor with L1 normalization applied, same shape as input.\n        \"\"\"\n        return x / torch.mean(torch.abs(x), dim=1, keepdim=True)\n\nbatch_size = 32768\n# choose dim so total <2^31\ndim = 65535\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    Simple model that performs L1 normalization.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initializes the L1 normalization layer.\n        \"\"\"\n        pass\n\n    def __call__(self, x):\n        \"\"\"\n        Applies L1 normalization to the input tensor.\n\n        Args:\n            x (jnp.ndarray): Input tensor of shape (..., dim, ...).\n\n        Returns:\n            jnp.ndarray: Output tensor with L1 normalization applied, same shape as input.\n        \"\"\"\n        return x / jnp.mean(jnp.abs(x), axis=1, keepdims=True)\n\nbatch_size = 32768\n# choose dim so total <2^31\ndim = 65535\n\ndef get_inputs():\n    x = jax.random.uniform(jax.random.PRNGKey(0), (batch_size, dim))\n    return [x]\n\ndef get_init_inputs():\n    return []"}
{"kb_id": "kb_level_1_0032", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0032.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0032_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs L2 normalization.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initializes the L2Norm layer.\n\n        Args:\n            dim (int): Dimension along which to normalize.\n        \"\"\"\n        super(Model, self).__init__()\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies L2 normalization to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (*, dim, *).\n\n        Returns:\n            torch.Tensor: Output tensor with L2 normalization applied, same shape as input.\n        \"\"\"\n        return x / torch.norm(x, p=2, dim=1, keepdim=True)\n\nbatch_size = 32768\n# choose dim so total <2^31\ndim = 65535\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    Simple model that performs L2 normalization.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initializes the L2Norm layer.\n        \"\"\"\n        pass\n\n    def __call__(self, x):\n        \"\"\"\n        Applies L2 normalization to the input tensor.\n\n        Args:\n            x (jnp.ndarray): Input tensor of shape (*, dim, *).\n\n        Returns:\n            jnp.ndarray: Output tensor with L2 normalization applied, same shape as input.\n        \"\"\"\n        norm = jnp.linalg.norm(x, ord=2, axis=1, keepdims=True)\n        return x / norm\n\nbatch_size = 32768\n# choose dim so total <2^31\ndim = 65535\n\ndef get_inputs():\n    x = jax.random.uniform(jax.random.PRNGKey(0), (batch_size, dim))\n    return [x]\n\ndef get_init_inputs():\n    return []"}
{"kb_id": "kb_level_1_0033", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0033.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0033_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs batched matrix multiplication (C = A * B) where A, B, and C have the same batch dimension.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs batched matrix multiplication.\n\n        Args:\n            A: Input tensor of shape (batch_size, m, k).\n            B: Input tensor of shape (batch_size, k, n).\n\n        Returns:\n            C: Output tensor of shape (batch_size, m, n).\n        \"\"\"\n        return torch.bmm(A, B)\n\nbatch_size = 128\nm = 128 * 4\nk = 256 * 4\nn = 512 * 4\n\ndef get_inputs():\n    A = torch.rand(batch_size, m, k)\n    B = torch.rand(batch_size, k, n)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    Performs batched matrix multiplication (C = A * B) where A, B, and C have the same batch dimension.\n    \"\"\"\n    def __init__(self):\n        pass\n\n    def __call__(self, A: jnp.ndarray, B: jnp.ndarray) -> jnp.ndarray:\n        \"\"\"\n        Performs batched matrix multiplication.\n\n        Args:\n            A: Input tensor of shape (batch_size, m, k).\n            B: Input tensor of shape (batch_size, k, n).\n\n        Returns:\n            C: Output tensor of shape (batch_size, m, n).\n        \"\"\"\n        return jnp.matmul(A, B)\n\nbatch_size = 128\nm = 128 * 4\nk = 256 * 4\nn = 512 * 4\n\ndef get_inputs():\n    key1, key2 = jax.random.split(jax.random.PRNGKey(0))\n    A = jax.random.uniform(key1, (batch_size, m, k))\n    B = jax.random.uniform(key2, (batch_size, k, n))\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}
{"kb_id": "kb_level_1_0035", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0035.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0035_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs Max Pooling 1D.\n    \"\"\"\n    def __init__(self, kernel_size: int, stride: int = None, padding: int = 0, dilation: int = 1, return_indices: bool = False):\n        \"\"\"\n        Initializes the Max Pooling 1D layer.\n\n        Args:\n            kernel_size (int): Size of the window to take a max over.\n            stride (int, optional): Stride of the window. Defaults to None (same as kernel_size).\n            padding (int, optional): Implicit zero padding to be added on both sides. Defaults to 0.\n            dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n            return_indices (bool, optional): Whether to return the indices of the maximum values. Defaults to False.\n        \"\"\"\n        super(Model, self).__init__()\n        self.maxpool = nn.MaxPool1d(kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, return_indices=return_indices)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Max Pooling 1D to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, num_features, sequence_length).\n\n        Returns:\n            torch.Tensor: Output tensor with Max Pooling 1D applied, shape (batch_size, num_features, output_sequence_length).\n        \"\"\"\n        return self.maxpool(x)\n\nbatch_size = 64\nfeatures = 192\nsequence_length = 65536\n\nkernel_size = 8\nstride      = 1\npadding     = 4\ndilation    = 3            \n\nreturn_indices = False\n\ndef get_inputs():\n    x = torch.rand(batch_size, features, sequence_length)\n    return [x]\n\ndef get_init_inputs():\n    return [kernel_size, stride, padding, dilation, return_indices]", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    Simple model that performs Max Pooling 1D.\n    \"\"\"\n    def __init__(self, kernel_size: int, stride: int = None, padding: int = 0, dilation: int = 1, return_indices: bool = False):\n        \"\"\"\n        Initializes the Max Pooling 1D layer.\n\n        Args:\n            kernel_size (int): Size of the window to take a max over.\n            stride (int, optional): Stride of the window. Defaults to None (same as kernel_size).\n            padding (int, optional): Implicit zero padding to be added on both sides. Defaults to 0.\n            dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n            return_indices (bool, optional): Whether to return the indices of the maximum values. Defaults to False.\n        \"\"\"\n        self.kernel_size = kernel_size\n        self.stride = stride if stride is not None else kernel_size\n        self.padding = padding\n        self.dilation = dilation\n        self.return_indices = return_indices\n\n    def __call__(self, x: jnp.ndarray) -> jnp.ndarray:\n        \"\"\"\n        Applies Max Pooling 1D to the input tensor.\n\n        Args:\n            x (jnp.ndarray): Input tensor of shape (batch_size, num_features, sequence_length).\n\n        Returns:\n            jnp.ndarray: Output tensor with Max Pooling 1D applied, shape (batch_size, num_features, output_sequence_length).\n        \"\"\"\n        return maxpool1d(\n            x,\n            kernel_size=self.kernel_size,\n            stride=self.stride,\n            padding=self.padding,\n            dilation=self.dilation,\n            return_indices=self.return_indices\n        )\n\ndef maxpool1d(x, kernel_size, stride, padding, dilation, return_indices=False):\n    \"\"\"\n    MaxPool1d for JAX, emulating PyTorch's behavior.\n    Args:\n        x: (batch, channels, length)\n        kernel_size: int\n        stride: int\n        padding: int\n        dilation: int\n        return_indices: bool\n    Returns:\n        (batch, channels, out_length)\n    \"\"\"\n    # x: (N, C, L)\n    N, C, L = x.shape\n    effective_kernel = dilation * (kernel_size - 1) + 1\n\n    # Pad both sides\n    if padding > 0:\n        x = jnp.pad(x, ((0,0), (0,0), (padding, padding)), mode='constant', constant_values=-jnp.inf)\n\n    L_padded = x.shape[2]\n    out_length = (L_padded - effective_kernel) // stride + 1\n\n    # Get all windowed indices\n    idxs = jnp.arange(out_length) * stride\n    window_idxs = jnp.arange(kernel_size) * dilation\n    idxs = idxs[:, None] + window_idxs[None, :]  # (out_length, kernel_size)\n    # idxs: (out_length, kernel_size)\n\n    # Gather windows\n    def gather_windows(x1d):\n        # x1d: (L_padded,)\n        return x1d[idxs]  # (out_length, kernel_size)\n\n    # vmap over batch and channel\n    x_windows = jax.vmap(\n        lambda x1: jax.vmap(gather_windows)(x1)\n    )(x)  # (N, C, out_length, kernel_size)\n\n    # Compute max and optionally indices\n    max_vals = jnp.max(x_windows, axis=-1)  # (N, C, out_length)\n    if return_indices:\n        max_idxs = jnp.argmax(x_windows, axis=-1)  # (N, C, out_length)\n        return max_vals, max_idxs\n    else:\n        return max_vals\n\nbatch_size = 64\nfeatures = 192\nsequence_length = 65536\n\nkernel_size = 8\nstride      = 1\npadding     = 4\ndilation    = 3            \n\nreturn_indices = False\n\ndef get_inputs():\n    x = jax.random.uniform(jax.random.PRNGKey(0), (batch_size, features, sequence_length))\n    return [x]\n\ndef get_init_inputs():\n    return [kernel_size, stride, padding, dilation, return_indices]"}
{"kb_id": "kb_level_1_0036", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0036.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0036_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs Max Pooling 2D.\n    \"\"\"\n    def __init__(self, kernel_size: int, stride: int, padding: int, dilation: int):\n        \"\"\"\n        Initializes the Max Pooling 2D layer.\n\n        Args:\n            kernel_size (int): Size of the pooling window.\n            stride (int): Stride of the pooling window.\n            padding (int): Padding to be applied before pooling.\n            dilation (int): Spacing between kernel elements.\n        \"\"\"\n        super(Model, self).__init__()\n        self.maxpool = nn.MaxPool2d(kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Max Pooling 2D to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor after Max Pooling 2D, shape (batch_size, channels, pooled_height, pooled_width).\n        \"\"\"\n        return self.maxpool(x)\n\nbatch_size = 32\nchannels = 64\nheight = 512\nwidth = 512\nkernel_size = 4\nstride = 1\npadding = 1\ndilation = 1\n\ndef get_inputs():\n    x = torch.rand(batch_size, channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [kernel_size, stride, padding, dilation]\n", "jax_code": "import jax\nimport jax.numpy as jnp\n\ndef max_pool2d(x, kernel_size, stride, padding, dilation):\n    \"\"\"\n    Applies 2D max pooling to the input tensor.\n\n    Args:\n        x: Input tensor of shape (batch_size, channels, height, width).\n        kernel_size: Size of the pooling window (int).\n        stride: Stride of the pooling window (int).\n        padding: Padding to be applied before pooling (int).\n        dilation: Spacing between kernel elements (int).\n\n    Returns:\n        Output tensor after Max Pooling 2D, shape (batch_size, channels, pooled_height, pooled_width).\n    \"\"\"\n    # JAX expects NHWC, so transpose from NCHW to NHWC\n    x_nhwc = jnp.transpose(x, (0, 2, 3, 1))\n    window_shape = (kernel_size, kernel_size)\n    window_dilation = (dilation, dilation)\n    strides = (stride, stride)\n    # Padding: convert int to ((before, after), (before, after))\n    if isinstance(padding, int):\n        pad_hw = ((padding, padding), (padding, padding))\n    else:\n        pad_hw = padding\n    # jax.lax.reduce_window expects padding as a list of (low, high) for each spatial dim\n    padding_config = [(pad_hw[0][0], pad_hw[0][1]), (pad_hw[1][0], pad_hw[1][1])]\n    # For batch and channel, no padding\n    full_padding = [(0, 0), *padding_config, (0, 0)]\n    out = jax.lax.reduce_window(\n        x_nhwc,\n        -jnp.inf,\n        jax.lax.max,\n        window_shape=(1, *window_shape, 1),\n        strides=(1, *strides, 1),\n        padding=full_padding,\n        window_dilation=(1, *window_dilation, 1),\n    )\n    # Transpose back to NCHW\n    out_nchw = jnp.transpose(out, (0, 3, 1, 2))\n    return out_nchw\n\nclass Model:\n    \"\"\"\n    Simple model that performs Max Pooling 2D.\n    \"\"\"\n    def __init__(self, kernel_size: int, stride: int, padding: int, dilation: int):\n        \"\"\"\n        Initializes the Max Pooling 2D layer.\n\n        Args:\n            kernel_size (int): Size of the pooling window.\n            stride (int): Stride of the pooling window.\n            padding (int): Padding to be applied before pooling.\n            dilation (int): Spacing between kernel elements.\n        \"\"\"\n        self.kernel_size = kernel_size\n        self.stride = stride\n        self.padding = padding\n        self.dilation = dilation\n\n    def __call__(self, x):\n        \"\"\"\n        Applies Max Pooling 2D to the input tensor.\n\n        Args:\n            x: Input tensor of shape (batch_size, channels, height, width).\n\n        Returns:\n            Output tensor after Max Pooling 2D, shape (batch_size, channels, pooled_height, pooled_width).\n        \"\"\"\n        return max_pool2d(\n            x,\n            kernel_size=self.kernel_size,\n            stride=self.stride,\n            padding=self.padding,\n            dilation=self.dilation,\n        )\n\nbatch_size = 32\nchannels = 64\nheight = 512\nwidth = 512\nkernel_size = 4\nstride = 1\npadding = 1\ndilation = 1\n\ndef get_inputs():\n    x = jax.random.uniform(jax.random.PRNGKey(0), (batch_size, channels, height, width))\n    return [x]\n\ndef get_init_inputs():\n    return [kernel_size, stride, padding, dilation]"}
{"kb_id": "kb_level_1_0037", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0037.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0037_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs Max Pooling 3D.\n    \"\"\"\n    def __init__(self, kernel_size: int, stride: int = None, padding: int = 0, dilation: int = 1, return_indices: bool = False, ceil_mode: bool = False):\n        \"\"\"\n        Initializes the Max Pooling 3D layer.\n\n        Args:\n            kernel_size (int): Size of the kernel for the max pooling operation.\n            stride (int, optional): Stride of the pooling operation. Defaults to None, which means stride is equal to kernel_size.\n            padding (int, optional): Padding applied to the input tensor. Defaults to 0.\n            dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n            return_indices (bool, optional): Whether to return indices of the maximum values. Defaults to False.\n            ceil_mode (bool, optional): When True, the output size is ceil(input_size / stride) instead of floor. Defaults to False.\n        \"\"\"\n        super(Model, self).__init__()\n        self.maxpool = nn.MaxPool3d(kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, return_indices=return_indices, ceil_mode=ceil_mode)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Max Pooling 3D to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, channels, dim1, dim2, dim3).\n\n        Returns:\n            torch.Tensor: Output tensor with Max Pooling 3D applied.\n        \"\"\"\n        return self.maxpool(x)\n\nbatch_size = 16\nchannels = 32\ndim1 = 128\ndim2 = 128\ndim3 = 128\nkernel_size = 3\nstride = 2\npadding = 1\ndilation = 3\n\ndef get_inputs():\n    x = torch.rand(batch_size, channels, dim1, dim2, dim3)\n    return [x]\n\ndef get_init_inputs():\n    return [kernel_size, stride, padding, dilation]", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    Simple model that performs Max Pooling 3D.\n    \"\"\"\n    def __init__(self, kernel_size: int, stride: int = None, padding: int = 0, dilation: int = 1, return_indices: bool = False, ceil_mode: bool = False):\n        \"\"\"\n        Initializes the Max Pooling 3D layer.\n\n        Args:\n            kernel_size (int): Size of the kernel for the max pooling operation.\n            stride (int, optional): Stride of the pooling operation. Defaults to None, which means stride is equal to kernel_size.\n            padding (int, optional): Padding applied to the input tensor. Defaults to 0.\n            dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n            return_indices (bool, optional): Whether to return indices of the maximum values. Defaults to False.\n            ceil_mode (bool, optional): When True, the output size is ceil(input_size / stride) instead of floor. Defaults to False.\n        \"\"\"\n        self.kernel_size = kernel_size\n        self.stride = stride if stride is not None else kernel_size\n        self.padding = padding\n        self.dilation = dilation\n        self.return_indices = return_indices\n        self.ceil_mode = ceil_mode\n\n    def forward(self, x: jnp.ndarray) -> jnp.ndarray:\n        \"\"\"\n        Applies Max Pooling 3D to the input tensor.\n\n        Args:\n            x (jnp.ndarray): Input tensor of shape (batch_size, channels, dim1, dim2, dim3).\n\n        Returns:\n            jnp.ndarray: Output tensor with Max Pooling 3D applied.\n        \"\"\"\n        # x: (N, C, D, H, W)\n        N, C, D, H, W = x.shape\n        k = self.kernel_size\n        s = self.stride\n        p = self.padding\n        d = self.dilation\n\n        # Calculate effective kernel size with dilation\n        eff_k = d * (k - 1) + 1\n\n        # Pad input\n        pad = [(0,0), (0,0)]\n        for dim in [D, H, W]:\n            pad.append((p, p))\n        x_padded = jnp.pad(x, pad, mode='constant', constant_values=-jnp.inf)\n\n        # Compute output shape\n        def get_out_size(in_size):\n            if self.ceil_mode:\n                return int(jnp.ceil((in_size + 2 * p - eff_k) / s)) + 1\n            else:\n                return int(jnp.floor((in_size + 2 * p - eff_k) / s)) + 1\n\n        out_D = get_out_size(D)\n        out_H = get_out_size(H)\n        out_W = get_out_size(W)\n\n        # Stride tricks for 3D pooling with dilation\n        # We want to extract sliding windows of shape (k, k, k) with stride s and dilation d\n        # We'll use jax.lax.reduce_window\n\n        window_shape = (1, 1, eff_k, eff_k, eff_k)\n        strides = (1, 1, s, s, s)\n        # jax.lax.reduce_window does not support dilation directly, so we need to use window_dilation\n        window_dimensions = (1, 1, k, k, k)\n        window_strides = (1, 1, s, s, s)\n        base_dilation = (1, 1, 1, 1, 1)\n        window_dilation = (1, 1, d, d, d)\n\n        out = jax.lax.reduce_window(\n            x_padded,\n            -jnp.inf,\n            jax.lax.max,\n            window_dimensions,\n            window_strides,\n            'VALID',\n            base_dilation=base_dilation,\n            window_dilation=window_dilation\n        )\n\n        # Crop to output shape in case of over-padding due to ceil_mode\n        out = out[:, :, :out_D, :out_H, :out_W]\n\n        if self.return_indices:\n            # Not supported in JAX, so just return the output\n            return out, None\n        return out\n\nbatch_size = 16\nchannels = 32\ndim1 = 128\ndim2 = 128\ndim3 = 128\nkernel_size = 3\nstride = 2\npadding = 1\ndilation = 3\n\ndef get_inputs():\n    x = jax.random.uniform(jax.random.PRNGKey(0), (batch_size, channels, dim1, dim2, dim3))\n    return [x]\n\ndef get_init_inputs():\n    return [kernel_size, stride, padding, dilation]"}
{"kb_id": "kb_level_1_0038", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0038.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0038_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs 1D Average Pooling.\n    \"\"\"\n    def __init__(self, kernel_size: int, stride: int = 1, padding: int = 0):\n        \"\"\"\n        Initializes the 1D Average Pooling layer.\n\n        Args:\n            kernel_size (int): Size of the pooling window.\n            stride (int, optional): Stride of the pooling operation. Defaults to 1.\n            padding (int, optional): Padding applied to the input tensor. Defaults to 0.\n        \"\"\"\n        super(Model, self).__init__()\n        self.avg_pool = nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=padding)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies 1D Average Pooling to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, input_length).\n\n        Returns:\n            torch.Tensor: Output tensor with 1D Average Pooling applied, shape (batch_size, in_channels, output_length).\n        \"\"\"\n        return self.avg_pool(x)\n\nbatch_size = 64\nin_channels = 128\ninput_length = 65536\nkernel_size = 8\nstride = 1\npadding = 4\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, input_length)\n    return [x]\n\ndef get_init_inputs():\n    return [kernel_size, stride, padding]", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    Simple model that performs 1D Average Pooling.\n    \"\"\"\n    def __init__(self, kernel_size: int, stride: int = 1, padding: int = 0):\n        \"\"\"\n        Initializes the 1D Average Pooling layer.\n\n        Args:\n            kernel_size (int): Size of the pooling window.\n            stride (int, optional): Stride of the pooling operation. Defaults to 1.\n            padding (int, optional): Padding applied to the input tensor. Defaults to 0.\n        \"\"\"\n        self.kernel_size = kernel_size\n        self.stride = stride\n        self.padding = padding\n\n    def forward(self, x: jnp.ndarray) -> jnp.ndarray:\n        \"\"\"\n        Applies 1D Average Pooling to the input tensor.\n\n        Args:\n            x (jnp.ndarray): Input tensor of shape (batch_size, in_channels, input_length).\n\n        Returns:\n            jnp.ndarray: Output tensor with 1D Average Pooling applied, shape (batch_size, in_channels, output_length).\n        \"\"\"\n        # x: (batch, channels, length)\n        batch_size, in_channels, input_length = x.shape\n\n        # Pad along the last dimension (length)\n        if self.padding > 0:\n            pad_width = [(0, 0), (0, 0), (self.padding, self.padding)]\n            x = jnp.pad(x, pad_width, mode='constant', constant_values=0)\n\n        # Calculate output length\n        L_in = x.shape[2]\n        kernel_size = self.kernel_size\n        stride = self.stride\n        output_length = (L_in - kernel_size) // stride + 1\n\n        # Use jax.lax.reduce_window to perform average pooling\n        window_shape = (1, 1, kernel_size)\n        window_strides = (1, 1, stride)\n        pooled = jax.lax.reduce_window(\n            x,\n            0.0,\n            jax.lax.add,\n            window_shape,\n            window_strides,\n            padding='VALID'\n        )\n        pooled = pooled / kernel_size\n        return pooled\n\nbatch_size = 64\nin_channels = 128\ninput_length = 65536\nkernel_size = 8\nstride = 1\npadding = 4\n\ndef get_inputs():\n    x = jax.random.uniform(jax.random.PRNGKey(0), (batch_size, in_channels, input_length))\n    return [x]\n\ndef get_init_inputs():\n    return [kernel_size, stride, padding]"}
{"kb_id": "kb_level_1_0039", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0039.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0039_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs 2D Average Pooling.\n    \"\"\"\n    def __init__(self, kernel_size: int, stride: int = None, padding: int = 0):\n        \"\"\"\n        Initializes the Average Pooling layer.\n\n        Args:\n            kernel_size (int): Size of the pooling window.\n            stride (int, optional): Stride of the pooling operation. Defaults to None (same as kernel_size).\n            padding (int, optional): Padding applied to the input tensor. Defaults to 0.\n        \"\"\"\n        super(Model, self).__init__()\n        self.avg_pool = nn.AvgPool2d(kernel_size=kernel_size, stride=stride, padding=padding)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies 2D Average Pooling to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor with Average Pooling applied.\n        \"\"\"\n        return self.avg_pool(x)\n\nbatch_size = 16\nchannels = 64\nheight = 2048\nwidth = 2048\nkernel_size = 11\n\ndef get_inputs():\n    x = torch.rand(batch_size, channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [kernel_size]", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    Simple model that performs 2D Average Pooling.\n    \"\"\"\n    def __init__(self, kernel_size: int, stride: int = None, padding: int = 0):\n        \"\"\"\n        Initializes the Average Pooling layer.\n\n        Args:\n            kernel_size (int): Size of the pooling window.\n            stride (int, optional): Stride of the pooling operation. Defaults to None (same as kernel_size).\n            padding (int, optional): Padding applied to the input tensor. Defaults to 0.\n        \"\"\"\n        self.kernel_size = kernel_size\n        self.stride = stride if stride is not None else kernel_size\n        self.padding = padding\n\n    def __call__(self, x: jnp.ndarray) -> jnp.ndarray:\n        \"\"\"\n        Applies 2D Average Pooling to the input tensor.\n\n        Args:\n            x (jnp.ndarray): Input tensor of shape (batch_size, channels, height, width).\n\n        Returns:\n            jnp.ndarray: Output tensor with Average Pooling applied.\n        \"\"\"\n        # x: (N, C, H, W)\n        N, C, H, W = x.shape\n        kH, kW = self.kernel_size, self.kernel_size\n        sH, sW = self.stride, self.stride\n        pH, pW = self.padding, self.padding\n\n        # Pad input if needed\n        if pH > 0 or pW > 0:\n            # Pad only height and width dimensions\n            pad_width = ((0,0), (0,0), (pH,pH), (pW,pW))\n            x = jnp.pad(x, pad_width, mode='constant', constant_values=0)\n\n        # Calculate output dimensions\n        out_H = (x.shape[2] - kH) // sH + 1\n        out_W = (x.shape[3] - kW) // sW + 1\n\n        # Use jax.lax.reduce_window to perform average pooling\n        window_shape = (1, 1, kH, kW)\n        strides = (1, 1, sH, sW)\n        pooled = jax.lax.reduce_window(\n            x,\n            0.0,\n            jax.lax.add,\n            window_shape,\n            strides,\n            padding='VALID'\n        )\n        # Divide by window size to get average\n        pooled = pooled / (kH * kW)\n        return pooled\n\nbatch_size = 16\nchannels = 64\nheight = 2048\nwidth = 2048\nkernel_size = 11\n\ndef get_inputs():\n    x = jax.random.uniform(jax.random.PRNGKey(0), (batch_size, channels, height, width))\n    return [x]\n\ndef get_init_inputs():\n    return [kernel_size]"}
{"kb_id": "kb_level_1_0041", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0041.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0041_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs sum reduction over a specified dimension.\n    \"\"\"\n    def __init__(self, dim: int):\n        \"\"\"\n        Initializes the model with the dimension to reduce over.\n\n        Args:\n            dim (int): Dimension to reduce over.\n        \"\"\"\n        super(Model, self).__init__()\n        self.dim = dim\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies sum reduction over the specified dimension.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (..., dim, ...).\n\n        Returns:\n            torch.Tensor: Output tensor after sum reduction, shape (..., 1, ...).\n        \"\"\"\n        return torch.sum(x, dim=self.dim, keepdim=True)\n\nbatch_size = 128\ndim1 = 4096\ndim2 = 4095\nreduce_dim = 1\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [reduce_dim]", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    Simple model that performs sum reduction over a specified dimension.\n    \"\"\"\n    def __init__(self, dim: int):\n        \"\"\"\n        Initializes the model with the dimension to reduce over.\n\n        Args:\n            dim (int): Dimension to reduce over.\n        \"\"\"\n        self.dim = dim\n\n    def __call__(self, x: jnp.ndarray) -> jnp.ndarray:\n        \"\"\"\n        Applies sum reduction over the specified dimension.\n\n        Args:\n            x (jnp.ndarray): Input tensor of shape (..., dim, ...).\n\n        Returns:\n            jnp.ndarray: Output tensor after sum reduction, shape (..., 1, ...).\n        \"\"\"\n        return jnp.sum(x, axis=self.dim, keepdims=True)\n\nbatch_size = 128\ndim1 = 4096\ndim2 = 4095\nreduce_dim = 1\n\ndef get_inputs():\n    x = jax.random.uniform(jax.random.PRNGKey(0), (batch_size, dim1, dim2))\n    return [x]\n\ndef get_init_inputs():\n    return [reduce_dim]"}
{"kb_id": "kb_level_1_0042", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0042.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0042_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs mean reduction over a specific dimension.\n    \"\"\"\n    def __init__(self, dim: int):\n        \"\"\"\n        Initializes the model with the dimension to reduce over.\n\n        Args:\n            dim (int): The dimension to reduce over.\n        \"\"\"\n        super(Model, self).__init__()\n        self.dim = dim\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Reduces the input tensor along the specified dimension by taking the mean.\n\n        Args:\n            x (torch.Tensor): Input tensor of arbitrary shape.\n\n        Returns:\n            torch.Tensor: Output tensor with reduced dimension. The shape of the output is the same as the input except for the reduced dimension which is removed.\n        \"\"\"\n        return torch.mean(x, dim=self.dim)\n\nbatch_size = 128\ndim1 = 4096\ndim2 = 4095\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [1]", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    Simple model that performs mean reduction over a specific dimension.\n    \"\"\"\n    def __init__(self, dim: int):\n        \"\"\"\n        Initializes the model with the dimension to reduce over.\n\n        Args:\n            dim (int): The dimension to reduce over.\n        \"\"\"\n        self.dim = dim\n\n    def __call__(self, x):\n        \"\"\"\n        Reduces the input tensor along the specified dimension by taking the mean.\n\n        Args:\n            x (jnp.ndarray): Input tensor of arbitrary shape.\n\n        Returns:\n            jnp.ndarray: Output tensor with reduced dimension. The shape of the output is the same as the input except for the reduced dimension which is removed.\n        \"\"\"\n        return jnp.mean(x, axis=self.dim)\n\nbatch_size = 128\ndim1 = 4096\ndim2 = 4095\n\ndef get_inputs():\n    x = jax.random.uniform(jax.random.PRNGKey(0), (batch_size, dim1, dim2))\n    return [x]\n\ndef get_init_inputs():\n    return [1]"}
{"kb_id": "kb_level_1_0043", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0043.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0043_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs Max reduction over a specific dimension.\n    \"\"\"\n    def __init__(self, dim: int):\n        \"\"\"\n        Initializes the model with the dimension to reduce over.\n\n        Args:\n            dim (int): The dimension to reduce over.\n        \"\"\"\n        super(Model, self).__init__()\n        self.dim = dim\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Max reduction over the specified dimension to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor.\n\n        Returns:\n            torch.Tensor: Output tensor after Max reduction over the specified dimension.\n        \"\"\"\n        return torch.max(x, dim=self.dim)[0]\n\nbatch_size = 128\ndim1 = 4096\ndim2 = 4095\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [1] # Example, change to desired dimension", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    Simple model that performs Max reduction over a specific dimension.\n    \"\"\"\n    def __init__(self, dim: int):\n        \"\"\"\n        Initializes the model with the dimension to reduce over.\n\n        Args:\n            dim (int): The dimension to reduce over.\n        \"\"\"\n        self.dim = dim\n\n    def __call__(self, x: jnp.ndarray) -> jnp.ndarray:\n        \"\"\"\n        Applies Max reduction over the specified dimension to the input tensor.\n\n        Args:\n            x (jnp.ndarray): Input tensor.\n\n        Returns:\n            jnp.ndarray: Output tensor after Max reduction over the specified dimension.\n        \"\"\"\n        return jnp.max(x, axis=self.dim)\n\nbatch_size = 128\ndim1 = 4096\ndim2 = 4095\n\ndef get_inputs():\n    x = jax.random.uniform(jax.random.PRNGKey(0), (batch_size, dim1, dim2))\n    return [x]\n\ndef get_init_inputs():\n    return [1]  # Example, change to desired dimension"}
{"kb_id": "kb_level_1_0044", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0044.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0044_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs matrix-vector multiplication (C = A * B).\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs matrix-vector multiplication.\n\n        Args:\n            A: Input matrix of shape (M, K).\n            B: Input vector of shape (K, 1).\n\n        Returns:\n            Output vector of shape (M, 1).\n        \"\"\"\n        return torch.matmul(A, B)\n\nM = 256 * 8 # 2048\nK = 131072 * 8 # 1048576\n\ndef get_inputs():\n    A = torch.rand(M, K)\n    B = torch.rand(K, 1)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    Simple model that performs matrix-vector multiplication (C = A * B).\n    \"\"\"\n    def __init__(self):\n        pass\n\n    def __call__(self, A: jnp.ndarray, B: jnp.ndarray) -> jnp.ndarray:\n        \"\"\"\n        Performs matrix-vector multiplication.\n\n        Args:\n            A: Input matrix of shape (M, K).\n            B: Input vector of shape (K, 1).\n\n        Returns:\n            Output vector of shape (M, 1).\n        \"\"\"\n        return jnp.matmul(A, B)\n\nM = 256 * 8  # 2048\nK = 131072 * 8  # 1048576\n\ndef get_inputs():\n    key_A, key_B = jax.random.split(jax.random.PRNGKey(0))\n    A = jax.random.uniform(key_A, (M, K))\n    B = jax.random.uniform(key_B, (K, 1))\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}
{"kb_id": "kb_level_1_0046", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0046.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0046_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs Argmax over a specified dimension.\n    \"\"\"\n    def __init__(self, dim: int):\n        \"\"\"\n        Initializes the model with the dimension to perform argmax.\n\n        Args:\n            dim (int): The dimension to perform argmax over.\n        \"\"\"\n        super(Model, self).__init__()\n        self.dim = dim\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies argmax over the specified dimension to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor.\n\n        Returns:\n            torch.Tensor: Output tensor with argmax applied, with the specified dimension removed.\n        \"\"\"\n        return torch.argmax(x, dim=self.dim)\n\nbatch_size = 128\ndim1 = 4096\ndim2 = 4095\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [1]", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    Simple model that performs Argmax over a specified dimension.\n    \"\"\"\n    def __init__(self, dim: int):\n        \"\"\"\n        Initializes the model with the dimension to perform argmax.\n\n        Args:\n            dim (int): The dimension to perform argmax over.\n        \"\"\"\n        self.dim = dim\n\n    def __call__(self, x: jnp.ndarray) -> jnp.ndarray:\n        \"\"\"\n        Applies argmax over the specified dimension to the input tensor.\n\n        Args:\n            x (jnp.ndarray): Input tensor.\n\n        Returns:\n            jnp.ndarray: Output tensor with argmax applied, with the specified dimension removed.\n        \"\"\"\n        return jnp.argmax(x, axis=self.dim)\n\nbatch_size = 128\ndim1 = 4096\ndim2 = 4095\n\ndef get_inputs():\n    x = jax.random.uniform(jax.random.PRNGKey(0), (batch_size, dim1, dim2))\n    return [x]\n\ndef get_init_inputs():\n    return [1]"}
{"kb_id": "kb_level_1_0047", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0047.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0047_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that finds the index of the minimum value along a specified dimension.\n    \"\"\"\n    def __init__(self, dim: int):\n        \"\"\"\n        Initializes the model with the dimension to perform argmin on.\n\n        Args:\n            dim (int): Dimension along which to find the minimum value.\n        \"\"\"\n        super(Model, self).__init__()\n        self.dim = dim\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Finds the index of the minimum value along the specified dimension.\n\n        Args:\n            x (torch.Tensor): Input tensor.\n\n        Returns:\n            torch.Tensor: Tensor containing the indices of the minimum values along the specified dimension.\n        \"\"\"\n        return torch.argmin(x, dim=self.dim)\n\nbatch_size = 128\ndim1 = 4096\ndim2 = 4095\ndim = 1\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [dim]", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    Simple model that finds the index of the minimum value along a specified dimension.\n    \"\"\"\n    def __init__(self, dim: int):\n        \"\"\"\n        Initializes the model with the dimension to perform argmin on.\n\n        Args:\n            dim (int): Dimension along which to find the minimum value.\n        \"\"\"\n        self.dim = dim\n\n    def __call__(self, x: jnp.ndarray) -> jnp.ndarray:\n        \"\"\"\n        Finds the index of the minimum value along the specified dimension.\n\n        Args:\n            x (jnp.ndarray): Input tensor.\n\n        Returns:\n            jnp.ndarray: Tensor containing the indices of the minimum values along the specified dimension.\n        \"\"\"\n        return jnp.argmin(x, axis=self.dim)\n\nbatch_size = 128\ndim1 = 4096\ndim2 = 4095\ndim = 1\n\ndef get_inputs():\n    x = jax.random.uniform(jax.random.PRNGKey(0), (batch_size, dim1, dim2))\n    return [x]\n\ndef get_init_inputs():\n    return [dim]"}
{"kb_id": "kb_level_1_0048", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0048.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0048_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs min reduction over a specific dimension.\n    \"\"\"\n    def __init__(self, dim: int):\n        \"\"\"\n        Initializes the model with the dimension to reduce over.\n\n        Args:\n            dim (int): The dimension to reduce over.\n        \"\"\"\n        super(Model, self).__init__()\n        self.dim = dim\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies min reduction over the specified dimension to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor.\n\n        Returns:\n            torch.Tensor: Output tensor after min reduction over the specified dimension.\n        \"\"\"\n        return torch.min(x, dim=self.dim)[0]\n\nbatch_size = 128\ndim1 = 4096\ndim2 = 4095\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [1] # Example, change to desired dimension", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    Simple model that performs min reduction over a specific dimension.\n    \"\"\"\n    def __init__(self, dim: int):\n        \"\"\"\n        Initializes the model with the dimension to reduce over.\n\n        Args:\n            dim (int): The dimension to reduce over.\n        \"\"\"\n        self.dim = dim\n\n    def __call__(self, x: jnp.ndarray) -> jnp.ndarray:\n        \"\"\"\n        Applies min reduction over the specified dimension to the input tensor.\n\n        Args:\n            x (jnp.ndarray): Input tensor.\n\n        Returns:\n            jnp.ndarray: Output tensor after min reduction over the specified dimension.\n        \"\"\"\n        return jnp.min(x, axis=self.dim)\n\nbatch_size = 128\ndim1 = 4096\ndim2 = 4095\n\ndef get_inputs():\n    x = jax.random.uniform(jax.random.PRNGKey(0), (batch_size, dim1, dim2))\n    return [x]\n\ndef get_init_inputs():\n    return [1]  # Example, change to desired dimension"}
{"kb_id": "kb_level_1_0055", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0055.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0055_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix-scalar multiplication (C = A * s)\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A: torch.Tensor, s: float) -> torch.Tensor:\n        \"\"\"\n        Performs matrix-scalar multiplication.\n\n        Args:\n            A: Input matrix of shape (M, N)\n            s: Scalar value\n\n        Returns:\n            C: Resulting matrix of shape (M, N)\n        \"\"\"\n        return A * s\n\nM = 16384 * 4\nN = 4096 * 4\n\ndef get_inputs():\n    A = torch.rand(M, N)\n    s = 3.14\n    return [A, s]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    Simple model that performs a matrix-scalar multiplication (C = A * s)\n    \"\"\"\n    def __init__(self):\n        pass\n\n    def __call__(self, A: jnp.ndarray, s: float) -> jnp.ndarray:\n        \"\"\"\n        Performs matrix-scalar multiplication.\n\n        Args:\n            A: Input matrix of shape (M, N)\n            s: Scalar value\n\n        Returns:\n            C: Resulting matrix of shape (M, N)\n        \"\"\"\n        return A * s\n\nM = 16384 * 4\nN = 4096 * 4\n\ndef get_inputs():\n    key = jax.random.PRNGKey(0)\n    A = jax.random.uniform(key, (M, N))\n    s = 3.14\n    return [A, s]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}
{"kb_id": "kb_level_1_0066", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0066.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0066_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B) with a large K dimension\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs matrix multiplication of A and B.\n\n        Args:\n            A: Input tensor of shape (M, K)\n            B: Input tensor of shape (K, N)\n\n        Returns:\n            Output tensor of shape (M, N)\n        \"\"\"\n        return torch.matmul(A, B)\n\nM = 256\nN = 256\nK = 131072 * 4\n\ndef get_inputs():\n    A = torch.rand(M, K)\n    B = torch.rand(K, N)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "jax_code": "import jax\nimport jax.numpy as jnp\n\nM = 256\nN = 256\nK = 131072 * 4\n\nclass Model:\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B) with a large K dimension\n    \"\"\"\n    def __init__(self):\n        pass\n\n    def __call__(self, A: jnp.ndarray, B: jnp.ndarray) -> jnp.ndarray:\n        \"\"\"\n        Performs matrix multiplication of A and B.\n\n        Args:\n            A: Input tensor of shape (M, K)\n            B: Input tensor of shape (K, N)\n\n        Returns:\n            Output tensor of shape (M, N)\n        \"\"\"\n        return jnp.matmul(A, B)\n\ndef get_inputs():\n    key_A, key_B = jax.random.split(jax.random.PRNGKey(0))\n    A = jax.random.uniform(key_A, (M, K))\n    B = jax.random.uniform(key_B, (K, N))\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}
{"kb_id": "kb_level_1_0077", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0077.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0077_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B) with a small K dimension\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs matrix multiplication.\n\n        Args:\n            A: Input tensor of shape (M, K).\n            B: Input tensor of shape (K, N).\n\n        Returns:\n            Output tensor of shape (M, N).\n        \"\"\"\n        return torch.matmul(A, B)\n\nM = 16384 * 2\nN = 16384 * 2\nK = 32 * 2\n\ndef get_inputs():\n    A = torch.rand(M, K)\n    B = torch.rand(K, N)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B) with a small K dimension\n    \"\"\"\n    def __init__(self):\n        pass\n\n    def __call__(self, A: jnp.ndarray, B: jnp.ndarray) -> jnp.ndarray:\n        \"\"\"\n        Performs matrix multiplication.\n\n        Args:\n            A: Input tensor of shape (M, K).\n            B: Input tensor of shape (K, N).\n\n        Returns:\n            Output tensor of shape (M, N).\n        \"\"\"\n        return jnp.matmul(A, B)\n\nM = 16384 * 2\nN = 16384 * 2\nK = 32 * 2\n\ndef get_inputs():\n    key1, key2 = jax.random.split(jax.random.PRNGKey(0))\n    A = jax.random.uniform(key1, (M, K))\n    B = jax.random.uniform(key2, (K, N))\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}
{"kb_id": "kb_level_1_0086", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0086.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0086_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\n\n# From https://github.com/karpathy/minGPT/blob/master/mingpt/model.py\n\nclass Model(nn.Module):\n    \"\"\"\n    Implementation of the GELU activation function currently in Google BERT repo (identical to OpenAI GPT).\n    Reference: Gaussian Error Linear Units (GELU) paper: https://arxiv.org/abs/1606.08415\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, x):\n        return 0.5 * x * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (x + 0.044715 * torch.pow(x, 3.0))))\n\nbatch_size = 8192\ndim = 8192\n\ndef get_inputs():\n    return [torch.rand(batch_size, dim)]\n\ndef get_init_inputs():\n    return []", "jax_code": "import math\nimport jax\nimport jax.numpy as jnp\n\n# From https://github.com/karpathy/minGPT/blob/master/mingpt/model.py\n\nclass Model:\n    \"\"\"\n    Implementation of the GELU activation function currently in Google BERT repo (identical to OpenAI GPT).\n    Reference: Gaussian Error Linear Units (GELU) paper: https://arxiv.org/abs/1606.08415\n    \"\"\"\n    def __init__(self):\n        pass\n\n    def __call__(self, x):\n        return 0.5 * x * (1.0 + jnp.tanh(math.sqrt(2.0 / math.pi) * (x + 0.044715 * jnp.power(x, 3.0))))\n\nbatch_size = 8192\ndim = 8192\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, dim)]\n\ndef get_init_inputs():\n    return []"}
{"kb_id": "kb_level_1_0087", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0087.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0087_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A simple model that performs a cumulative sum (prefix sum) operation along a specified dimension.\n\n    Parameters:\n        dim (int): The dimension along which to perform the scan operation.\n    \"\"\"\n\n    def __init__(self, dim):\n        \"\"\"\n        Initialize the Scan model.\n\n        Args:\n            dim (int): The dimension along which to perform the cumulative sum.\n        \"\"\"\n        super(Model, self).__init__()\n        self.dim = dim\n\n    def forward(self, x):\n        \"\"\"\n        Forward pass for the Scan model, computing the cumulative sum along the specified dimension.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, *input_shape), where `*input_shape` \n                              can vary depending on the use case.\n\n        Returns:\n            torch.Tensor: Tensor of the same shape as `x` after applying cumulative sum along `dim`.\n        \"\"\"\n        return torch.cumsum(x, dim=self.dim)\n\n# Define input dimensions and parameters\nbatch_size = 32768\ninput_shape = (32768,)\ndim = 1\n\ndef get_inputs():\n    \"\"\"\n    Generates random inputs for testing the Scan model.\n\n    Returns:\n        list: A list containing a single randomly generated tensor with shape \n              (batch_size, *input_shape).\n    \"\"\"\n    return [torch.rand(batch_size, *input_shape)]\n\ndef get_init_inputs():\n    \"\"\"\n    Returns the initialization parameters for the Scan model.\n\n    Returns:\n        list: A list containing the `dim` parameter for model initialization.\n    \"\"\"\n    return [dim]", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    A simple model that performs a cumulative sum (prefix sum) operation along a specified dimension.\n\n    Parameters:\n        dim (int): The dimension along which to perform the scan operation.\n    \"\"\"\n\n    def __init__(self, dim):\n        \"\"\"\n        Initialize the Scan model.\n\n        Args:\n            dim (int): The dimension along which to perform the cumulative sum.\n        \"\"\"\n        self.dim = dim\n\n    def __call__(self, x):\n        \"\"\"\n        Forward pass for the Scan model, computing the cumulative sum along the specified dimension.\n\n        Args:\n            x (jnp.ndarray): Input tensor of shape (batch_size, *input_shape), where `*input_shape` \n                             can vary depending on the use case.\n\n        Returns:\n            jnp.ndarray: Tensor of the same shape as `x` after applying cumulative sum along `dim`.\n        \"\"\"\n        return jnp.cumsum(x, axis=self.dim)\n\n# Define input dimensions and parameters\nbatch_size = 32768\ninput_shape = (32768,)\ndim = 1\n\ndef get_inputs():\n    \"\"\"\n    Generates random inputs for testing the Scan model.\n\n    Returns:\n        list: A list containing a single randomly generated tensor with shape \n              (batch_size, *input_shape).\n    \"\"\"\n    key = jax.random.PRNGKey(0)\n    x = jax.random.uniform(key, shape=(batch_size, *input_shape))\n    return [x]\n\ndef get_init_inputs():\n    \"\"\"\n    Returns the initialization parameters for the Scan model.\n\n    Returns:\n        list: A list containing the `dim` parameter for model initialization.\n    \"\"\"\n    return [dim]"}
{"kb_id": "kb_level_1_0088", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0088.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0088_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B) with irregular shapes\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs matrix multiplication of A and B.\n\n        Args:\n            A: Input tensor with shape (M, K).\n            B: Input tensor with shape (K, N).\n\n        Returns:\n            C: Output tensor with shape (M, N).\n        \"\"\"\n        return torch.matmul(A, B)\n\nM = 8205\nK = 2949\nN = 5921\n\ndef get_inputs():\n    A = torch.rand(M, K)\n    B = torch.rand(K, N)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "jax_code": "import jax\nimport jax.numpy as jnp\n\nM = 8205\nK = 2949\nN = 5921\n\nclass Model:\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B) with irregular shapes\n    \"\"\"\n    def __init__(self):\n        pass\n\n    def __call__(self, A: jnp.ndarray, B: jnp.ndarray) -> jnp.ndarray:\n        \"\"\"\n        Performs matrix multiplication of A and B.\n\n        Args:\n            A: Input tensor with shape (M, K).\n            B: Input tensor with shape (K, N).\n\n        Returns:\n            C: Output tensor with shape (M, N).\n        \"\"\"\n        return jnp.matmul(A, B)\n\ndef get_inputs():\n    key1, key2 = jax.random.split(jax.random.PRNGKey(0))\n    A = jax.random.uniform(key1, (M, K))\n    B = jax.random.uniform(key2, (K, N))\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}
{"kb_id": "kb_level_1_0089", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0089.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0089_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a cumulative product operation along a specified dimension.\n\n    Parameters:\n        dim (int): The dimension along which to perform the cumulative product operation.\n    \"\"\"\n\n    def __init__(self, dim):\n        \"\"\"\n        Initialize the CumulativeProductModel.\n\n        Args:\n            dim (int): The dimension along which to perform the cumulative product.\n        \"\"\"\n        super(Model, self).__init__()\n        self.dim = dim\n\n    def forward(self, x):\n        \"\"\"\n        Forward pass, computing the cumulative product along the specified dimension.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, *input_shape).\n\n        Returns:\n            torch.Tensor: Tensor of the same shape as `x` after applying cumulative product along `dim`.\n        \"\"\"\n        return torch.cumprod(x, dim=self.dim)\n\n# Define input dimensions and parameters\nbatch_size = 32768\ninput_shape = (32768,)\ndim = 1\n\ndef get_inputs():\n    return [torch.rand(batch_size, *input_shape)]\n\ndef get_init_inputs():\n    return [dim]\n", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    A model that performs a cumulative product operation along a specified dimension.\n\n    Parameters:\n        dim (int): The dimension along which to perform the cumulative product operation.\n    \"\"\"\n\n    def __init__(self, dim):\n        \"\"\"\n        Initialize the CumulativeProductModel.\n\n        Args:\n            dim (int): The dimension along which to perform the cumulative product.\n        \"\"\"\n        self.dim = dim\n\n    def __call__(self, x):\n        \"\"\"\n        Forward pass, computing the cumulative product along the specified dimension.\n\n        Args:\n            x (jnp.ndarray): Input tensor of shape (batch_size, *input_shape).\n\n        Returns:\n            jnp.ndarray: Tensor of the same shape as `x` after applying cumulative product along `dim`.\n        \"\"\"\n        return jnp.cumprod(x, axis=self.dim)\n\n# Define input dimensions and parameters\nbatch_size = 32768\ninput_shape = (32768,)\ndim = 1\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, *input_shape)]\n\ndef get_init_inputs():\n    return [dim]"}
{"kb_id": "kb_level_1_0090", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0090.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0090_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a reverse cumulative sum operation along a specified dimension.\n\n    Parameters:\n        dim (int): The dimension along which to perform the reverse cumulative sum.\n    \"\"\"\n\n    def __init__(self, dim):\n        super(Model, self).__init__()\n        self.dim = dim\n\n    def forward(self, x):\n        return torch.cumsum(x.flip(self.dim), dim=self.dim).flip(self.dim)\n\nbatch_size = 32768\ninput_shape = (32768,)\ndim = 1\n\ndef get_inputs():\n    return [torch.rand(batch_size, *input_shape)]\n\ndef get_init_inputs():\n    return [dim]\n", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    A model that performs a reverse cumulative sum operation along a specified dimension.\n\n    Parameters:\n        dim (int): The dimension along which to perform the reverse cumulative sum.\n    \"\"\"\n\n    def __init__(self, dim):\n        self.dim = dim\n\n    def __call__(self, x):\n        # Reverse along the specified dimension\n        x_reversed = jnp.flip(x, axis=self.dim)\n        # Cumulative sum along the specified dimension\n        cumsum = jnp.cumsum(x_reversed, axis=self.dim)\n        # Reverse back along the same dimension\n        return jnp.flip(cumsum, axis=self.dim)\n\nbatch_size = 32768\ninput_shape = (32768,)\ndim = 1\n\ndef get_inputs():\n    key = jax.random.PRNGKey(0)\n    x = jax.random.uniform(key, shape=(batch_size, *input_shape))\n    return [x]\n\ndef get_init_inputs():\n    return [dim]"}
{"kb_id": "kb_level_1_0091", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0091.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0091_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs an exclusive cumulative sum (does not include the current element).\n\n    Parameters:\n        dim (int): The dimension along which to perform the exclusive cumulative sum.\n    \"\"\"\n\n    def __init__(self, dim):\n        super(Model, self).__init__()\n        self.dim = dim\n\n    def forward(self, x):\n        exclusive_cumsum = torch.cat((torch.zeros_like(x.select(self.dim, 0).unsqueeze(self.dim)), x), dim=self.dim)[:-1]\n        return torch.cumsum(exclusive_cumsum, dim=self.dim)\n\nbatch_size = 32768\ninput_shape = (32768,)\ndim = 1\n\ndef get_inputs():\n    return [torch.rand(batch_size, *input_shape)]\n\ndef get_init_inputs():\n    return [dim]\n", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    A model that performs an exclusive cumulative sum (does not include the current element).\n\n    Parameters:\n        dim (int): The dimension along which to perform the exclusive cumulative sum.\n    \"\"\"\n\n    def __init__(self, dim):\n        self.dim = dim\n\n    def __call__(self, x):\n        # Create a zeros slice matching the shape of x, but only the first index along self.dim\n        zeros_shape = list(x.shape)\n        zeros_shape[self.dim] = 1\n        zeros = jnp.zeros(zeros_shape, dtype=x.dtype)\n        # Concatenate zeros at the start along self.dim\n        exclusive_cumsum = jnp.concatenate([zeros, x], axis=self.dim)\n        # Remove the last element along self.dim\n        exclusive_cumsum = jnp.take(exclusive_cumsum, indices=range(x.shape[self.dim]), axis=self.dim)\n        return jnp.cumsum(exclusive_cumsum, axis=self.dim)\n\nbatch_size = 32768\ninput_shape = (32768,)\ndim = 1\n\ndef get_inputs():\n    key = jax.random.PRNGKey(0)\n    x = jax.random.uniform(key, shape=(batch_size, *input_shape))\n    return [x]\n\ndef get_init_inputs():\n    return [dim]"}
{"kb_id": "kb_level_1_0092", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 67.36401673640168, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0092.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0092_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a masked cumulative sum, only summing elements that satisfy a condition.\n\n    Parameters:\n        dim (int): The dimension along which to perform the masked cumulative sum.\n    \"\"\"\n\n    def __init__(self, dim):\n        super(Model, self).__init__()\n        self.dim = dim\n\n    def forward(self, x, mask):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, *input_shape).\n            mask (torch.Tensor): Boolean mask of the same shape as x.\n\n        Returns:\n            torch.Tensor: Cumulative sum of elements where mask is True.\n        \"\"\"\n        return torch.cumsum(x * mask, dim=self.dim)\n\nbatch_size = 32768\ninput_shape = (32768,)\ndim = 1\n\ndef get_inputs():\n    x = torch.rand(batch_size, *input_shape)\n    mask = torch.randint(0, 2, x.shape).bool()  # Random boolean mask\n    return [x, mask]\n\ndef get_init_inputs():\n    return [dim]\n", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    A model that performs a masked cumulative sum, only summing elements that satisfy a condition.\n\n    Parameters:\n        dim (int): The dimension along which to perform the masked cumulative sum.\n    \"\"\"\n\n    def __init__(self, dim):\n        self.dim = dim\n\n    def __call__(self, x, mask):\n        \"\"\"\n        Args:\n            x (jnp.ndarray): Input tensor of shape (batch_size, *input_shape).\n            mask (jnp.ndarray): Boolean mask of the same shape as x.\n\n        Returns:\n            jnp.ndarray: Cumulative sum of elements where mask is True.\n        \"\"\"\n        # mask is boolean, so x * mask will zero out elements where mask is False\n        return jnp.cumsum(x * mask, axis=self.dim)\n\nbatch_size = 32768\ninput_shape = (32768,)\ndim = 1\n\ndef get_inputs():\n    key1, key2 = jax.random.split(jax.random.PRNGKey(0))\n    x = jax.random.uniform(key1, shape=(batch_size, *input_shape))\n    mask = jax.random.randint(key2, shape=x.shape, minval=0, maxval=2).astype(bool)\n    return [x, mask]\n\ndef get_init_inputs():\n    return [dim]"}
{"kb_id": "kb_level_1_0093", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0093.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0093_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that computes the Mean Squared Error loss for regression tasks.\n\n    Parameters:\n        None\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n\n    def forward(self, predictions, targets):\n        return torch.mean((predictions - targets) ** 2)\n\nbatch_size = 32768\ninput_shape = (32768,)\ndim = 1\n\ndef get_inputs():\n    scale = torch.rand(())\n    return [torch.rand(batch_size, *input_shape)*scale, torch.rand(batch_size, *input_shape)]\n\ndef get_init_inputs():\n    return []\n", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    A model that computes the Mean Squared Error loss for regression tasks.\n\n    Parameters:\n        None\n    \"\"\"\n    def __init__(self):\n        pass\n\n    def __call__(self, predictions, targets):\n        return jnp.mean((predictions - targets) ** 2)\n\nbatch_size = 32768\ninput_shape = (32768,)\ndim = 1\n\ndef get_inputs():\n    key1, key2, key3 = jax.random.split(jax.random.PRNGKey(0), 3)\n    scale = jax.random.uniform(key1, ())\n    preds = jax.random.uniform(key2, (batch_size, *input_shape)) * scale\n    targets = jax.random.uniform(key3, (batch_size, *input_shape))\n    return [preds, targets]\n\ndef get_init_inputs():\n    return []"}
{"kb_id": "kb_level_1_0094", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0094.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0094_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that computes Cross Entropy Loss for multi-class classification tasks.\n\n    Parameters:\n        None\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n\n    def forward(self, predictions, targets):\n        return torch.nn.functional.cross_entropy(predictions, targets)\n\nbatch_size = 32768\nnum_classes = 4096\ninput_shape = (num_classes,)\ndim = 1\n\ndef get_inputs():\n    return [torch.rand(batch_size, *input_shape), torch.randint(0, num_classes, (batch_size,))]\n\ndef get_init_inputs():\n    return []\n", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    A model that computes Cross Entropy Loss for multi-class classification tasks.\n\n    Parameters:\n        None\n    \"\"\"\n    def __init__(self):\n        pass\n\n    def __call__(self, predictions, targets):\n        # predictions: [batch_size, num_classes], logits\n        # targets: [batch_size], integer class labels\n        log_probs = jax.nn.log_softmax(predictions, axis=1)\n        nll = -jnp.take_along_axis(log_probs, targets[:, None], axis=1).squeeze(axis=1)\n        return nll.mean()\n\nbatch_size = 32768\nnum_classes = 4096\ninput_shape = (num_classes,)\ndim = 1\n\ndef get_inputs():\n    rng = jax.random.PRNGKey(0)\n    rng_pred, rng_target = jax.random.split(rng)\n    predictions = jax.random.uniform(rng_pred, (batch_size, *input_shape))\n    targets = jax.random.randint(rng_target, (batch_size,), 0, num_classes)\n    return [predictions, targets]\n\ndef get_init_inputs():\n    return []"}
{"kb_id": "kb_level_1_0095", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0095.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0095_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that computes Smooth L1 (Huber) Loss for regression tasks.\n\n    Parameters:\n        None\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n\n    def forward(self, predictions, targets):\n        return torch.nn.functional.smooth_l1_loss(predictions, targets)\n\nbatch_size = 32768\ninput_shape = (32768,)\ndim = 1\n\ndef get_inputs():\n    scale = torch.rand(())\n    return [torch.rand(batch_size, *input_shape)*scale, torch.rand(batch_size, *input_shape)]\n\ndef get_init_inputs():\n    return []\n", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    A model that computes Smooth L1 (Huber) Loss for regression tasks.\n\n    Parameters:\n        None\n    \"\"\"\n    def __init__(self):\n        pass\n\n    def __call__(self, predictions, targets):\n        # Default beta=1.0 as in PyTorch\n        beta = 1.0\n        diff = predictions - targets\n        abs_diff = jnp.abs(diff)\n        loss = jnp.where(abs_diff < beta,\n                         0.5 * (diff ** 2) / beta,\n                         abs_diff - 0.5 * beta)\n        # PyTorch's smooth_l1_loss default reduction is 'mean'\n        return jnp.mean(loss)\n\nbatch_size = 32768\ninput_shape = (32768,)\ndim = 1\n\ndef get_inputs():\n    key1, key2, key3 = jax.random.split(jax.random.PRNGKey(0), 3)\n    scale = jax.random.uniform(key1, ())\n    x = jax.random.uniform(key2, (batch_size, *input_shape)) * scale\n    y = jax.random.uniform(key3, (batch_size, *input_shape))\n    return [x, y]\n\ndef get_init_inputs():\n    return []"}
{"kb_id": "kb_level_1_0096", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.84815618221259, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0096.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0096_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n\n    def forward(self, Q: torch.Tensor, K: torch.Tensor, V: torch.Tensor) -> torch.Tensor:\n        out = torch.nn.functional.scaled_dot_product_attention(Q, K, V)\n        return out\n\nbatch_size = 32\nnum_heads = 32\nsequence_length = 512\nembedding_dimension = 1024\n\ndef get_inputs():\n    Q = torch.rand(batch_size, num_heads, sequence_length, embedding_dimension, device='cuda', dtype=torch.float16)\n    K = torch.rand(batch_size, num_heads, sequence_length, embedding_dimension, device='cuda', dtype=torch.float16)\n    V = torch.rand(batch_size, num_heads, sequence_length, embedding_dimension, device='cuda', dtype=torch.float16)\n    return [Q, K, V]\n\ndef get_init_inputs():\n    return []\n", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    def __init__(self):\n        pass\n\n    def __call__(self, Q: jnp.ndarray, K: jnp.ndarray, V: jnp.ndarray) -> jnp.ndarray:\n        # Q, K, V: (batch, heads, seq, dim)\n        # Compute attention scores\n        d = Q.shape[-1]\n        attn_scores = jnp.einsum('bhqd,bhkd->bhqk', Q, K) / jnp.sqrt(d)\n        attn_weights = jax.nn.softmax(attn_scores, axis=-1)\n        out = jnp.einsum('bhqk,bhkd->bhqd', attn_weights, V)\n        return out\n\nbatch_size = 32\nnum_heads = 32\nsequence_length = 512\nembedding_dimension = 1024\n\ndef get_inputs():\n    key = jax.random.PRNGKey(0)\n    Q = jax.random.uniform(\n        key, \n        (batch_size, num_heads, sequence_length, embedding_dimension), \n        dtype=jnp.float16\n    )\n    key, subkey = jax.random.split(key)\n    K = jax.random.uniform(\n        subkey, \n        (batch_size, num_heads, sequence_length, embedding_dimension), \n        dtype=jnp.float16\n    )\n    key, subkey = jax.random.split(key)\n    V = jax.random.uniform(\n        subkey, \n        (batch_size, num_heads, sequence_length, embedding_dimension), \n        dtype=jnp.float16\n    )\n    return [Q, K, V]\n\ndef get_init_inputs():\n    return []"}
{"kb_id": "kb_level_1_0097", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0097.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0097_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that computes Kullback-Leibler Divergence for comparing two distributions.\n\n    Parameters:\n        None\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n\n    def forward(self, predictions, targets):\n        return torch.nn.functional.kl_div(torch.log(predictions), targets, reduction='batchmean')\n\nbatch_size = 8192 * 2\ninput_shape = (8192 * 2,)\ndim = 1\n\ndef get_inputs():\n    scale = torch.rand(())\n    return [(torch.rand(batch_size, *input_shape)*scale).softmax(dim=-1), torch.rand(batch_size, *input_shape).softmax(dim=-1)]\n\ndef get_init_inputs():\n    return []\n", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    A model that computes Kullback-Leibler Divergence for comparing two distributions.\n\n    Parameters:\n        None\n    \"\"\"\n    def __init__(self):\n        pass\n\n    def __call__(self, predictions, targets):\n        # jax.scipy.special.kl_div is elementwise, so we implement KLDiv as in PyTorch:\n        # torch.nn.functional.kl_div(torch.log(predictions), targets, reduction='batchmean')\n        # KL(P || Q) = sum_i targets_i * (log(targets_i) - log(predictions_i))\n        # PyTorch's kl_div(input, target) expects input = log Q, target = P\n        # So: kl_div(log(predictions), targets) = sum targets * (log(targets) - log(predictions))\n        # reduction='batchmean' divides by batch_size\n        # predictions: (batch_size, input_shape)\n        # targets: (batch_size, input_shape)\n        # We'll sum over all elements and divide by batch_size\n\n        # Add small epsilon for numerical stability\n        eps = 1e-8\n        predictions = jnp.clip(predictions, eps, 1.0)\n        targets = jnp.clip(targets, eps, 1.0)\n        log_predictions = jnp.log(predictions)\n        log_targets = jnp.log(targets)\n        kl = targets * (log_targets - log_predictions)\n        kl_sum = jnp.sum(kl)\n        batch_size = predictions.shape[0]\n        return kl_sum / batch_size\n\nbatch_size = 8192 * 2\ninput_shape = (8192 * 2,)\ndim = 1\n\ndef get_inputs():\n    key1, key2, key3 = jax.random.split(jax.random.PRNGKey(0), 3)\n    scale = jax.random.uniform(key1, ())\n    preds = jax.random.uniform(key2, (batch_size, *input_shape)) * scale\n    preds = jax.nn.softmax(preds, axis=-1)\n    targets = jax.random.uniform(key3, (batch_size, *input_shape))\n    targets = jax.nn.softmax(targets, axis=-1)\n    return [preds, targets]\n\ndef get_init_inputs():\n    return []"}
{"kb_id": "kb_level_1_0098", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0098.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0098_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that computes Triplet Margin Loss for metric learning tasks.\n\n    Parameters:\n        margin (float): The margin between the positive and negative samples.\n    \"\"\"\n    def __init__(self, margin=1.0):\n        super(Model, self).__init__()\n        self.loss_fn = torch.nn.TripletMarginLoss(margin=margin)\n\n    def forward(self, anchor, positive, negative):\n        return self.loss_fn(anchor, positive, negative)\n\nbatch_size = 32768\ninput_shape = (8192,)\ndim = 1\n\ndef get_inputs():\n    scale = torch.rand(())\n    return [torch.rand(batch_size, *input_shape)*scale, torch.rand(batch_size, *input_shape), torch.rand(batch_size, *input_shape)]\n    \ndef get_init_inputs():\n    return [1.0]  # Default margin\n", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    A model that computes Triplet Margin Loss for metric learning tasks.\n\n    Parameters:\n        margin (float): The margin between the positive and negative samples.\n    \"\"\"\n    def __init__(self, margin=1.0):\n        self.margin = margin\n\n    def __call__(self, anchor, positive, negative):\n        # Triplet Margin Loss: max(||anchor - positive|| - ||anchor - negative|| + margin, 0)\n        # Default: p=2 (Euclidean)\n        ap_dist = jnp.linalg.norm(anchor - positive, ord=2, axis=1)\n        an_dist = jnp.linalg.norm(anchor - negative, ord=2, axis=1)\n        loss = jnp.maximum(ap_dist - an_dist + self.margin, 0.0)\n        return jnp.mean(loss)\n\nbatch_size = 32768\ninput_shape = (8192,)\ndim = 1\n\ndef get_inputs():\n    key = jax.random.PRNGKey(0)\n    scale_key, a_key, p_key, n_key = jax.random.split(key, 4)\n    scale = jax.random.uniform(scale_key, ())\n    anchor = jax.random.uniform(a_key, (batch_size, *input_shape)) * scale\n    positive = jax.random.uniform(p_key, (batch_size, *input_shape))\n    negative = jax.random.uniform(n_key, (batch_size, *input_shape))\n    return [anchor, positive, negative]\n\ndef get_init_inputs():\n    return [1.0]  # Default margin"}
{"kb_id": "kb_level_1_0099", "level": "level_1", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_1_0099.py", "jax_path": "results/runs/2025-11-23-18h09_level_1_gpt41_strict_full_v2_n100/jax_outputs/kb_level_1_0099_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B) where one of the matrices is tall and skinny (M >> N or N >> M)\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A, B):\n        \"\"\"\n        Performs the matrix multiplication.\n\n        Args:\n            A (torch.Tensor): Input matrix of shape (M, K) or (K, M) where M >> N or N >> M.\n            B (torch.Tensor): Input matrix of shape (K, N) or (N, K) where M >> N or N >> M.\n\n        Returns:\n            torch.Tensor: Output matrix of shape (M, N) or (N, M)\n        \"\"\"\n        return torch.matmul(A, B)\n\nM = 16384 * 2\nN = 16 * 2\n\ndef get_inputs():\n    A = torch.rand(M, N)\n    B = torch.rand(N, M)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B) where one of the matrices is tall and skinny (M >> N or N >> M)\n    \"\"\"\n    def __init__(self):\n        pass\n\n    def __call__(self, A, B):\n        \"\"\"\n        Performs the matrix multiplication.\n\n        Args:\n            A (jnp.ndarray): Input matrix of shape (M, K) or (K, M) where M >> N or N >> M.\n            B (jnp.ndarray): Input matrix of shape (K, N) or (N, K) where M >> N or N >> M.\n\n        Returns:\n            jnp.ndarray: Output matrix of shape (M, N) or (N, M)\n        \"\"\"\n        return jnp.matmul(A, B)\n\nM = 16384 * 2\nN = 16 * 2\n\ndef get_inputs():\n    key1, key2 = jax.random.split(jax.random.PRNGKey(0))\n    A = jax.random.uniform(key1, (M, N))\n    B = jax.random.uniform(key2, (N, M))\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}
{"kb_id": "kb_level_2_0000", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.87364620938628, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0000.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0000_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a transposed 3D convolution, clamps the output to a minimum value, \n    and then divides the result by a constant.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, min_value, divisor):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n        self.min_value = min_value\n        self.divisor = divisor\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = torch.clamp(x, min=self.min_value)\n        x = x / self.divisor\n        return x\n\nbatch_size = 16\nin_channels = 64\nout_channels = 128\ndepth, height, width = 24, 48, 48\nkernel_size = 3\nstride = 2\npadding = 1\nmin_value = -1.0\ndivisor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, min_value, divisor]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a transposed 3D convolution, clamps the output to a minimum value, \n    and then divides the result by a constant.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    stride: int\n    padding: int\n    min_value: float\n    divisor: float\n\n    @nn.compact\n    def __call__(self, x):\n        # Flax ConvTranspose3D expects (N, D, H, W, C), so we need to permute axes\n        # Input x is (N, C, D, H, W) -> (N, D, H, W, C)\n        x = jnp.transpose(x, (0, 2, 3, 4, 1))\n        conv_transpose = nn.ConvTranspose(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size, self.kernel_size),\n            strides=(self.stride, self.stride, self.stride),\n            padding=[(self.padding, self.padding)] * 3,\n            dimension_numbers=('NDHWC', 'DHWIO', 'NDHWC'),\n            use_bias=True,\n        )\n        x = conv_transpose(x)\n        x = jnp.clip(x, a_min=self.min_value)\n        x = x / self.divisor\n        # Back to (N, C, D, H, W)\n        x = jnp.transpose(x, (0, 4, 1, 2, 3))\n        return x\n\nbatch_size = 16\nin_channels = 64\nout_channels = 128\ndepth, height, width = 24, 48, 48\nkernel_size = 3\nstride = 2\npadding = 1\nmin_value = -1.0\ndivisor = 2.0\n\ndef get_inputs():\n    # JAX expects float32 by default\n    x = jax.random.uniform(\n        jax.random.PRNGKey(0),\n        (batch_size, in_channels, depth, height, width),\n        dtype=jnp.float32\n    )\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, min_value, divisor]"}
{"kb_id": "kb_level_2_0001", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0001.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0001_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, followed by max pooling, hardtanh activation, mean operation, and tanh activation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, maxpool_kernel_size, maxpool_stride, hardtanh_min, hardtanh_max):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n        self.maxpool = nn.MaxPool2d(kernel_size=maxpool_kernel_size, stride=maxpool_stride)\n        self.hardtanh = nn.Hardtanh(min_val=hardtanh_min, max_val=hardtanh_max)\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = self.maxpool(x)\n        x = self.hardtanh(x)\n        x = torch.mean(x, dim=(2, 3), keepdim=True)\n        x = torch.tanh(x)\n        return x\n\nbatch_size = 128\nin_channels  = 64  \nout_channels = 64  \nheight = width = 256  \nkernel_size  = 3\nstride = 1\npadding = 1\nmaxpool_kernel_size = 2\nmaxpool_stride = 2\nhardtanh_min = -1\nhardtanh_max = 1\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, maxpool_kernel_size, maxpool_stride, hardtanh_min, hardtanh_max]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, followed by max pooling, hardtanh activation, mean operation, and tanh activation.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    stride: int\n    padding: int\n    maxpool_kernel_size: int\n    maxpool_stride: int\n    hardtanh_min: float\n    hardtanh_max: float\n\n    @nn.compact\n    def __call__(self, x):\n        # ConvTranspose2d in Flax: use nn.ConvTranspose\n        x = nn.ConvTranspose(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size),\n            strides=(self.stride, self.stride),\n            padding=[(self.padding, self.padding), (self.padding, self.padding)],\n            use_bias=True,\n        )(x)\n        # MaxPool2d\n        x = nn.max_pool(\n            x,\n            window_shape=(self.maxpool_kernel_size, self.maxpool_kernel_size),\n            strides=(self.maxpool_stride, self.maxpool_stride),\n            padding='VALID'\n        )\n        # Hardtanh\n        x = jnp.clip(x, self.hardtanh_min, self.hardtanh_max)\n        # Mean over H and W (axes 2, 3), keepdim=True\n        x = jnp.mean(x, axis=(2, 3), keepdims=True)\n        # Tanh activation\n        x = jnp.tanh(x)\n        return x\n\nbatch_size = 128\nin_channels  = 64  \nout_channels = 64  \nheight = width = 256  \nkernel_size  = 3\nstride = 1\npadding = 1\nmaxpool_kernel_size = 2\nmaxpool_stride = 2\nhardtanh_min = -1\nhardtanh_max = 1\n\ndef get_inputs():\n    key = jax.random.PRNGKey(0)\n    x = jax.random.uniform(key, (batch_size, in_channels, height, width))\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, maxpool_kernel_size, maxpool_stride, hardtanh_min, hardtanh_max]"}
{"kb_id": "kb_level_2_0002", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.87364620938628, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0002.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0002_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, batch normalization, tanh activation, max pooling, and group normalization.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, groups, num_groups):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n        self.batch_norm = nn.BatchNorm2d(out_channels)\n        self.tanh = nn.Tanh()\n        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.group_norm = nn.GroupNorm(num_groups=num_groups, num_channels=out_channels)\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = self.batch_norm(x)\n        x = self.tanh(x)\n        x = self.max_pool(x)\n        x = self.group_norm(x)\n        return x\n\nbatch_size = 512\nin_channels  = 64  \nout_channels = 128  \nheight = width = 2048  \nkernel_size  = 5\nstride       = 1  \npadding      = 1\ngroups       = 8\nnum_groups   = 8\nheight, width = 32, 32\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, groups, num_groups]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, batch normalization, tanh activation, max pooling, and group normalization.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    stride: int\n    padding: int\n    groups: int\n    num_groups: int\n\n    @nn.compact\n    def __call__(self, x, train=True):\n        # ConvTranspose2d in PyTorch: (N, C_in, H, W) -> (N, C_out, H_out, W_out)\n        # Flax ConvTranspose: (N, H, W, C_in) -> (N, H_out, W_out, C_out)\n        # So we need to transpose input and output accordingly\n\n        # Move channels to last dimension\n        x = jnp.transpose(x, (0, 2, 3, 1))  # (N, H, W, C)\n\n        x = nn.ConvTranspose(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size),\n            strides=(self.stride, self.stride),\n            padding=[(self.padding, self.padding), (self.padding, self.padding)],\n            feature_group_count=1,  # PyTorch's groups param is not supported for ConvTranspose2d in Flax\n            use_bias=True,\n        )(x)\n\n        x = nn.BatchNorm(use_running_average=not train, axis=-1, momentum=0.9, epsilon=1e-5)(x)\n        x = jnp.tanh(x)\n        x = nn.max_pool(x, window_shape=(2, 2), strides=(2, 2), padding='VALID')\n        x = nn.GroupNorm(num_groups=self.num_groups, epsilon=1e-5, axis=-1)(x)\n\n        # Move channels back to (N, C, H, W)\n        x = jnp.transpose(x, (0, 3, 1, 2))\n        return x\n\nbatch_size = 512\nin_channels  = 64  \nout_channels = 128  \nheight = width = 32\nkernel_size  = 5\nstride       = 1  \npadding      = 1\ngroups       = 8\nnum_groups   = 8\n\ndef get_inputs():\n    # Return a list with a single input array, shape (batch_size, in_channels, height, width)\n    key = jax.random.PRNGKey(0)\n    x = jax.random.uniform(key, (batch_size, in_channels, height, width), minval=0.0, maxval=1.0)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, groups, num_groups]"}
{"kb_id": "kb_level_2_0003", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0003.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0003_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a Gemm, multiplies the result, and applies LeakyReLU.\n    \"\"\"\n    def __init__(self, in_features, out_features, multiplier, negative_slope):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.multiplier = multiplier\n        self.leaky_relu = nn.LeakyReLU(negative_slope)\n\n    def forward(self, x):\n        x = self.gemm(x)\n        x = x * self.multiplier\n        x = self.leaky_relu(x)\n        return x\n\nbatch_size = 1024\nin_features  = 8192  \nout_features = 8192\nmultiplier = 2.0\nnegative_slope = 0.1\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, multiplier, negative_slope]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a Gemm, multiplies the result, and applies LeakyReLU.\n    \"\"\"\n    in_features: int\n    out_features: int\n    multiplier: float\n    negative_slope: float\n\n    @nn.compact\n    def __call__(self, x):\n        x = nn.Dense(self.out_features)(x)\n        x = x * self.multiplier\n        x = jnp.where(x >= 0, x, self.negative_slope * x)\n        return x\n\nbatch_size = 1024\nin_features  = 8192  \nout_features = 8192\nmultiplier = 2.0\nnegative_slope = 0.1\n\ndef get_inputs():\n    key = jax.random.PRNGKey(0)\n    x = jax.random.uniform(key, (batch_size, in_features))\n    return [x]\n\ndef get_init_inputs():\n    return [in_features, out_features, multiplier, negative_slope]"}
{"kb_id": "kb_level_2_0004", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.49730700179532, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0004.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0004_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a series of operations:\n    1. Transposed 3D convolution\n    2. Mean pooling (across depth)\n    3. Addition\n    4. Softmax (across channels)\n    5. Tanh activation\n    6. Scaling\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, scaling_factor):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n        self.bias = nn.Parameter(torch.randn(1, out_channels, 1, 1, 1))  # Broadcastable bias over channels\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        x = self.conv_transpose(x)                            # (B, C, D, H, W)\n        x = x.mean(dim=2, keepdim=True)                       # Mean pool over depth dim (D)\n        x = x + self.bias                                     # Bias add per channel\n        x = torch.softmax(x, dim=1)                           # Softmax over channels\n        x = torch.tanh(x)                                     # Nonlinearity\n        x = x * self.scaling_factor                           # Scaling\n        return x\n\n# === Test config ===\nbatch_size = 16\nin_channels  = 16  \nout_channels = 64  \ndepth = 32; height = width = 128  \nkernel_size  = 3\nstride       = 1  \npadding = 1\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, scaling_factor]\n", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a series of operations:\n    1. Transposed 3D convolution\n    2. Mean pooling (across depth)\n    3. Addition\n    4. Softmax (across channels)\n    5. Tanh activation\n    6. Scaling\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    stride: int\n    padding: int\n    scaling_factor: float\n\n    @nn.compact\n    def __call__(self, x):\n        # Flax ConvTranspose3D expects (N, D, H, W, C), so we need to permute\n        # Input x is (B, C, D, H, W) -> (B, D, H, W, C)\n        x = jnp.transpose(x, (0, 2, 3, 4, 1))\n        conv_transpose = nn.ConvTranspose(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size, self.kernel_size),\n            strides=(self.stride, self.stride, self.stride),\n            padding=[(self.padding, self.padding)]*3,\n            feature_group_count=1,\n            use_bias=False,\n            dimension_numbers=('NDHWC', 'DHWIO', 'NDHWC'),\n        )\n        x = conv_transpose(x)  # (B, D, H, W, C_out)\n        # Mean pool over depth (axis=1)\n        x = jnp.mean(x, axis=1, keepdims=True)  # (B, 1, H, W, C_out)\n        # Bias: shape (1, 1, 1, 1, C_out), broadcastable\n        bias = self.param('bias', nn.initializers.normal(), (1, 1, 1, 1, self.out_channels))\n        x = x + bias\n        # Softmax over channels (last axis)\n        x = jax.nn.softmax(x, axis=-1)\n        # Tanh activation\n        x = jnp.tanh(x)\n        # Scaling\n        x = x * self.scaling_factor\n        # Return to (B, C, D, H, W) for compatibility if needed\n        x = jnp.transpose(x, (0, 4, 1, 2, 3))\n        return x\n\n# === Test config ===\nbatch_size = 16\nin_channels  = 16  \nout_channels = 64  \ndepth = 32\nheight = width = 128  \nkernel_size  = 3\nstride       = 1  \npadding = 1\nscaling_factor = 2.0\n\ndef get_inputs():\n    # Return a list with a single input array, shape (B, C, D, H, W)\n    key = jax.random.PRNGKey(0)\n    x = jax.random.uniform(key, (batch_size, in_channels, depth, height, width))\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, scaling_factor]"}
{"kb_id": "kb_level_2_0005", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0005.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0005_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a matrix multiplication, division, summation, and scaling.\n    \"\"\"\n    def __init__(self, input_size, hidden_size, scaling_factor):\n        super(Model, self).__init__()\n        self.weight = nn.Parameter(torch.randn(hidden_size, input_size))\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, input_size).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, hidden_size).\n        \"\"\"\n        x = torch.matmul(x, self.weight.T)  # Gemm\n        x = x / 2  # Divide\n        x = torch.sum(x, dim=1, keepdim=True) # Sum\n        x = x * self.scaling_factor  # Scaling\n        return x\n\n\nbatch_size   = 1024  \ninput_size   = 8192  \nhidden_size  = 8192 \nscaling_factor = 1.5\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, scaling_factor]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a matrix multiplication, division, summation, and scaling.\n    \"\"\"\n    input_size: int\n    hidden_size: int\n    scaling_factor: float\n\n    @nn.compact\n    def __call__(self, x):\n        \"\"\"\n        Args:\n            x (jnp.ndarray): Input tensor of shape (batch_size, input_size).\n        Returns:\n            jnp.ndarray: Output tensor of shape (batch_size, hidden_size).\n        \"\"\"\n        weight = self.param(\n            \"weight\",\n            jax.nn.initializers.normal(),\n            (self.hidden_size, self.input_size)\n        )\n        x = jnp.matmul(x, weight.T)  # Gemm\n        x = x / 2  # Divide\n        x = jnp.sum(x, axis=1, keepdims=True)  # Sum\n        x = x * self.scaling_factor  # Scaling\n        return x\n\nbatch_size   = 1024  \ninput_size   = 8192  \nhidden_size  = 8192 \nscaling_factor = 1.5\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, scaling_factor]"}
{"kb_id": "kb_level_2_0006", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0006.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0006_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A 3D convolutional transpose layer followed by Batch Normalization and subtraction.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bias=True):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, bias=bias)\n        self.batch_norm = nn.BatchNorm3d(out_channels)\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = self.batch_norm(x)\n        x = x - torch.mean(x, dim=(2, 3, 4), keepdim=True)  # Subtract mean along spatial dimensions\n        return x\n\nbatch_size = 16\nin_channels = 16\nout_channels = 32\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A 3D convolutional transpose layer followed by Batch Normalization and subtraction.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    stride: int\n    padding: int\n    bias: bool = True\n\n    @nn.compact\n    def __call__(self, x, train=True):\n        # Flax ConvTranspose3D expects (N, D, H, W, C), so we need to permute axes\n        # PyTorch: (N, C, D, H, W)\n        # Flax:    (N, D, H, W, C)\n        x = jnp.transpose(x, (0, 2, 3, 4, 1))\n        x = nn.ConvTranspose(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size, self.kernel_size),\n            strides=(self.stride, self.stride, self.stride),\n            padding=[(self.padding, self.padding)]*3,\n            use_bias=self.bias,\n            dimension_numbers=('NDHWC', 'DHWIO', 'NDHWC')\n        )(x)\n        x = nn.BatchNorm(use_running_average=not train, axis=-1, momentum=0.9, epsilon=1e-5)(x)\n        # Subtract mean along spatial dimensions (D, H, W)\n        mean = jnp.mean(x, axis=(1, 2, 3), keepdims=True)\n        x = x - mean\n        # Convert back to (N, C, D, H, W)\n        x = jnp.transpose(x, (0, 4, 1, 2, 3))\n        return x\n\nbatch_size = 16\nin_channels = 16\nout_channels = 32\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\n\ndef get_inputs():\n    # Return a list with a single input array, matching PyTorch's shape: (N, C, D, H, W)\n    key = jax.random.PRNGKey(0)\n    x = jax.random.uniform(key, (batch_size, in_channels, depth, height, width))\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding]"}
{"kb_id": "kb_level_2_0007", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.24865831842575, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0007.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0007_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, applies Mish activation, adds a value, \n    applies Hardtanh activation, and scales the output.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, add_value, scale):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, output_padding)\n        self.add_value = add_value\n        self.scale = scale\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = torch.nn.functional.mish(x) # Mish activation\n        x = x + self.add_value\n        x = torch.nn.functional.hardtanh(x, min_val=-1, max_val=1) # Hardtanh activation\n        x = x * self.scale # Scaling\n        return x\n\nbatch_size = 128\nin_channels  = 64  \nout_channels = 64  \nheight = width = 128  \nkernel_size  = 3\nstride       = 2  \npadding      = 1\noutput_padding = 1\nadd_value = 0.5\nscale = 2\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, add_value, scale]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, applies Mish activation, adds a value, \n    applies Hardtanh activation, and scales the output.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    stride: int\n    padding: int\n    output_padding: int\n    add_value: float\n    scale: float\n\n    @nn.compact\n    def __call__(self, x):\n        # Flax ConvTranspose uses (batch, height, width, channels) by default\n        # Input is (batch, channels, height, width), so we need to transpose\n        x = jnp.transpose(x, (0, 2, 3, 1))  # BCHW -> BHWC\n\n        conv_transpose = nn.ConvTranspose(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size),\n            strides=(self.stride, self.stride),\n            padding=[(self.padding, self.padding), (self.padding, self.padding)],\n            kernel_dilation=(1, 1),\n            use_bias=True,\n            name=\"conv_transpose\"\n        )\n        # Flax ConvTranspose does not have output_padding, so we manually pad if needed\n        x = conv_transpose(x)\n        # If output_padding > 0, pad the output accordingly\n        if self.output_padding > 0:\n            pad_h = (0, self.output_padding)\n            pad_w = (0, self.output_padding)\n            x = jnp.pad(x, ((0,0), pad_h, pad_w, (0,0)))\n\n        # Mish activation: x * tanh(softplus(x))\n        x = x * jnp.tanh(jax.nn.softplus(x))\n        x = x + self.add_value\n        # Hardtanh: clamp between -1 and 1\n        x = jnp.clip(x, a_min=-1.0, a_max=1.0)\n        x = x * self.scale\n\n        # Transpose back to (batch, channels, height, width)\n        x = jnp.transpose(x, (0, 3, 1, 2))\n        return x\n\nbatch_size = 128\nin_channels  = 64  \nout_channels = 64  \nheight = width = 128  \nkernel_size  = 3\nstride       = 2  \npadding      = 1\noutput_padding = 1\nadd_value = 0.5\nscale = 2\n\ndef get_inputs():\n    # Return a list with a single input array, shape (batch, channels, height, width)\n    key = jax.random.PRNGKey(0)\n    x = jax.random.uniform(key, (batch_size, in_channels, height, width), minval=0.0, maxval=1.0)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, add_value, scale]"}
{"kb_id": "kb_level_2_0008", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 68.15140845070424, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0008.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0008_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, applies Instance Normalization, and divides by a constant.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, divide_by):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.instance_norm = nn.InstanceNorm2d(out_channels)\n        self.divide_by = divide_by\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.instance_norm(x)\n        x = x / self.divide_by\n        return x\n\nbatch_size = 128\nin_channels  = 64  \nout_channels = 128  \nheight = width = 128  \nkernel_size = 3\ndivide_by = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, divide_by]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, applies Instance Normalization, and divides by a constant.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    divide_by: float\n\n    @nn.compact\n    def __call__(self, x):\n        x = nn.Conv(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size),\n            use_bias=True\n        )(x)\n        x = nn.InstanceNorm()(x)\n        x = x / self.divide_by\n        return x\n\nbatch_size = 128\nin_channels  = 64  \nout_channels = 128  \nheight = width = 128  \nkernel_size = 3\ndivide_by = 2.0\n\ndef get_inputs():\n    key = jax.random.PRNGKey(0)\n    x = jax.random.uniform(key, (batch_size, in_channels, height, width))\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, divide_by]"}
{"kb_id": "kb_level_2_0009", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0009.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0009_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a sequence of operations:\n        - Matrix multiplication\n        - Summation\n        - Max\n        - Average pooling\n        - LogSumExp\n        - LogSumExp\n    \"\"\"\n    def __init__(self, in_features, out_features):\n        super(Model, self).__init__()\n        self.linear = nn.Linear(in_features, out_features)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, 1).\n        \"\"\"\n        x = self.linear(x)  # (batch_size, out_features)\n        x = torch.sum(x, dim=1, keepdim=True) # (batch_size, 1)\n        x = torch.max(x, dim=1, keepdim=True)[0] # (batch_size, 1)\n        x = torch.mean(x, dim=1, keepdim=True) # (batch_size, 1)\n        x = torch.logsumexp(x, dim=1, keepdim=True) # (batch_size, 1)\n        x = torch.logsumexp(x, dim=1, keepdim=True) # (batch_size, 1)\n        return x\n\nbatch_size = 1024\nin_features  = 8192  \nout_features = 8192\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a sequence of operations:\n        - Matrix multiplication\n        - Summation\n        - Max\n        - Average pooling\n        - LogSumExp\n        - LogSumExp\n    \"\"\"\n    in_features: int\n    out_features: int\n\n    @nn.compact\n    def __call__(self, x):\n        \"\"\"\n        Args:\n            x (jnp.ndarray): Input tensor of shape (batch_size, in_features).\n        Returns:\n            jnp.ndarray: Output tensor of shape (batch_size, 1).\n        \"\"\"\n        x = nn.Dense(self.out_features)(x)  # (batch_size, out_features)\n        x = jnp.sum(x, axis=1, keepdims=True)  # (batch_size, 1)\n        x = jnp.max(x, axis=1, keepdims=True)  # (batch_size, 1)\n        x = jnp.mean(x, axis=1, keepdims=True)  # (batch_size, 1)\n        x = jax.scipy.special.logsumexp(x, axis=1, keepdims=True)  # (batch_size, 1)\n        x = jax.scipy.special.logsumexp(x, axis=1, keepdims=True)  # (batch_size, 1)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]"}
{"kb_id": "kb_level_2_0010", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0010.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0010_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, applies GELU, and normalizes with GroupNorm.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, groups, num_groups):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride)\n        self.group_norm = nn.GroupNorm(num_groups=num_groups, num_channels=out_channels)\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = torch.nn.functional.gelu(x)\n        x = self.group_norm(x)\n        return x\n\nbatch_size   = 128  \nin_channels  = 64  \nout_channels = 64  \nheight = width = 256  \nkernel_size  = 3\nstride       = 1\ngroups = 8\nnum_groups = 8\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, groups, num_groups]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, applies GELU, and normalizes with GroupNorm.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    stride: int\n    groups: int\n    num_groups: int\n\n    @nn.compact\n    def __call__(self, x):\n        # Flax ConvTranspose uses (batch, height, width, channels), so we need to transpose\n        # Input: (N, C, H, W) -> (N, H, W, C)\n        x = jnp.transpose(x, (0, 2, 3, 1))\n        x = nn.ConvTranspose(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size),\n            strides=(self.stride, self.stride),\n            use_bias=True,\n            feature_group_count=1,  # PyTorch's groups param is not directly supported for ConvTranspose2d in Flax\n            padding='SAME'\n        )(x)\n        x = nn.gelu(x)\n        x = nn.GroupNorm(num_groups=self.num_groups, epsilon=1e-5)(x)\n        # Output: (N, H, W, C) -> (N, C, H, W)\n        x = jnp.transpose(x, (0, 3, 1, 2))\n        return x\n\nbatch_size   = 128  \nin_channels  = 64  \nout_channels = 64  \nheight = width = 256  \nkernel_size  = 3\nstride       = 1\ngroups = 8\nnum_groups = 8\n\ndef get_inputs():\n    # Return a list with a single input array, shape (batch, channels, height, width)\n    key = jax.random.PRNGKey(0)\n    x = jax.random.uniform(key, (batch_size, in_channels, height, width), dtype=jnp.float32)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, groups, num_groups]"}
{"kb_id": "kb_level_2_0011", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0011.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0011_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, applies ReLU, and adds a bias term.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, bias_shape):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.bias = nn.Parameter(torch.randn(bias_shape)) \n\n    def forward(self, x):\n        x = self.conv(x)\n        x = torch.relu(x)\n        x = x + self.bias\n        return x\n\nbatch_size = 128\nin_channels  = 64  \nout_channels = 128  \nheight = width = 128\nkernel_size = 3\nbias_shape = (out_channels, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, bias_shape]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, applies ReLU, and adds a bias term.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    bias_shape: tuple\n\n    @nn.compact\n    def __call__(self, x):\n        x = nn.Conv(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size),\n            use_bias=False,\n            padding='VALID'\n        )(x)\n        x = jax.nn.relu(x)\n        bias = self.param('bias', nn.initializers.normal(), self.bias_shape)\n        x = x + bias\n        return x\n\nbatch_size = 128\nin_channels  = 64  \nout_channels = 128  \nheight = width = 128\nkernel_size = 3\nbias_shape = (out_channels, 1, 1)\n\ndef get_inputs():\n    # Flax expects NHWC by default, but we use NCHW to match PyTorch, so set data_format in Conv if needed.\n    # Here, we use NCHW to match the original.\n    return [jnp.random.rand(batch_size, in_channels, height, width).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, bias_shape]"}
{"kb_id": "kb_level_2_0012", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.74774774774775, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0012.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0012_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, followed by a sum, \n    a residual add, a multiplication, and another residual add.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        original_x = x.clone().detach()\n        x = x + self.bias\n        x = x + original_x\n        x = x * original_x\n        x = x + original_x\n        return x\n\nbatch_size = 16\nin_channels = 32\nout_channels = 64\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\nbias_shape = (out_channels, 1, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, followed by a sum, \n    a residual add, a multiplication, and another residual add.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    stride: int\n    padding: int\n    output_padding: int\n    bias_shape: tuple\n\n    @nn.compact\n    def __call__(self, x):\n        # Flax ConvTranspose3D expects (N, D, H, W, C), so we need to permute\n        # Input x is (N, C, D, H, W) -> (N, D, H, W, C)\n        x = jnp.transpose(x, (0, 2, 3, 4, 1))\n        conv_transpose = nn.ConvTranspose(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size, self.kernel_size),\n            strides=(self.stride, self.stride, self.stride),\n            padding=[(self.padding, self.padding)]*3,\n            use_bias=False,\n            dimension_numbers=('NDHWC', 'DHWIO', 'NDHWC'),\n        )\n        x = conv_transpose(x)\n        # output_padding is not directly supported in Flax, so we manually pad if needed\n        if self.output_padding != 0:\n            pad = self.output_padding\n            x = jnp.pad(x, ((0,0), (0,pad), (0,pad), (0,pad), (0,0)))\n        original_x = jnp.array(x)\n        bias = self.param('bias', nn.initializers.normal(), self.bias_shape)\n        # bias shape: (out_channels, 1, 1, 1), need to broadcast to (N, D, H, W, C)\n        # Flax output: (N, D, H, W, C), bias: (C, 1, 1, 1)\n        # So reshape bias to (1, 1, 1, 1, C) and broadcast\n        bias_broadcast = bias.reshape((1, 1, 1, 1, -1))\n        x = x + bias_broadcast\n        x = x + original_x\n        x = x * original_x\n        x = x + original_x\n        # Return to (N, C, D, H, W)\n        x = jnp.transpose(x, (0, 4, 1, 2, 3))\n        return x\n\nbatch_size = 16\nin_channels = 32\nout_channels = 64\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\nbias_shape = (out_channels, 1, 1, 1)\n\ndef get_inputs():\n    # Return a list with a single input array, shape (batch_size, in_channels, depth, height, width)\n    key = jax.random.PRNGKey(0)\n    x = jax.random.uniform(key, (batch_size, in_channels, depth, height, width))\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape]"}
{"kb_id": "kb_level_2_0013", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0013.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0013_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a convolution, adds a bias term, scales, applies sigmoid, and performs group normalization.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, num_groups, bias_shape, scale_shape):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.bias = nn.Parameter(torch.randn(bias_shape)) \n        self.scale = nn.Parameter(torch.randn(scale_shape))\n        self.group_norm = nn.GroupNorm(num_groups, out_channels)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x + self.bias\n        x = x * self.scale\n        x = torch.sigmoid(x)\n        x = self.group_norm(x)\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 32\nheight = width = 256\nkernel_size = 3\nnum_groups = 8\nbias_shape = (out_channels, 1, 1)\nscale_shape = (out_channels, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, num_groups, bias_shape, scale_shape]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a convolution, adds a bias term, scales, applies sigmoid, and performs group normalization.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    num_groups: int\n    bias_shape: tuple\n    scale_shape: tuple\n\n    @nn.compact\n    def __call__(self, x):\n        x = nn.Conv(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size),\n            use_bias=False,\n            padding='SAME'\n        )(x)\n        bias = self.param('bias', nn.initializers.normal(), self.bias_shape)\n        scale = self.param('scale', nn.initializers.normal(), self.scale_shape)\n        x = x + bias\n        x = x * scale\n        x = jax.nn.sigmoid(x)\n        x = nn.GroupNorm(num_groups=self.num_groups, epsilon=1e-5)(x)\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 32\nheight = width = 256\nkernel_size = 3\nnum_groups = 8\nbias_shape = (out_channels, 1, 1)\nscale_shape = (out_channels, 1, 1)\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, in_channels, height, width).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, num_groups, bias_shape, scale_shape]"}
{"kb_id": "kb_level_2_0014", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.37275985663082, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0014.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0014_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a matrix multiplication, scales the result, adds a residual connection, clamps the output,\n    applies LogSumExp, and finally applies the Mish activation function.\n    \"\"\"\n    def __init__(self, input_size, hidden_size, scale_factor, clamp_min, clamp_max):\n        super(Model, self).__init__()\n        self.matmul = nn.Linear(input_size, hidden_size)\n        self.scale_factor = scale_factor\n        self.clamp_min = clamp_min\n        self.clamp_max = clamp_max\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x: Input tensor of shape (batch_size, input_size).\n\n        Returns:\n            Output tensor of shape (batch_size, hidden_size).\n        \"\"\"\n        x = self.matmul(x)\n        x = x * self.scale_factor\n        x = x + x\n        x = torch.clamp(x, self.clamp_min, self.clamp_max)\n        x = torch.logsumexp(x, dim=1, keepdim=True)\n        x = x * torch.nn.functional.mish(x)  # Mish activation\n        return x\n\nbatch_size = 1024\ninput_size = 8192\nhidden_size = 8192\nscale_factor = 2.0\nclamp_min = -10.0\nclamp_max = 10.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, scale_factor, clamp_min, clamp_max]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a matrix multiplication, scales the result, adds a residual connection, clamps the output,\n    applies LogSumExp, and finally applies the Mish activation function.\n    \"\"\"\n    input_size: int\n    hidden_size: int\n    scale_factor: float\n    clamp_min: float\n    clamp_max: float\n\n    @nn.compact\n    def __call__(self, x):\n        \"\"\"\n        Args:\n            x: Input tensor of shape (batch_size, input_size).\n\n        Returns:\n            Output tensor of shape (batch_size, hidden_size).\n        \"\"\"\n        x = nn.Dense(self.hidden_size)(x)\n        x = x * self.scale_factor\n        x = x + x\n        x = jnp.clip(x, self.clamp_min, self.clamp_max)\n        x = jax.nn.logsumexp(x, axis=1, keepdims=True)\n        x = x * mish(x)\n        return x\n\ndef mish(x):\n    return x * jnp.tanh(jax.nn.softplus(x))\n\nbatch_size = 1024\ninput_size = 8192\nhidden_size = 8192\nscale_factor = 2.0\nclamp_min = -10.0\nclamp_max = 10.0\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, input_size).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, scale_factor, clamp_min, clamp_max]"}
{"kb_id": "kb_level_2_0015", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0015.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0015_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, applies Group Normalization, computes the mean\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, num_groups):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size)\n        self.group_norm = nn.GroupNorm(num_groups, out_channels)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, D, H, W).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, 1).\n        \"\"\"\n        x = self.conv(x)\n        x = self.group_norm(x)\n        x = x.mean(dim=[1, 2, 3, 4]) # Compute mean across all dimensions except batch\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 24\nD, H, W = 24, 32, 32\nkernel_size = 3\nnum_groups = 8\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, D, H, W)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, num_groups]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, applies Group Normalization, computes the mean\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    num_groups: int\n\n    @nn.compact\n    def __call__(self, x):\n        # x: (batch_size, in_channels, D, H, W)\n        x = nn.Conv(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size, self.kernel_size),\n            strides=(1, 1, 1),\n            padding='SAME',\n            use_bias=True\n        )(x)\n        x = nn.GroupNorm(\n            num_groups=self.num_groups,\n            epsilon=1e-5,\n            use_bias=True,\n            use_scale=True\n        )(x)\n        # Compute mean across all dimensions except batch\n        x = jnp.mean(x, axis=(1, 2, 3, 4))\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 24\nD, H, W = 24, 32, 32\nkernel_size = 3\nnum_groups = 8\n\ndef get_inputs():\n    # Returns a list with a single input array of shape (batch_size, in_channels, D, H, W)\n    key = jax.random.PRNGKey(0)\n    x = jax.random.uniform(key, (batch_size, in_channels, D, H, W), minval=0.0, maxval=1.0)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, num_groups]"}
{"kb_id": "kb_level_2_0016", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 67.67482517482519, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0016.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0016_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a 3D convolution, applies minimum operation along a specific dimension, \n    and then applies softmax.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, dim):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size)\n        self.dim = dim\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, D, H, W)\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, H, W)\n        \"\"\"\n        x = self.conv(x)\n        x = torch.min(x, dim=self.dim)[0]  # Apply minimum along the specified dimension\n        x = torch.softmax(x, dim=1)  # Apply softmax along the channel dimension\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 24  # Increased output channels\nD, H, W = 24, 32, 32  # Increased depth\nkernel_size = 3\ndim = 2  # Dimension along which to apply minimum operation (e.g., depth)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, D, H, W)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, dim]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a 3D convolution, applies minimum operation along a specific dimension, \n    and then applies softmax.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    dim: int\n\n    @nn.compact\n    def __call__(self, x):\n        \"\"\"\n        Args:\n            x (jnp.ndarray): Input tensor of shape (batch_size, in_channels, D, H, W)\n        Returns:\n            jnp.ndarray: Output tensor of shape (batch_size, out_channels, H, W)\n        \"\"\"\n        # Flax Conv3D expects (batch, D, H, W, C), so we need to permute axes\n        # PyTorch: (N, C, D, H, W) -> Flax: (N, D, H, W, C)\n        x = jnp.transpose(x, (0, 2, 3, 4, 1))\n        x = nn.Conv(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size, self.kernel_size),\n            strides=(1, 1, 1),\n            padding='VALID',\n            use_bias=True,\n        )(x)\n        # Output is (N, D', H', W', out_channels)\n        # Transpose back to (N, out_channels, D', H', W') for min/softmax logic\n        x = jnp.transpose(x, (0, 4, 1, 2, 3))\n        # Apply minimum along the specified dimension\n        x = jnp.min(x, axis=self.dim)\n        # x shape: (N, out_channels, H', W') if dim=2 (D')\n        # Apply softmax along channel dimension (axis=1)\n        x = jax.nn.softmax(x, axis=1)\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 24\nD, H, W = 24, 32, 32\nkernel_size = 3\ndim = 2  # Dimension along which to apply minimum operation (e.g., depth)\n\ndef get_inputs():\n    # Return a list with a single input array of shape (batch_size, in_channels, D, H, W)\n    return [jnp.random.rand(batch_size, in_channels, D, H, W).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, dim]"}
{"kb_id": "kb_level_2_0017", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0017.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0017_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a convolution, applies minimum operation, Tanh, and another Tanh.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = torch.min(x, dim=1, keepdim=True)[0] # Apply minimum operation along the channel dimension\n        x = torch.tanh(x)\n        x = torch.tanh(x)\n        return x\n\nbatch_size = 128\nin_channels = 16\nout_channels = 64\nheight = width = 256\nkernel_size = 3\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a convolution, applies minimum operation, Tanh, and another Tanh.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n\n    @nn.compact\n    def __call__(self, x):\n        # Flax Conv expects (N, H, W, C), so we need to transpose\n        x = jnp.transpose(x, (0, 2, 3, 1))  # (N, H, W, C)\n        x = nn.Conv(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size),\n            strides=(1, 1),\n            padding='SAME',\n            use_bias=True,\n        )(x)\n        # After conv: (N, H, W, out_channels)\n        # Min along channel dimension (axis=-1)\n        x = jnp.min(x, axis=-1, keepdims=True)  # (N, H, W, 1)\n        x = jnp.tanh(x)\n        x = jnp.tanh(x)\n        # Transpose back to (N, 1, H, W)\n        x = jnp.transpose(x, (0, 3, 1, 2))\n        return x\n\nbatch_size = 128\nin_channels = 16\nout_channels = 64\nheight = width = 256\nkernel_size = 3\n\ndef get_inputs():\n    # Return a list with a single input array, shape (batch_size, in_channels, height, width)\n    key = jax.random.PRNGKey(0)\n    x = jax.random.uniform(key, (batch_size, in_channels, height, width))\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]"}
{"kb_id": "kb_level_2_0018", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.37275985663082, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0018.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0018_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, adds an input tensor, and applies HardSwish activation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n\n    def forward(self, x, add_input):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, D, H, W).\n            add_input (torch.Tensor): Input tensor to be added after transposed convolution, of shape (batch_size, out_channels, D, H, W).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, D, H, W) after HardSwish activation.\n        \"\"\"\n        x = self.conv_transpose(x)\n        x = x + add_input\n        x = x * torch.nn.functional.hardswish(x)\n        return x\n\n\nbatch_size = 128\nin_channels = 32\nout_channels = 64\nD, H, W = 16, 16, 16\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\nbias_shape = (out_channels, 1, 1, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, D, H, W), torch.rand(batch_size, out_channels, D*stride, H*stride, W*stride)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, adds an input tensor, and applies HardSwish activation.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    stride: int\n    padding: int\n    output_padding: int\n    bias_shape: tuple\n\n    @nn.compact\n    def __call__(self, x, add_input):\n        # Flax ConvTranspose3D expects (N, D, H, W, C), so we need to permute axes\n        # PyTorch: (N, C, D, H, W)\n        # JAX/Flax: (N, D, H, W, C)\n        x = jnp.transpose(x, (0, 2, 3, 4, 1))\n        add_input = jnp.transpose(add_input, (0, 2, 3, 4, 1))\n\n        conv_transpose = nn.ConvTranspose(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size, self.kernel_size),\n            strides=(self.stride, self.stride, self.stride),\n            padding=[(self.padding, self.padding)] * 3,\n            use_bias=False,\n            dimension_numbers=('NDHWC', 'DHWIO', 'NDHWC'),\n            transpose_kernel=True,\n        )\n        x = conv_transpose(x)\n\n        # Output padding: manually crop if needed\n        # Flax ConvTranspose does not have output_padding, so we crop to match add_input shape\n        if x.shape != add_input.shape:\n            # Crop x to match add_input shape\n            crop_d = x.shape[1] - add_input.shape[1]\n            crop_h = x.shape[2] - add_input.shape[2]\n            crop_w = x.shape[3] - add_input.shape[3]\n            x = x[:, \n                  (crop_d // 2):(x.shape[1] - (crop_d - crop_d // 2)),\n                  (crop_h // 2):(x.shape[2] - (crop_h - crop_h // 2)),\n                  (crop_w // 2):(x.shape[3] - (crop_w - crop_w // 2)),\n                  :\n            ]\n\n        # Add bias\n        bias = self.param('bias', nn.initializers.normal(), self.bias_shape)\n        # bias_shape: (out_channels, 1, 1, 1, 1) in PyTorch (C,1,1,1,1)\n        # In JAX: (C,1,1,1,1) but we need to broadcast to (N, D, H, W, C)\n        # So we reshape to (1,1,1,1,C) and add\n        bias = jnp.reshape(bias, (1, 1, 1, 1, self.out_channels))\n        x = x + bias\n\n        x = x + add_input\n\n        # HardSwish: x * relu6(x + 3) / 6\n        def hardswish(x):\n            return x * jnp.clip(x + 3, 0, 6) / 6\n\n        x = x * hardswish(x)\n\n        # Transpose back to (N, C, D, H, W)\n        x = jnp.transpose(x, (0, 4, 1, 2, 3))\n        return x\n\nbatch_size = 128\nin_channels = 32\nout_channels = 64\nD, H, W = 16, 16, 16\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\nbias_shape = (out_channels, 1, 1, 1, 1)\n\ndef get_inputs():\n    # JAX uses numpy arrays, not torch tensors\n    x = jnp.random.rand(batch_size, in_channels, D, H, W)\n    add_input = jnp.random.rand(batch_size, out_channels, D*stride, H*stride, W*stride)\n    return [x, add_input]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape]"}
{"kb_id": "kb_level_2_0019", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0019.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0019_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs:\n    1. Conv3D\n    2. HardSwish activation\n    3. GroupNorm  \n    4. Mean pooling across spatial dimensions\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, num_groups=4, bias=True):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size, bias=bias)\n        self.group_norm = nn.GroupNorm(num_groups, out_channels)\n\n    def forward(self, x):\n        x = self.conv(x)                             # (B, C, D, H, W)\n        x = F.hardswish(x)                           # Nonlinear activation\n        x = self.group_norm(x)                       # Normalization over channels\n        x = torch.mean(x, dim=[2, 3, 4])             # Mean over spatial dims \u2192 (B, C)\n        return x\n\n# === Test config ===\nbatch_size = 1024\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 4\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass GroupNorm3D(nn.Module):\n    num_groups: int\n    num_channels: int\n    eps: float = 1e-5\n\n    @nn.compact\n    def __call__(self, x):\n        # x: (B, C, D, H, W)\n        B, C, D, H, W = x.shape\n        assert C == self.num_channels\n        assert C % self.num_groups == 0, \"num_channels must be divisible by num_groups\"\n        G = self.num_groups\n        x = x.reshape(B, G, C // G, D, H, W)\n        mean = jnp.mean(x, axis=(2, 3, 4, 5), keepdims=True)\n        var = jnp.var(x, axis=(2, 3, 4, 5), keepdims=True)\n        x = (x - mean) / jnp.sqrt(var + self.eps)\n        x = x.reshape(B, C, D, H, W)\n        gamma = self.param('gamma', nn.initializers.ones, (1, C, 1, 1, 1))\n        beta = self.param('beta', nn.initializers.zeros, (1, C, 1, 1, 1))\n        return x * gamma + beta\n\ndef hardswish(x):\n    return x * jnp.clip(x + 3, 0, 6) / 6\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs:\n    1. Conv3D\n    2. HardSwish activation\n    3. GroupNorm  \n    4. Mean pooling across spatial dimensions\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    num_groups: int = 4\n    bias: bool = True\n\n    @nn.compact\n    def __call__(self, x):\n        # x: (B, C, D, H, W)\n        x = nn.Conv(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size, self.kernel_size),\n            strides=(1, 1, 1),\n            use_bias=self.bias,\n            padding='VALID'\n        )(x)\n        x = hardswish(x)\n        x = GroupNorm3D(self.num_groups, self.out_channels)(x)\n        x = jnp.mean(x, axis=(2, 3, 4))  # Mean over D, H, W -> (B, C)\n        return x\n\n# === Test config ===\nbatch_size = 1024\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 4\n\ndef get_inputs():\n    key = jax.random.PRNGKey(0)\n    x = jax.random.uniform(\n        key,\n        (batch_size, in_channels, depth, height, width),\n        minval=0.0,\n        maxval=1.0\n    )\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]"}
{"kb_id": "kb_level_2_0020", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0020.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0020_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a batch matrix multiplication, instance normalization, summation, residual addition, and multiplication.\n    \"\"\"\n    def __init__(self, in_features, out_features, eps=1e-5, momentum=0.1):\n        super(Model, self).__init__()\n        self.bmm = nn.Linear(in_features, out_features)\n        self.instance_norm = nn.InstanceNorm2d(out_features, eps=eps, momentum=momentum)\n\n    def forward(self, x, y):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n            y (torch.Tensor): Input tensor of shape (batch_size, out_features).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.bmm(x)\n        x = self.instance_norm(x.unsqueeze(1).unsqueeze(1)).squeeze(1).squeeze(1)\n        x = x + y\n        x = x * y\n        return x\n\nbatch_size = 1024  # Increased batch size\nin_features = 8192  # Increased input features\nout_features = 8192  # Increased output features\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features), torch.rand(batch_size, out_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass InstanceNorm2d(nn.Module):\n    num_features: int\n    eps: float = 1e-5\n\n    @nn.compact\n    def __call__(self, x):\n        # x: (batch, 1, 1, num_features)\n        mean = jnp.mean(x, axis=(1, 2), keepdims=True)\n        var = jnp.var(x, axis=(1, 2), keepdims=True)\n        x_norm = (x - mean) / jnp.sqrt(var + self.eps)\n        gamma = self.param('gamma', nn.initializers.ones, (1, 1, 1, self.num_features))\n        beta = self.param('beta', nn.initializers.zeros, (1, 1, 1, self.num_features))\n        return x_norm * gamma + beta\n\nclass Model(nn.Module):\n    in_features: int\n    out_features: int\n    eps: float = 1e-5\n\n    def setup(self):\n        self.bmm = nn.Dense(self.out_features)\n        self.instance_norm = InstanceNorm2d(self.out_features, eps=self.eps)\n\n    def __call__(self, x, y):\n        # x: (batch_size, in_features)\n        # y: (batch_size, out_features)\n        x = self.bmm(x)  # (batch_size, out_features)\n        x = x[:, None, None, :]  # (batch_size, 1, 1, out_features)\n        x = self.instance_norm(x)  # (batch_size, 1, 1, out_features)\n        x = x.squeeze(axis=(1, 2))  # (batch_size, out_features)\n        x = x + y\n        x = x * y\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\n\ndef get_inputs():\n    key1, key2 = jax.random.split(jax.random.PRNGKey(0))\n    x = jax.random.uniform(key1, (batch_size, in_features))\n    y = jax.random.uniform(key2, (batch_size, out_features))\n    return [x, y]\n\ndef get_init_inputs():\n    return [in_features, out_features]"}
{"kb_id": "kb_level_2_0021", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0021.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0021_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, applies Mish, and applies Mish again.\n    \"\"\"\n    def __init__(self, in_features, out_features):\n        super(Model, self).__init__()\n        self.linear = nn.Linear(in_features, out_features)\n\n    def forward(self, x):\n        x = self.linear(x)\n        x = torch.nn.functional.mish(x)\n        x = torch.nn.functional.mish(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\ndef mish(x):\n    return x * jnp.tanh(jax.nn.softplus(x))\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, applies Mish, and applies Mish again.\n    \"\"\"\n    in_features: int\n    out_features: int\n\n    @nn.compact\n    def __call__(self, x):\n        x = nn.Dense(self.out_features)(x)\n        x = mish(x)\n        x = mish(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]"}
{"kb_id": "kb_level_2_0022", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0022.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0022_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, adds a bias term, clamps, scales, clamps, and divides.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape, scaling_factor):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.bias = nn.Parameter(torch.randn(bias_shape)) \n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = x + self.bias\n        x = torch.clamp(x, min=0.0, max=1.0)\n        x = x * self.scaling_factor\n        x = torch.clamp(x, min=0.0, max=1.0)\n        x = x / self.scaling_factor\n        return x\n\nbatch_size = 128\nin_channels  = 64  \nout_channels = 64  \nheight = width = 128 \nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\nbias_shape = (out_channels, 1, 1)\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape, scaling_factor]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, adds a bias term, clamps, scales, clamps, and divides.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    stride: int\n    padding: int\n    output_padding: int\n    bias_shape: tuple\n    scaling_factor: float\n\n    @nn.compact\n    def __call__(self, x):\n        # Flax ConvTranspose uses (batch, height, width, channels) by default\n        # Input is (batch, in_channels, height, width) in PyTorch, so we need to transpose\n        x = jnp.transpose(x, (0, 2, 3, 1))  # to (batch, height, width, channels)\n        conv_transpose = nn.ConvTranspose(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size),\n            strides=(self.stride, self.stride),\n            padding=[(self.padding, self.padding), (self.padding, self.padding)],\n            kernel_init=nn.initializers.lecun_normal(),\n            use_bias=False,\n        )\n        x = conv_transpose(x)\n        # Output shape: (batch, new_height, new_width, out_channels)\n        # Add bias: shape (out_channels, 1, 1) in PyTorch, so (1, 1, 1, out_channels) in Flax\n        bias = self.param('bias', nn.initializers.normal(), (1, 1, 1, self.out_channels))\n        x = x + bias\n        x = jnp.clip(x, a_min=0.0, a_max=1.0)\n        x = x * self.scaling_factor\n        x = jnp.clip(x, a_min=0.0, a_max=1.0)\n        x = x / self.scaling_factor\n        # Transpose back to (batch, channels, height, width)\n        x = jnp.transpose(x, (0, 3, 1, 2))\n        return x\n\nbatch_size = 128\nin_channels  = 64  \nout_channels = 64  \nheight = width = 128 \nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\nbias_shape = (out_channels, 1, 1)\nscaling_factor = 2.0\n\ndef get_inputs():\n    # Return a list with a single JAX array of shape (batch, in_channels, height, width)\n    return [jnp.random.rand(batch_size, in_channels, height, width).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape, scaling_factor]"}
{"kb_id": "kb_level_2_0023", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0023.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0023_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a GEMM, applies Group Normalization, and then HardTanh.\n    \"\"\"\n    def __init__(self, in_features, out_features, num_groups, hardtanh_min, hardtanh_max):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.group_norm = nn.GroupNorm(num_groups, out_features)\n        self.hardtanh = nn.Hardtanh(min_val=hardtanh_min, max_val=hardtanh_max)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.gemm(x)\n        x = self.group_norm(x)\n        x = self.hardtanh(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nnum_groups = 16\nhardtanh_min = -2.0\nhardtanh_max = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, num_groups, hardtanh_min, hardtanh_max]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass GroupNorm(nn.Module):\n    num_groups: int\n    num_channels: int\n    eps: float = 1e-5\n    use_bias: bool = True\n    use_scale: bool = True\n\n    @nn.compact\n    def __call__(self, x):\n        # x: (batch, features)\n        # Reshape to (batch, num_groups, group_size)\n        assert x.shape[-1] == self.num_channels\n        group_size = self.num_channels // self.num_groups\n        assert self.num_channels % self.num_groups == 0\n        orig_shape = x.shape\n        x = x.reshape(x.shape[0], self.num_groups, group_size)\n        mean = jnp.mean(x, axis=(2,), keepdims=True)\n        var = jnp.var(x, axis=(2,), keepdims=True)\n        x = (x - mean) / jnp.sqrt(var + self.eps)\n        x = x.reshape(orig_shape)\n        if self.use_scale:\n            gamma = self.param('gamma', nn.initializers.ones, (self.num_channels,))\n            x = x * gamma\n        if self.use_bias:\n            beta = self.param('beta', nn.initializers.zeros, (self.num_channels,))\n            x = x + beta\n        return x\n\nclass Model(nn.Module):\n    in_features: int\n    out_features: int\n    num_groups: int\n    hardtanh_min: float\n    hardtanh_max: float\n\n    @nn.compact\n    def __call__(self, x):\n        x = nn.Dense(self.out_features)(x)\n        x = GroupNorm(self.num_groups, self.out_features)(x)\n        x = jnp.clip(x, self.hardtanh_min, self.hardtanh_max)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nnum_groups = 16\nhardtanh_min = -2.0\nhardtanh_max = 2.0\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, in_features).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [in_features, out_features, num_groups, hardtanh_min, hardtanh_max]"}
{"kb_id": "kb_level_2_0024", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0024.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0024_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, takes the minimum with a constant, adds a bias term, and multiplies by a scaling factor.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, constant_value, bias_shape, scaling_factor):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.constant_value = constant_value\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = torch.min(x, torch.tensor(self.constant_value))\n        x = x + self.bias\n        x = x * self.scaling_factor\n        return x\n\nbatch_size = 128\nin_channels = 64\nout_channels = 128\nheight = width = 128\nkernel_size = 3\nconstant_value = 0.5\nbias_shape = (out_channels, 1, 1)\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, constant_value, bias_shape, scaling_factor]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, takes the minimum with a constant, adds a bias term, and multiplies by a scaling factor.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    constant_value: float\n    bias_shape: tuple\n    scaling_factor: float\n\n    @nn.compact\n    def __call__(self, x):\n        conv = nn.Conv(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size),\n            use_bias=False,\n        )\n        x = conv(x)\n        x = jnp.minimum(x, self.constant_value)\n        bias = self.param('bias', nn.initializers.normal(), self.bias_shape)\n        x = x + bias\n        x = x * self.scaling_factor\n        return x\n\nbatch_size = 128\nin_channels = 64\nout_channels = 128\nheight = width = 128\nkernel_size = 3\nconstant_value = 0.5\nbias_shape = (out_channels, 1, 1)\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, in_channels, height, width).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, constant_value, bias_shape, scaling_factor]"}
{"kb_id": "kb_level_2_0025", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.37275985663082, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0025.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0025_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a convolution, scales the output, and then applies a minimum operation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, scale_factor):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.scale_factor = scale_factor\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height, width).\n        \"\"\"\n        x = self.conv(x)\n        x = x * self.scale_factor\n        x = torch.min(x, dim=1, keepdim=True)[0]  # Minimum along channel dimension\n        return x\n\nbatch_size = 64\nin_channels = 64\nout_channels = 128\nheight = width = 256\nkernel_size = 3\nscale_factor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, scale_factor]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a convolution, scales the output, and then applies a minimum operation.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    scale_factor: float\n\n    @nn.compact\n    def __call__(self, x):\n        \"\"\"\n        Args:\n            x (jnp.ndarray): Input tensor of shape (batch_size, in_channels, height, width).\n        Returns:\n            jnp.ndarray: Output tensor of shape (batch_size, out_channels, height, width).\n        \"\"\"\n        # Flax Conv expects (N, H, W, C), so we need to transpose\n        x = jnp.transpose(x, (0, 2, 3, 1))  # (N, H, W, C)\n        x = nn.Conv(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size),\n            strides=(1, 1),\n            padding='SAME',\n            use_bias=True,\n        )(x)\n        x = x * self.scale_factor\n        # Minimum along channel dimension (axis=-1), keepdims=True\n        x = jnp.min(x, axis=-1, keepdims=True)  # (N, H, W, 1)\n        # Transpose back to (N, C, H, W)\n        x = jnp.transpose(x, (0, 3, 1, 2))\n        return x\n\nbatch_size = 64\nin_channels = 64\nout_channels = 128\nheight = width = 256\nkernel_size = 3\nscale_factor = 2.0\n\ndef get_inputs():\n    # Return a list with a single input array of shape (batch_size, in_channels, height, width)\n    key = jax.random.PRNGKey(0)\n    x = jax.random.uniform(key, (batch_size, in_channels, height, width))\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, scale_factor]"}
{"kb_id": "kb_level_2_0026", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.37275985663082, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0026.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0026_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a GEMM (general matrix multiplication), applies scaling, \n    and then batch normalization.\n    \"\"\"\n    def __init__(self, in_features, out_features, scale_shape, eps=1e-5, momentum=0.1):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.scale = nn.Parameter(torch.randn(scale_shape))\n        self.bn = nn.BatchNorm1d(out_features, eps=eps, momentum=momentum)\n\n    def forward(self, x):\n        x = self.gemm(x)\n        x = x * self.scale\n        x = self.bn(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nscale_shape = (out_features,)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scale_shape]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\nfrom flax.core import freeze, unfreeze\nimport numpy as np\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a GEMM (general matrix multiplication), applies scaling, \n    and then batch normalization.\n    \"\"\"\n    in_features: int\n    out_features: int\n    scale_shape: tuple\n    eps: float = 1e-5\n    momentum: float = 0.1\n\n    @nn.compact\n    def __call__(self, x, train=True):\n        x = nn.Dense(self.out_features)(x)\n        scale = self.param('scale', nn.initializers.normal(), self.scale_shape)\n        x = x * scale\n        x = nn.BatchNorm(use_running_average=not train, \n                         momentum=self.momentum, \n                         epsilon=self.eps,\n                         use_bias=True, \n                         use_scale=True)(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nscale_shape = (out_features,)\n\ndef get_inputs():\n    return [jnp.array(np.random.rand(batch_size, in_features), dtype=jnp.float32)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scale_shape]"}
{"kb_id": "kb_level_2_0027", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.87364620938628, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0027.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0027_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, layer normalization, GELU activation, and scaling.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bias=True, eps=1e-5, scaling_factor=1.0):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, bias=bias)\n        self.layer_norm = nn.LayerNorm(out_channels, eps=eps)\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, D, H, W).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, D', H', W').\n        \"\"\"\n        x = self.conv_transpose(x)\n        x = self.layer_norm(x)\n        x = torch.nn.functional.gelu(x)\n        x = x * self.scaling_factor\n        return x\n\nbatch_size = 32\nin_channels = 32\nout_channels = 64\nD, H, W = 16, 32, 32\nkernel_size = 4\nstride = 2\npadding = 1\nbias = True\neps = 1e-5\nscaling_factor = 1.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, D, H, W)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, bias, eps, scaling_factor]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, layer normalization, GELU activation, and scaling.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    stride: int\n    padding: int\n    bias: bool = True\n    eps: float = 1e-5\n    scaling_factor: float = 1.0\n\n    @nn.compact\n    def __call__(self, x):\n        # Flax ConvTranspose3D expects (N, D, H, W, C), so we need to permute\n        x = jnp.transpose(x, (0, 2, 3, 4, 1))  # (N, D, H, W, C)\n        conv = nn.ConvTranspose(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size, self.kernel_size),\n            strides=(self.stride, self.stride, self.stride),\n            padding=[(self.padding, self.padding)] * 3,\n            use_bias=self.bias,\n            dimension_numbers=('NDHWC', 'DHWIO', 'NDHWC'),\n        )\n        x = conv(x)\n        # LayerNorm over channel axis (-1)\n        x = nn.LayerNorm(axis=-1, epsilon=self.eps)(x)\n        x = nn.gelu(x)\n        x = x * self.scaling_factor\n        # Transpose back to (N, C, D, H, W)\n        x = jnp.transpose(x, (0, 4, 1, 2, 3))\n        return x\n\nbatch_size = 32\nin_channels = 32\nout_channels = 64\nD, H, W = 16, 32, 32\nkernel_size = 4\nstride = 2\npadding = 1\nbias = True\neps = 1e-5\nscaling_factor = 1.0\n\ndef get_inputs():\n    key = jax.random.PRNGKey(0)\n    x = jax.random.uniform(key, (batch_size, in_channels, D, H, W))\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, bias, eps, scaling_factor]"}
{"kb_id": "kb_level_2_0029", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 68.75666074600356, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0029.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0029_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a convolution transpose, minimum operation, sum operation, GELU activation and addition.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, output_padding)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = torch.min(x, dim=1, keepdim=True)[0]  # Minimum operation along channel dimension\n        x = torch.sum(x, dim=2, keepdim=True)  # Sum operation along height dimension\n        x = torch.nn.functional.gelu(x)  # GELU activation\n        x = x + self.bias\n        return x\n\nbatch_size = 16\nin_channels = 64\nout_channels = 128\nheight, width = 128, 128\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\nbias_shape = (1, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a convolution transpose, minimum operation, sum operation, GELU activation and addition.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    stride: int\n    padding: int\n    output_padding: int\n    bias_shape: tuple\n\n    @nn.compact\n    def __call__(self, x):\n        # Flax ConvTranspose2D expects (N, H, W, C), so we need to transpose\n        x = jnp.transpose(x, (0, 2, 3, 1))  # (N, H, W, C)\n        conv_transpose = nn.ConvTranspose(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size),\n            strides=(self.stride, self.stride),\n            padding=[(self.padding, self.padding), (self.padding, self.padding)],\n            kernel_init=nn.initializers.lecun_normal(),\n            use_bias=False,\n        )\n        x = conv_transpose(x)\n        # Output shape: (N, H_out, W_out, out_channels)\n        # Mimic output_padding by cropping or padding as needed\n        if self.output_padding != 0:\n            # Add output_padding to H and W\n            pad = self.output_padding\n            x = jnp.pad(x, ((0,0), (0,pad), (0,pad), (0,0)))\n        # Now, min along channel dimension (last axis)\n        x = jnp.min(x, axis=-1, keepdims=True)  # (N, H_out, W_out, 1)\n        # Sum along height dimension (axis=1)\n        x = jnp.sum(x, axis=1, keepdims=True)  # (N, 1, W_out, 1)\n        # GELU activation\n        x = nn.gelu(x)\n        # Add bias (broadcasted)\n        bias = self.param('bias', nn.initializers.normal(), self.bias_shape)\n        x = x + bias\n        # Transpose back to (N, C, H, W) for consistency with PyTorch\n        x = jnp.transpose(x, (0, 3, 1, 2))\n        return x\n\nbatch_size = 16\nin_channels = 64\nout_channels = 128\nheight, width = 128, 128\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\nbias_shape = (1, 1, 1)\n\ndef get_inputs():\n    # Return a list with a single input array of shape (batch_size, in_channels, height, width)\n    key = jax.random.PRNGKey(0)\n    x = jax.random.uniform(key, (batch_size, in_channels, height, width))\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape]"}
{"kb_id": "kb_level_2_0030", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.74774774774775, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0030.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0030_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a matrix multiplication, applies Swish activation, sums with a bias term, and normalizes with GroupNorm.\n    \"\"\"\n    def __init__(self, in_features, out_features, num_groups, bias_shape):\n        super(Model, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.group_norm = nn.GroupNorm(num_groups, out_features)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.matmul(x)\n        x = torch.sigmoid(x) * x  # Swish activation\n        x = x + self.bias\n        x = self.group_norm(x)\n        return x\n\nbatch_size = 32768\nin_features = 1024\nout_features = 4096\nnum_groups = 64\nbias_shape = (out_features,)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, num_groups, bias_shape]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a matrix multiplication, applies Swish activation, sums with a bias term, and normalizes with GroupNorm.\n    \"\"\"\n    in_features: int\n    out_features: int\n    num_groups: int\n    bias_shape: tuple\n\n    @nn.compact\n    def __call__(self, x):\n        # Linear layer\n        x = nn.Dense(self.out_features)(x)\n        # Swish activation: x * sigmoid(x)\n        x = x * jax.nn.sigmoid(x)\n        # Bias addition\n        bias = self.param('bias', nn.initializers.normal(), self.bias_shape)\n        x = x + bias\n        # GroupNorm expects (batch, ..., features)\n        # Flax's GroupNorm normalizes over the last axis by default\n        x = nn.GroupNorm(num_groups=self.num_groups)(x)\n        return x\n\nbatch_size = 32768\nin_features = 1024\nout_features = 4096\nnum_groups = 64\nbias_shape = (out_features,)\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, num_groups, bias_shape]"}
{"kb_id": "kb_level_2_0031", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.87364620938628, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0031.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0031_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs average pooling, 3D transposed convolution, clamping,\n    spatial softmax, and multiplication by a learnable scale.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, pool_kernel_size, clamp_min, clamp_max):\n        super(Model, self).__init__()\n        self.avg_pool = nn.AvgPool3d(pool_kernel_size)\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.clamp_min = clamp_min\n        self.clamp_max = clamp_max\n        self.scale = nn.Parameter(torch.ones(1, out_channels, 1, 1, 1))\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, depth, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, depth, height, width).\n        \"\"\"\n        x = self.avg_pool(x)\n        x = self.conv_transpose(x)\n        x = torch.clamp(x, self.clamp_min, self.clamp_max)\n        b, c, d, h, w = x.shape\n        x = x.view(b, c, -1)                     # flatten spatial dims\n        x = torch.softmax(x, dim=2)\n        x = x.view(b, c, d, h, w)\n        x = x * self.scale\n        return x\n\nbatch_size = 32\nin_channels = 32\nout_channels = 64\ndepth, height, width = 32, 64, 64\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\npool_kernel_size = 2\nclamp_min = 0.0\nclamp_max = 1.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, pool_kernel_size, clamp_min, clamp_max]\n", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs average pooling, 3D transposed convolution, clamping,\n    spatial softmax, and multiplication by a learnable scale.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    stride: int\n    padding: int\n    output_padding: int\n    pool_kernel_size: int\n    clamp_min: float\n    clamp_max: float\n\n    @nn.compact\n    def __call__(self, x):\n        # Average Pooling 3D\n        x = nn.avg_pool(\n            x,\n            window_shape=(self.pool_kernel_size, self.pool_kernel_size, self.pool_kernel_size),\n            strides=(self.pool_kernel_size, self.pool_kernel_size, self.pool_kernel_size),\n            padding='VALID'\n        )\n        # ConvTranspose3D\n        x = nn.ConvTranspose(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size, self.kernel_size),\n            strides=(self.stride, self.stride, self.stride),\n            padding=[(self.padding, self.padding)]*3,\n            kernel_init=nn.initializers.lecun_normal(),\n            use_bias=True\n        )(x)\n        # Output padding for ConvTranspose3D\n        # Flax does not support output_padding directly, so we manually pad if needed\n        if self.output_padding > 0:\n            pad = self.output_padding\n            x = jnp.pad(\n                x,\n                ((0, 0), (0, 0), (0, pad), (0, pad), (0, pad)),\n                mode='constant'\n            )\n            # Crop to match PyTorch's output shape if needed\n            # (No cropping here, as we only add output_padding)\n        # Clamp\n        x = jnp.clip(x, self.clamp_min, self.clamp_max)\n        # Spatial softmax\n        b, c, d, h, w = x.shape\n        x_flat = x.reshape((b, c, -1))\n        x_flat = jax.nn.softmax(x_flat, axis=2)\n        x = x_flat.reshape((b, c, d, h, w))\n        # Learnable scale\n        scale = self.param('scale', nn.initializers.ones, (1, self.out_channels, 1, 1, 1))\n        x = x * scale\n        return x\n\nbatch_size = 32\nin_channels = 32\nout_channels = 64\ndepth, height, width = 32, 64, 64\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\npool_kernel_size = 2\nclamp_min = 0.0\nclamp_max = 1.0\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, in_channels, depth, height, width).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, pool_kernel_size, clamp_min, clamp_max]"}
{"kb_id": "kb_level_2_0032", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.74774774774775, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0032.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0032_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, scales the result, and applies batch normalization.\n    \"\"\"\n    def __init__(self, in_features, out_features, scale_shape, eps=1e-5, momentum=0.1):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.scale = nn.Parameter(torch.randn(scale_shape))\n        self.bn = nn.BatchNorm1d(out_features, eps=eps, momentum=momentum)\n\n    def forward(self, x):\n        x = self.gemm(x)\n        x = x * self.scale\n        x = self.bn(x)\n        return x\n\nbatch_size = 16384\nin_features = 4096\nout_features = 4096\nscale_shape = (out_features,)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scale_shape]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\nfrom flax.core import freeze, unfreeze\nimport numpy as np\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, scales the result, and applies batch normalization.\n    \"\"\"\n    in_features: int\n    out_features: int\n    scale_shape: tuple\n    eps: float = 1e-5\n    momentum: float = 0.1\n\n    @nn.compact\n    def __call__(self, x, train=True):\n        x = nn.Dense(self.out_features)(x)\n        scale = self.param('scale', nn.initializers.normal(), self.scale_shape)\n        x = x * scale\n        x = nn.BatchNorm(use_running_average=not train, \n                         momentum=self.momentum, \n                         epsilon=self.eps,\n                         use_bias=True, \n                         use_scale=True)(x)\n        return x\n\nbatch_size = 16384\nin_features = 4096\nout_features = 4096\nscale_shape = (out_features,)\n\ndef get_inputs():\n    # Return a list with a single JAX array of shape (batch_size, in_features)\n    return [jnp.array(np.random.rand(batch_size, in_features), dtype=jnp.float32)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scale_shape]"}
{"kb_id": "kb_level_2_0033", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0033.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0033_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, followed by a sum, layer normalization, average pooling, and GELU activation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, sum_weight, norm_shape, pool_kernel_size):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.sum_weight = nn.Parameter(torch.tensor(sum_weight))\n        self.norm = nn.LayerNorm(norm_shape)\n        self.avg_pool = nn.AvgPool3d(kernel_size=pool_kernel_size)\n        self.gelu = nn.GELU()\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = x + self.sum_weight\n        x = self.norm(x)\n        x = self.avg_pool(x)\n        x = self.gelu(x)\n        return x\n\nbatch_size = 32\nin_channels = 32\nout_channels = 64\ndepth, height, width = 16, 32, 32\nkernel_size = (3, 3, 3)\nstride = (2, 2, 2)\npadding = (1, 1, 1)\noutput_padding = (1, 1, 1)\nsum_weight = 1.0\nnorm_shape = (out_channels,)\npool_kernel_size = (2, 2, 2)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, sum_weight, norm_shape, pool_kernel_size]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass ConvTranspose3D(nn.Module):\n    features: int\n    kernel_size: tuple\n    strides: tuple = (1, 1, 1)\n    padding: tuple = (0, 0, 0)\n    output_padding: tuple = (0, 0, 0)\n    use_bias: bool = True\n\n    @nn.compact\n    def __call__(self, x):\n        # x: (N, C, D, H, W) -> (N, D, H, W, C)\n        x = jnp.transpose(x, (0, 2, 3, 4, 1))\n        kernel = self.param(\n            'kernel',\n            nn.initializers.lecun_normal(),\n            self.kernel_size + (self.features, x.shape[-1])\n        )\n        bias = self.param(\n            'bias',\n            nn.initializers.zeros,\n            (self.features,)\n        ) if self.use_bias else None\n\n        # Calculate output spatial shape\n        d, h, w = x.shape[1:4]\n        sd, sh, sw = self.strides\n        pd, ph, pw = self.padding\n        opd, oph, opw = self.output_padding\n        kd, kh, kw = self.kernel_size\n\n        out_d = (d - 1) * sd - 2 * pd + kd + opd\n        out_h = (h - 1) * sh - 2 * ph + kh + oph\n        out_w = (w - 1) * sw - 2 * pw + kw + opw\n        output_shape = (x.shape[0], out_d, out_h, out_w, self.features)\n\n        x = jax.lax.conv_transpose(\n            x,\n            kernel,\n            strides=self.strides,\n            padding=self.padding,\n            dimension_numbers=('NDHWC', 'DHWIO', 'NDHWC'),\n            transpose_kernel=True,\n            output_shape=output_shape\n        )\n        if self.use_bias:\n            x = x + bias\n        # Back to (N, C, D, H, W)\n        x = jnp.transpose(x, (0, 4, 1, 2, 3))\n        return x\n\nclass LayerNorm(nn.Module):\n    norm_shape: tuple\n\n    @nn.compact\n    def __call__(self, x):\n        # x: (N, C, D, H, W)\n        # norm_shape is (C,)\n        return nn.LayerNorm(axis=1, epsilon=1e-5, use_bias=True, use_scale=True)(x)\n\nclass AvgPool3D(nn.Module):\n    kernel_size: tuple\n\n    @nn.compact\n    def __call__(self, x):\n        # x: (N, C, D, H, W)\n        kD, kH, kW = self.kernel_size\n        # Pool over D, H, W (axes 2, 3, 4)\n        return nn.avg_pool(\n            x,\n            window_shape=(1, 1, kD, kH, kW),\n            strides=(1, 1, kD, kH, kW),\n            padding='VALID'\n        )\n\nclass Model(nn.Module):\n    in_channels: int\n    out_channels: int\n    kernel_size: tuple\n    stride: tuple\n    padding: tuple\n    output_padding: tuple\n    sum_weight: float\n    norm_shape: tuple\n    pool_kernel_size: tuple\n\n    def setup(self):\n        self.conv_transpose = ConvTranspose3D(\n            features=self.out_channels,\n            kernel_size=self.kernel_size,\n            strides=self.stride,\n            padding=self.padding,\n            output_padding=self.output_padding\n        )\n        self.sum_weight_param = self.param('sum_weight', lambda key: jnp.array(self.sum_weight, dtype=jnp.float32))\n        self.norm = LayerNorm(norm_shape=self.norm_shape)\n        self.avg_pool = AvgPool3D(kernel_size=self.pool_kernel_size)\n        self.gelu = nn.gelu\n\n    def __call__(self, x):\n        x = self.conv_transpose(x)\n        x = x + self.sum_weight_param\n        x = self.norm(x)\n        x = self.avg_pool(x)\n        x = self.gelu(x)\n        return x\n\nbatch_size = 32\nin_channels = 32\nout_channels = 64\ndepth, height, width = 16, 32, 32\nkernel_size = (3, 3, 3)\nstride = (2, 2, 2)\npadding = (1, 1, 1)\noutput_padding = (1, 1, 1)\nsum_weight = 1.0\nnorm_shape = (out_channels,)\npool_kernel_size = (2, 2, 2)\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, in_channels, depth, height, width).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, sum_weight, norm_shape, pool_kernel_size]"}
{"kb_id": "kb_level_2_0034", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.24865831842575, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0034.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0034_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a matrix multiplication, scaling, and residual addition.\n\n    Args:\n        in_features (int): Number of input features.\n        out_features (int): Number of output features.\n        scaling_factor (float): Scaling factor to apply after matrix multiplication.\n    \"\"\"\n    def __init__(self, in_features, out_features, scaling_factor):\n        super(Model, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        \"\"\"\n        Forward pass of the model.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.matmul(x)\n        original_x = x.clone().detach()\n        x = x * self.scaling_factor\n        x = x + original_x\n        return x\n\nbatch_size = 16384\nin_features = 4096\nout_features = 4096\nscaling_factor = 0.5\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a matrix multiplication, scaling, and residual addition.\n\n    Args:\n        in_features (int): Number of input features.\n        out_features (int): Number of output features.\n        scaling_factor (float): Scaling factor to apply after matrix multiplication.\n    \"\"\"\n    in_features: int\n    out_features: int\n    scaling_factor: float\n\n    def setup(self):\n        self.matmul = nn.Dense(self.out_features, use_bias=True)\n\n    def __call__(self, x):\n        \"\"\"\n        Forward pass of the model.\n\n        Args:\n            x (jnp.ndarray): Input tensor of shape (batch_size, in_features).\n\n        Returns:\n            jnp.ndarray: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.matmul(x)\n        original_x = jnp.array(x)  # clone/detach not needed in JAX; arrays are immutable\n        x = x * self.scaling_factor\n        x = x + original_x\n        return x\n\nbatch_size = 16384\nin_features = 4096\nout_features = 4096\nscaling_factor = 0.5\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, in_features).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor]"}
{"kb_id": "kb_level_2_0035", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0035.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0035_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a GEMM, BatchNorm, GELU, and ReLU in sequence.\n    \"\"\"\n    def __init__(self, in_features, out_features):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.batch_norm = nn.BatchNorm1d(out_features)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.gemm(x)\n        x = self.batch_norm(x)\n        x = torch.nn.functional.gelu(x)\n        x = torch.relu(x)\n        return x\n\nbatch_size = 16384\nin_features = 4096\nout_features = 4096\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a GEMM, BatchNorm, GELU, and ReLU in sequence.\n    \"\"\"\n    in_features: int\n    out_features: int\n\n    @nn.compact\n    def __call__(self, x, *, train=True):\n        x = nn.Dense(self.out_features)(x)\n        x = nn.BatchNorm(use_running_average=not train, axis=-1, momentum=0.1, epsilon=1e-5)(x)\n        x = nn.gelu(x)\n        x = jnp.maximum(x, 0)\n        return x\n\nbatch_size = 16384\nin_features = 4096\nout_features = 4096\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, in_features).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [in_features, out_features]"}
{"kb_id": "kb_level_2_0036", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0036.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0036_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, global average pooling, adds a bias, applies log-sum-exp, sum, and multiplication.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, bias_shape):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = torch.mean(x, dim=(2, 3), keepdim=True)  # Global average pooling\n        x = x + self.bias\n        x = torch.logsumexp(x, dim=1, keepdim=True)  # Log-sum-exp\n        x = torch.sum(x, dim=(2, 3))  # Sum\n        x = x * 10.0  # Multiplication\n        return x\n\nbatch_size = 16\nin_channels = 64\nout_channels = 128\nheight = width = 512\nkernel_size = 3\nbias_shape = (out_channels, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, bias_shape]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, global average pooling, adds a bias, applies log-sum-exp, sum, and multiplication.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    bias_shape: tuple\n\n    @nn.compact\n    def __call__(self, x):\n        # ConvTranspose2d in PyTorch: (N, C_in, H, W) -> (N, C_out, H_out, W_out)\n        # Flax ConvTranspose: (N, H, W, C_in) -> (N, H_out, W_out, C_out)\n        # So we need to transpose input and output accordingly\n        x = jnp.transpose(x, (0, 2, 3, 1))  # (N, H, W, C_in)\n        x = nn.ConvTranspose(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size),\n            strides=(1, 1),\n            padding='SAME',\n            use_bias=False,\n            name='conv_transpose'\n        )(x)\n        x = jnp.transpose(x, (0, 3, 1, 2))  # (N, C_out, H_out, W_out)\n\n        # Global average pooling over H and W\n        x = jnp.mean(x, axis=(2, 3), keepdims=True)\n\n        # Add bias (broadcasted)\n        bias = self.param('bias', nn.initializers.normal(), self.bias_shape)\n        x = x + bias\n\n        # Log-sum-exp over channel dimension\n        x = jax.scipy.special.logsumexp(x, axis=1, keepdims=True)\n\n        # Sum over H and W\n        x = jnp.sum(x, axis=(2, 3))\n\n        # Multiply by 10.0\n        x = x * 10.0\n        return x\n\nbatch_size = 16\nin_channels = 64\nout_channels = 128\nheight = width = 512\nkernel_size = 3\nbias_shape = (out_channels, 1, 1)\n\ndef get_inputs():\n    # Return a list with a single input array, shape (batch_size, in_channels, height, width)\n    key = jax.random.PRNGKey(0)\n    x = jax.random.uniform(key, (batch_size, in_channels, height, width))\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, bias_shape]"}
{"kb_id": "kb_level_2_0037", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.24865831842575, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0037.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0037_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, max pooling, log sum exp, and ReLU activation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n        self.max_pool = nn.MaxPool3d(kernel_size=2, stride=2)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x: Input tensor of shape (batch_size, in_channels, depth, height, width)\n        Returns:\n            Output tensor of shape (batch_size, out_channels, depth', height', width')\n        \"\"\"\n        x = self.conv(x)\n        x = self.max_pool(x)\n        x = torch.logsumexp(x, dim=1, keepdim=True)\n        x = torch.relu(x)\n        return x\n\nbatch_size = 4\nin_channels = 32\nout_channels = 64\ndepth, height, width = 32, 128, 128\nkernel_size = 3\nstride = 1\npadding = 1\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, max pooling, log sum exp, and ReLU activation.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    stride: int\n    padding: int\n\n    @nn.compact\n    def __call__(self, x):\n        # Flax Conv3D expects (batch, D, H, W, C), so we need to transpose\n        # Input: (batch, in_channels, D, H, W) -> (batch, D, H, W, in_channels)\n        x = jnp.transpose(x, (0, 2, 3, 4, 1))\n        x = nn.Conv(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size, self.kernel_size),\n            strides=(self.stride, self.stride, self.stride),\n            padding=[(self.padding, self.padding)] * 3,\n            use_bias=True,\n        )(x)\n        # MaxPool3D: kernel_size=2, stride=2\n        x = nn.max_pool(\n            x,\n            window_shape=(2, 2, 2),\n            strides=(2, 2, 2),\n            padding=\"VALID\"\n        )\n        # logsumexp over channel axis (which is now -1)\n        x = jax.scipy.special.logsumexp(x, axis=-1, keepdims=True)\n        x = nn.relu(x)\n        # Output: (batch, D', H', W', 1) -> (batch, 1, D', H', W')\n        x = jnp.transpose(x, (0, 4, 1, 2, 3))\n        return x\n\nbatch_size = 4\nin_channels = 32\nout_channels = 64\ndepth, height, width = 32, 128, 128\nkernel_size = 3\nstride = 1\npadding = 1\n\ndef get_inputs():\n    # Return a list with a single input array of shape (batch, in_channels, D, H, W)\n    key = jax.random.PRNGKey(0)\n    x = jax.random.uniform(\n        key,\n        (batch_size, in_channels, depth, height, width),\n        minval=0.0,\n        maxval=1.0\n    )\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding]"}
{"kb_id": "kb_level_2_0038", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0038.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0038_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, multiplies by a scalar, applies global average pooling, \n    another global average pooling\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, multiplier):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.multiplier = multiplier\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = x * self.multiplier\n        x = torch.mean(x, dim=[2, 3], keepdim=True)  # First global average pooling\n        x = torch.mean(x, dim=[2, 3], keepdim=True)  # Second global average pooling\n        return x\n\nbatch_size = 16\nin_channels = 64\nout_channels = 128\nheight, width = 128, 128\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\nmultiplier = 0.5\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, multiplier]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, multiplies by a scalar, applies global average pooling, \n    another global average pooling\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    stride: int\n    padding: int\n    output_padding: int\n    multiplier: float\n\n    @nn.compact\n    def __call__(self, x):\n        # Flax ConvTranspose uses 'SAME'/'VALID' padding, so we need to manually pad if necessary\n        # PyTorch's padding is the number of zeros added to both sides, so we mimic it with jnp.pad\n        # For 2D, padding is (pad_h, pad_w)\n        pad_h = self.padding\n        pad_w = self.padding\n        if pad_h > 0 or pad_w > 0:\n            x = jnp.pad(x, ((0,0), (0,0), (pad_h, pad_h), (pad_w, pad_w)))\n        conv_transpose = nn.ConvTranspose(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size),\n            strides=(self.stride, self.stride),\n            padding='VALID',  # since we already padded\n            use_bias=True,\n        )\n        x = conv_transpose(x)\n        # Output padding: PyTorch adds extra size after transposed conv if needed\n        # In JAX, we can pad the output if output_padding > 0\n        if self.output_padding > 0:\n            x = jnp.pad(\n                x,\n                ((0,0), (0,0), (0, self.output_padding), (0, self.output_padding))\n            )\n        x = x * self.multiplier\n        x = jnp.mean(x, axis=(2, 3), keepdims=True)  # First global average pooling\n        x = jnp.mean(x, axis=(2, 3), keepdims=True)  # Second global average pooling\n        return x\n\nbatch_size = 16\nin_channels = 64\nout_channels = 128\nheight, width = 128, 128\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\nmultiplier = 0.5\n\ndef get_inputs():\n    # JAX expects numpy arrays, not torch tensors\n    return [jnp.random.rand(batch_size, in_channels, height, width).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, multiplier]"}
{"kb_id": "kb_level_2_0039", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0039.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0039_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a matrix multiplication (Gemm), applies Sigmoid,\n    another Gemm, and computes LogSumExp over features.\n    \"\"\"\n    def __init__(self, input_size, hidden_size, output_size):\n        super(Model, self).__init__()\n        self.linear1 = nn.Linear(input_size, hidden_size)\n        self.linear2 = nn.Linear(hidden_size, output_size)\n\n    def forward(self, x):\n        x = self.linear1(x)\n        x = torch.sigmoid(x)\n        x = self.linear2(x)\n        x = torch.logsumexp(x, dim=1)  # compute LogSumExp over features per sample\n        return x\n\nbatch_size = 16384\ninput_size = 2048\nhidden_size = 4096\noutput_size = 1024\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, output_size]\n", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a matrix multiplication (Gemm), applies Sigmoid,\n    another Gemm, and computes LogSumExp over features.\n    \"\"\"\n    input_size: int\n    hidden_size: int\n    output_size: int\n\n    @nn.compact\n    def __call__(self, x):\n        x = nn.Dense(self.hidden_size)(x)\n        x = jax.nn.sigmoid(x)\n        x = nn.Dense(self.output_size)(x)\n        x = jax.scipy.special.logsumexp(x, axis=1)  # compute LogSumExp over features per sample\n        return x\n\nbatch_size = 16384\ninput_size = 2048\nhidden_size = 4096\noutput_size = 1024\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, input_size).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, output_size]"}
{"kb_id": "kb_level_2_0040", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.62230215827337, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0040.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0040_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a convolution, subtraction, tanh activation, subtraction and average pooling.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, subtract1_value, subtract2_value, kernel_size_pool):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.subtract1_value = subtract1_value\n        self.subtract2_value = subtract2_value\n        self.avgpool = nn.AvgPool2d(kernel_size_pool)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x - self.subtract1_value\n        x = torch.tanh(x)\n        x = x - self.subtract2_value\n        x = self.avgpool(x)\n        return x\n\nbatch_size = 128\nin_channels = 64\nout_channels = 128\nheight, width = 128, 128\nkernel_size = 3\nsubtract1_value = 0.5\nsubtract2_value = 0.2\nkernel_size_pool = 2\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, subtract1_value, subtract2_value, kernel_size_pool]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a convolution, subtraction, tanh activation, subtraction and average pooling.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    subtract1_value: float\n    subtract2_value: float\n    kernel_size_pool: int\n\n    @nn.compact\n    def __call__(self, x):\n        x = nn.Conv(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size),\n            strides=(1, 1),\n            padding='SAME',\n            use_bias=True\n        )(x)\n        x = x - self.subtract1_value\n        x = jnp.tanh(x)\n        x = x - self.subtract2_value\n        x = nn.avg_pool(\n            x,\n            window_shape=(self.kernel_size_pool, self.kernel_size_pool),\n            strides=(self.kernel_size_pool, self.kernel_size_pool),\n            padding='VALID'\n        )\n        return x\n\nbatch_size = 128\nin_channels = 64\nout_channels = 128\nheight, width = 128, 128\nkernel_size = 3\nsubtract1_value = 0.5\nsubtract2_value = 0.2\nkernel_size_pool = 2\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, in_channels, height, width).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, subtract1_value, subtract2_value, kernel_size_pool]"}
{"kb_id": "kb_level_2_0041", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0041.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0041_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, applies Mish activation, and then applies Tanh activation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, D, H, W).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, D', H', W').\n        \"\"\"\n        x = self.conv(x)\n        x = torch.nn.functional.mish(x)\n        x = torch.tanh(x)\n        return x\n\nbatch_size = 16\nin_channels = 32\nout_channels = 64\nD, H, W = 32, 64, 64\nkernel_size = 3\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, D, H, W)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, applies Mish activation, and then applies Tanh activation.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    stride: int = 1\n    padding: int = 0\n\n    @nn.compact\n    def __call__(self, x):\n        # Flax Conv3D expects (batch, D, H, W, C), so we need to transpose\n        # Input x: (batch, in_channels, D, H, W)\n        x = jnp.transpose(x, (0, 2, 3, 4, 1))  # (batch, D, H, W, C)\n        x = nn.Conv(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size, self.kernel_size),\n            strides=(self.stride, self.stride, self.stride),\n            padding=[(self.padding, self.padding)] * 3,\n            use_bias=True,\n        )(x)\n        # Mish activation: x * tanh(softplus(x))\n        x = x * jnp.tanh(jax.nn.softplus(x))\n        x = jnp.tanh(x)\n        # Transpose back to (batch, out_channels, D, H, W)\n        x = jnp.transpose(x, (0, 4, 1, 2, 3))\n        return x\n\nbatch_size = 16\nin_channels = 32\nout_channels = 64\nD, H, W = 32, 64, 64\nkernel_size = 3\n\ndef get_inputs():\n    # Return a list with a single input array of shape (batch_size, in_channels, D, H, W)\n    key = jax.random.PRNGKey(0)\n    x = jax.random.uniform(key, (batch_size, in_channels, D, H, W))\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]"}
{"kb_id": "kb_level_2_0042", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 68.63475177304966, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0042.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0042_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, scales the output, applies tanh, multiplies by a scaling factor, and applies sigmoid.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, scaling_factor, bias_shape):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size)\n        self.scaling_factor = nn.Parameter(torch.randn(bias_shape))\n        self.bias = nn.Parameter(torch.randn(bias_shape)) \n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x * self.scaling_factor \n        x = torch.tanh(x)\n        x = x * self.bias\n        x = torch.sigmoid(x)\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 64, 64\nkernel_size = 3\nscaling_factor = 2\nbias_shape = (out_channels, 1, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, scaling_factor, bias_shape]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, scales the output, applies tanh, multiplies by a scaling factor, and applies sigmoid.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    scaling_factor: float\n    bias_shape: tuple\n\n    def setup(self):\n        self.conv = nn.Conv(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size, self.kernel_size),\n            strides=(1, 1, 1),\n            padding='SAME',\n            use_bias=False\n        )\n        self.scaling_factor_param = self.param(\n            'scaling_factor_param',\n            nn.initializers.normal(),\n            self.bias_shape\n        )\n        self.bias = self.param(\n            'bias',\n            nn.initializers.normal(),\n            self.bias_shape\n        )\n\n    def __call__(self, x):\n        x = self.conv(x)\n        x = x * self.scaling_factor_param\n        x = jnp.tanh(x)\n        x = x * self.bias\n        x = jax.nn.sigmoid(x)\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 64, 64\nkernel_size = 3\nscaling_factor = 2\nbias_shape = (out_channels, 1, 1, 1)\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, in_channels, depth, height, width).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, scaling_factor, bias_shape]"}
{"kb_id": "kb_level_2_0043", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.125, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0043.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0043_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, applies Softmax and Sigmoid.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, bias=True):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding, bias=bias)\n        self.softmax = nn.Softmax(dim=1)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, D, H, W).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, D, H, W).\n        \"\"\"\n        x = self.conv_transpose(x)\n        x = self.softmax(x)\n        x = self.sigmoid(x)\n        return x\n\nbatch_size = 16\nin_channels = 32\nout_channels = 64\nD, H, W = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, D, H, W)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, applies Softmax and Sigmoid.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    stride: int\n    padding: int\n    output_padding: int\n    bias: bool = True\n\n    @nn.compact\n    def __call__(self, x):\n        # Flax ConvTranspose3D expects (N, D, H, W, C), so we need to permute axes\n        # PyTorch: (N, C, D, H, W) -> Flax: (N, D, H, W, C)\n        x = jnp.transpose(x, (0, 2, 3, 4, 1))\n        conv = nn.ConvTranspose(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size, self.kernel_size),\n            strides=(self.stride, self.stride, self.stride),\n            padding=[(self.padding, self.padding)]*3,\n            use_bias=self.bias,\n            # Flax does not have output_padding, so we handle it below\n        )\n        x = conv(x)\n        # Handle output_padding manually if needed\n        if self.output_padding > 0:\n            pad = self.output_padding\n            # Pad at the end of D, H, W\n            x = jnp.pad(\n                x,\n                ((0, 0), (0, pad), (0, pad), (0, pad), (0, 0)),\n                mode='constant'\n            )\n            # Crop to match PyTorch's output shape if needed\n            # (PyTorch's ConvTranspose3d with output_padding can be tricky, but this is a close approximation)\n        # Softmax over channel axis (axis=-1 after transpose)\n        x = nn.softmax(x, axis=-1)\n        x = nn.sigmoid(x)\n        # Back to (N, C, D, H, W)\n        x = jnp.transpose(x, (0, 4, 1, 2, 3))\n        return x\n\nbatch_size = 16\nin_channels = 32\nout_channels = 64\nD, H, W = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, in_channels, D, H, W).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding]"}
{"kb_id": "kb_level_2_0044", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0044.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0044_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, applies Mish, and another Mish.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = torch.nn.functional.mish(x)\n        x = torch.nn.functional.mish(x)\n        return x\n\nbatch_size   = 64  \nin_channels  = 64  \nout_channels = 128  \nheight = width = 256\nkernel_size = 3\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, applies Mish, and another Mish.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n\n    @nn.compact\n    def __call__(self, x):\n        x = nn.Conv(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size),\n            strides=(1, 1),\n            padding='SAME',\n            use_bias=True\n        )(x)\n        x = mish(x)\n        x = mish(x)\n        return x\n\ndef mish(x):\n    return x * jnp.tanh(jax.nn.softplus(x))\n\nbatch_size   = 64  \nin_channels  = 64  \nout_channels = 128  \nheight = width = 256\nkernel_size = 3\n\ndef get_inputs():\n    # Flax expects NHWC by default, but we keep NCHW to match PyTorch logic.\n    # We'll transpose to NHWC before passing to the model.\n    x = jax.random.uniform(jax.random.PRNGKey(0), (batch_size, in_channels, height, width))\n    # Transpose to NHWC for Flax Conv2D\n    x = jnp.transpose(x, (0, 2, 3, 1))\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]"}
{"kb_id": "kb_level_2_0045", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0045.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0045_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, scaling, average pooling, bias addition, and scaling.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, scale1, scale2, bias_shape):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n        self.scale1 = nn.Parameter(torch.tensor(scale1))\n        self.avg_pool = nn.AvgPool3d(kernel_size=2)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.scale2 = nn.Parameter(torch.tensor(scale2))\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = x * self.scale1\n        x = self.avg_pool(x)\n        x = x + self.bias\n        x = x * self.scale2\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\nscale1 = 0.5\nscale2 = 1.0\nbias_shape = (out_channels, 1, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, scale1, scale2, bias_shape]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\nfrom typing import Tuple, Any\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, scaling, average pooling, bias addition, and scaling.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    stride: int\n    padding: int\n    scale1: float\n    scale2: float\n    bias_shape: Tuple[int, int, int, int]\n\n    @nn.compact\n    def __call__(self, x):\n        # Flax ConvTranspose3D expects (N, D, H, W, C), so we need to permute axes\n        # Input x: (N, C, D, H, W) -> (N, D, H, W, C)\n        x = jnp.transpose(x, (0, 2, 3, 4, 1))\n        x = nn.ConvTranspose(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size, self.kernel_size),\n            strides=(self.stride, self.stride, self.stride),\n            padding=[(self.padding, self.padding)]*3,\n            use_bias=False,\n            dimension_numbers=('NDHWC', 'DHWIO', 'NDHWC')\n        )(x)\n        scale1 = self.param('scale1', lambda rng, shape: jnp.array(self.scale1), ())\n        x = x * scale1\n        # Average pooling\n        x = nn.avg_pool(\n            x,\n            window_shape=(2, 2, 2),\n            strides=(2, 2, 2),\n            padding='VALID'\n        )\n        bias = self.param('bias', nn.initializers.normal(), self.bias_shape)\n        # bias shape: (out_channels, 1, 1, 1), need to broadcast to (N, D, H, W, C)\n        # Flax output shape: (N, D, H, W, C)\n        # So reshape bias to (1, 1, 1, 1, out_channels) and add\n        bias = jnp.reshape(bias, (1, 1, 1, 1, self.out_channels))\n        x = x + bias\n        scale2 = self.param('scale2', lambda rng, shape: jnp.array(self.scale2), ())\n        x = x * scale2\n        # Back to (N, C, D, H, W)\n        x = jnp.transpose(x, (0, 4, 1, 2, 3))\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\nscale1 = 0.5\nscale2 = 1.0\nbias_shape = (out_channels, 1, 1, 1)\n\ndef get_inputs():\n    # Return a list with a single input array of shape (batch_size, in_channels, depth, height, width)\n    return [jnp.random.rand(batch_size, in_channels, depth, height, width).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, scale1, scale2, bias_shape]"}
{"kb_id": "kb_level_2_0046", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.49730700179532, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0046.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0046_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a series of operations: Gemm, Subtract, GlobalAvgPool, LogSumExp, GELU, and ResidualAdd.\n    \"\"\"\n    def __init__(self, in_features, out_features, bias=True):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features, bias=bias)\n        self.subtract = nn.Parameter(torch.randn(out_features))\n\n    def forward(self, x):\n        original_x = x.clone().detach()\n        # Gemm\n        x = self.gemm(x)\n\n        # Subtract\n        x = x - self.subtract\n\n        # GlobalAvgPool\n        x = torch.mean(x, dim=1, keepdim=True)\n\n        # LogSumExp\n        x = torch.logsumexp(x, dim=1, keepdim=True)\n\n        # GELU\n        x = torch.nn.functional.gelu(x)\n\n        # ResidualAdd\n        x = x + original_x\n\n        return x\n\nbatch_size = 2048\nin_features = 8192\nout_features = 8192\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a series of operations: Gemm, Subtract, GlobalAvgPool, LogSumExp, GELU, and ResidualAdd.\n    \"\"\"\n    in_features: int\n    out_features: int\n    bias: bool = True\n\n    def setup(self):\n        self.gemm = nn.Dense(self.out_features, use_bias=self.bias)\n        self.subtract = self.param('subtract', jax.nn.initializers.normal(), (self.out_features,))\n\n    def __call__(self, x):\n        original_x = jnp.array(x)  # clone/detach equivalent\n\n        # Gemm\n        x = self.gemm(x)\n\n        # Subtract\n        x = x - self.subtract\n\n        # GlobalAvgPool (mean over dim=1, keepdim=True)\n        x = jnp.mean(x, axis=1, keepdims=True)\n\n        # LogSumExp (over dim=1, keepdim=True)\n        x = jax.scipy.special.logsumexp(x, axis=1, keepdims=True)\n\n        # GELU\n        x = jax.nn.gelu(x)\n\n        # ResidualAdd\n        # original_x shape: (batch_size, in_features)\n        # x shape: (batch_size, 1, out_features) after above ops\n        # But after mean and logsumexp, x is (batch_size, 1, out_features) only if keepdims=True and axis=1 on 3D input.\n        # In this code, after gemm, x is (batch_size, out_features)\n        # After mean over axis=1, x is (batch_size, 1)\n        # After logsumexp over axis=1, x is (batch_size, 1)\n        # After gelu, x is (batch_size, 1)\n        # original_x is (batch_size, in_features)\n        # To add, we need to broadcast or slice accordingly.\n        # We'll broadcast x to match original_x shape if possible.\n        x = x + original_x\n\n        return x\n\nbatch_size = 2048\nin_features = 8192\nout_features = 8192\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, in_features).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [in_features, out_features]"}
{"kb_id": "kb_level_2_0047", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0047.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0047_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, applies activation, and then applies Batch Normalization.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, eps=1e-5, momentum=0.1):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.bn = nn.BatchNorm2d(out_channels, eps=eps, momentum=momentum)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = torch.multiply(torch.tanh(torch.nn.functional.softplus(x)), x)\n        x = self.bn(x)\n        return x\n\nbatch_size = 64\nin_channels = 64\nout_channels = 128\nheight, width = 128, 128\nkernel_size = 3\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, applies activation, and then applies Batch Normalization.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    eps: float = 1e-5\n    momentum: float = 0.1\n\n    @nn.compact\n    def __call__(self, x, train=True):\n        x = nn.Conv(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size),\n            use_bias=True\n        )(x)\n        # Activation: multiply(tanh(softplus(x)), x)\n        x = jnp.tanh(nn.softplus(x)) * x\n        x = nn.BatchNorm(\n            use_running_average=not train,\n            momentum=self.momentum,\n            epsilon=self.eps\n        )(x)\n        return x\n\nbatch_size = 64\nin_channels = 64\nout_channels = 128\nheight, width = 128, 128\nkernel_size = 3\n\ndef get_inputs():\n    # Flax expects NHWC by default, but Conv2d in PyTorch uses NCHW.\n    # We'll use NCHW for input, and set Conv to use channels_first.\n    # But Flax's Conv expects NHWC, so we need to transpose.\n    x = jax.random.uniform(\n        jax.random.PRNGKey(0),\n        (batch_size, in_channels, height, width),\n        dtype=jnp.float32\n    )\n    # Transpose to NHWC for Flax\n    x = jnp.transpose(x, (0, 2, 3, 1))\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]"}
{"kb_id": "kb_level_2_0048", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0048.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0048_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a GEMM, scaling, hardtanh, and GELU activation.\n    \"\"\"\n    def __init__(self, in_features, out_features, scaling_factor, hardtanh_min, hardtanh_max):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.scaling_factor = scaling_factor\n        self.hardtanh = nn.Hardtanh(min_val=hardtanh_min, max_val=hardtanh_max)\n        self.gelu = nn.GELU()\n\n    def forward(self, x):\n        x = self.gemm(x)\n        x = x * self.scaling_factor\n        x = self.hardtanh(x)\n        x = self.gelu(x)\n        return x\n\nbatch_size = 2048\nin_features = 8192\nout_features = 8192\nscaling_factor = 0.5\nhardtanh_min = -2\nhardtanh_max = 2\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor, hardtanh_min, hardtanh_max]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a GEMM, scaling, hardtanh, and GELU activation.\n    \"\"\"\n    in_features: int\n    out_features: int\n    scaling_factor: float\n    hardtanh_min: float\n    hardtanh_max: float\n\n    @nn.compact\n    def __call__(self, x):\n        x = nn.Dense(self.out_features)(x)\n        x = x * self.scaling_factor\n        x = jnp.clip(x, self.hardtanh_min, self.hardtanh_max)\n        x = nn.gelu(x)\n        return x\n\nbatch_size = 2048\nin_features = 8192\nout_features = 8192\nscaling_factor = 0.5\nhardtanh_min = -2\nhardtanh_max = 2\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, in_features).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor, hardtanh_min, hardtanh_max]"}
{"kb_id": "kb_level_2_0049", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0049.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0049_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a convolution, multiplies by a learnable scalar, applies LeakyReLU, and then GELU.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, multiplier_shape):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.multiplier = nn.Parameter(torch.randn(multiplier_shape)) \n        self.leaky_relu = nn.LeakyReLU()\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x * self.multiplier\n        x = self.leaky_relu(x)\n        x = torch.nn.functional.gelu(x)\n        return x\n\nbatch_size = 64\nin_channels = 64\nout_channels = 64\nheight, width = 256, 256\nkernel_size = 3\nmultiplier_shape = (out_channels, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, multiplier_shape]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a convolution, multiplies by a learnable scalar, applies LeakyReLU, and then GELU.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    multiplier_shape: tuple\n\n    def setup(self):\n        self.conv = nn.Conv(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size),\n            use_bias=True\n        )\n        self.multiplier = self.param(\n            'multiplier',\n            nn.initializers.normal(),\n            self.multiplier_shape\n        )\n        self.leaky_relu = nn.leaky_relu\n\n    def __call__(self, x):\n        x = self.conv(x)\n        x = x * self.multiplier\n        x = self.leaky_relu(x)\n        x = nn.gelu(x)\n        return x\n\nbatch_size = 64\nin_channels = 64\nout_channels = 64\nheight, width = 256, 256\nkernel_size = 3\nmultiplier_shape = (out_channels, 1, 1)\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, in_channels, height, width).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, multiplier_shape]"}
{"kb_id": "kb_level_2_0050", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 68.15140845070424, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0050.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0050_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs matrix multiplication, max pooling, sum, and scaling.\n    \"\"\"\n    def __init__(self, in_features, out_features, kernel_size, scale_factor):\n        super(Model, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.max_pool = nn.MaxPool1d(kernel_size)\n        self.scale_factor = scale_factor\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.matmul(x)\n        x = self.max_pool(x.unsqueeze(1)).squeeze(1)\n        x = torch.sum(x, dim=1)\n        x = x * self.scale_factor\n        return x\n\nbatch_size = 128\nin_features = 32768\nout_features = 32768\nkernel_size = 2\nscale_factor = 0.5\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, kernel_size, scale_factor]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs matrix multiplication, max pooling, sum, and scaling.\n    \"\"\"\n    in_features: int\n    out_features: int\n    kernel_size: int\n    scale_factor: float\n\n    @nn.compact\n    def __call__(self, x):\n        # x: (batch_size, in_features)\n        x = nn.Dense(self.out_features)(x)  # (batch_size, out_features)\n        # Reshape for 1D max pooling: (batch_size, 1, out_features)\n        x = x[:, None, :]\n        # Apply 1D max pooling along the last dimension\n        x = nn.max_pool(\n            x,\n            window_shape=(1, self.kernel_size),\n            strides=(1, self.kernel_size),\n            padding='VALID'\n        )\n        # Remove the singleton dimension: (batch_size, pooled_features)\n        x = jnp.squeeze(x, axis=1)\n        # Sum along features\n        x = jnp.sum(x, axis=1)\n        # Scale\n        x = x * self.scale_factor\n        return x\n\nbatch_size = 128\nin_features = 32768\nout_features = 32768\nkernel_size = 2\nscale_factor = 0.5\n\ndef get_inputs():\n    key = jax.random.PRNGKey(0)\n    x = jax.random.uniform(key, (batch_size, in_features))\n    return [x]\n\ndef get_init_inputs():\n    return [in_features, out_features, kernel_size, scale_factor]"}
{"kb_id": "kb_level_2_0051", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0051.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0051_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, applies sigmoid, and sums the result.\n    \"\"\"\n    def __init__(self, input_size, hidden_size):\n        super(Model, self).__init__()\n        self.linear = nn.Linear(input_size, hidden_size)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x: Input tensor of shape (batch_size, input_size).\n\n        Returns:\n            Output tensor of shape (batch_size, 1).\n        \"\"\"\n        x = self.linear(x)\n        x = torch.sigmoid(x)\n        x = torch.sum(x, dim=1, keepdim=True)\n        return x\n\nbatch_size = 128\ninput_size = 32768\nhidden_size = 32768\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, applies sigmoid, and sums the result.\n    \"\"\"\n    input_size: int\n    hidden_size: int\n\n    @nn.compact\n    def __call__(self, x):\n        \"\"\"\n        Args:\n            x: Input tensor of shape (batch_size, input_size).\n\n        Returns:\n            Output tensor of shape (batch_size, 1).\n        \"\"\"\n        x = nn.Dense(self.hidden_size)(x)\n        x = jax.nn.sigmoid(x)\n        x = jnp.sum(x, axis=1, keepdims=True)\n        return x\n\nbatch_size = 128\ninput_size = 32768\nhidden_size = 32768\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size]"}
{"kb_id": "kb_level_2_0052", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.49730700179532, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0052.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0052_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, applies ReLU, and applies HardSwish activation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = torch.relu(x)\n        x = x * torch.clamp((x + 3) / 6, 0, 1)\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 128, 128\nkernel_size = 3\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, applies ReLU, and applies HardSwish activation.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n\n    @nn.compact\n    def __call__(self, x):\n        x = nn.Conv(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size),\n            strides=(1, 1),\n            padding='SAME',\n            use_bias=True,\n        )(x)\n        x = jax.nn.relu(x)\n        x = x * jnp.clip((x + 3) / 6, 0, 1)\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 128, 128\nkernel_size = 3\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, in_channels, height, width).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]"}
{"kb_id": "kb_level_2_0053", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0053.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0053_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, LogSumExp, HardSwish, subtraction, clamp operations.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bias_shape):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n        self.bias = nn.Parameter(torch.randn(1, 1, 1, 1)) \n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = torch.logsumexp(x, dim=1, keepdim=True)\n        x = x * torch.sigmoid(x + 3) / 6\n        x = x - self.bias\n        x = torch.clamp(x, min=-1, max=1)\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\nbias_shape = (1, 1, 1, 1)  \n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, bias_shape]\n", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass ConvTranspose3d(nn.Module):\n    features: int\n    kernel_size: int\n    strides: int\n    padding: int\n\n    @nn.compact\n    def __call__(self, x):\n        # x: (batch, in_channels, D, H, W)\n        # Flax expects (batch, D, H, W, C)\n        x = jnp.transpose(x, (0, 2, 3, 4, 1))\n        kernel_shape = (self.kernel_size, self.kernel_size, self.kernel_size)\n        x = nn.ConvTranspose(\n            features=self.features,\n            kernel_size=kernel_shape,\n            strides=(self.strides, self.strides, self.strides),\n            padding=[(self.padding, self.padding)] * 3,\n            feature_group_count=1,\n            use_bias=True,\n            dtype=jnp.float32,\n            name=\"conv_transpose3d\"\n        )(x)\n        # Back to (batch, channels, D, H, W)\n        x = jnp.transpose(x, (0, 4, 1, 2, 3))\n        return x\n\nclass Model(nn.Module):\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    stride: int\n    padding: int\n    bias_shape: tuple\n\n    def setup(self):\n        self.conv_transpose = ConvTranspose3d(\n            features=self.out_channels,\n            kernel_size=self.kernel_size,\n            strides=self.stride,\n            padding=self.padding\n        )\n        self.bias = self.param('bias', nn.initializers.normal(), self.bias_shape)\n\n    def __call__(self, x):\n        x = self.conv_transpose(x)\n        x = jax.scipy.special.logsumexp(x, axis=1, keepdims=True)\n        x = x * jax.nn.sigmoid(x + 3) / 6\n        x = x - self.bias\n        x = jnp.clip(x, a_min=-1, a_max=1)\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\nbias_shape = (1, 1, 1, 1)\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, in_channels, depth, height, width).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, bias_shape]"}
{"kb_id": "kb_level_2_0054", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.74774774774775, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0054.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0054_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, applies Swish activation, and scales the result.\n    \"\"\"\n    def __init__(self, in_features, out_features, scaling_factor):\n        super(Model, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        x = self.matmul(x)\n        x = x * torch.sigmoid(x)  # Swish activation\n        x = x * self.scaling_factor\n        return x\n\nbatch_size = 128\nin_features = 32768\nout_features = 32768\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, applies Swish activation, and scales the result.\n    \"\"\"\n    in_features: int\n    out_features: int\n    scaling_factor: float\n\n    @nn.compact\n    def __call__(self, x):\n        x = nn.Dense(self.out_features)(x)\n        x = x * jax.nn.sigmoid(x)  # Swish activation\n        x = x * self.scaling_factor\n        return x\n\nbatch_size = 128\nin_features = 32768\nout_features = 32768\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, in_features).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor]"}
{"kb_id": "kb_level_2_0055", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.87364620938628, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0055.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0055_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, subtracts a bias term, and applies tanh activation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, bias_shape, stride=2, padding=1, output_padding=1):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.bias = nn.Parameter(torch.randn(bias_shape)) \n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = x - self.bias\n        x = torch.tanh(x)\n        return x\n\nbatch_size = 32\nin_channels  = 64  \nout_channels = 64  \nheight = width = 256 \nkernel_size = 4\nbias_shape = (out_channels, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, bias_shape]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, subtracts a bias term, and applies tanh activation.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    bias_shape: tuple\n    stride: int = 2\n    padding: int = 1\n    output_padding: int = 1\n\n    @nn.compact\n    def __call__(self, x):\n        # Flax ConvTranspose uses (batch, height, width, channels)\n        # Input x is expected to be (batch, in_channels, height, width), so we need to transpose\n        x = jnp.transpose(x, (0, 2, 3, 1))  # (N, H, W, C)\n        conv = nn.ConvTranspose(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size),\n            strides=(self.stride, self.stride),\n            padding=[(self.padding, self.padding), (self.padding, self.padding)],\n            use_bias=False,\n            name=\"conv_transpose\"\n        )\n        x = conv(x)\n        # Add output_padding by slicing or padding if needed\n        if self.output_padding > 0:\n            pad_h = self.output_padding\n            pad_w = self.output_padding\n            x = jnp.pad(x, ((0,0), (0,pad_h), (0,pad_w), (0,0)))\n            # Optionally, you may want to slice to exact shape if needed\n\n        bias = self.param('bias', jax.nn.initializers.normal(), self.bias_shape)\n        # bias shape: (out_channels, 1, 1)\n        # x shape: (batch, H, W, out_channels)\n        # Reshape bias for broadcasting\n        bias_broadcast = bias.reshape((1, 1, 1, self.out_channels))\n        x = x - bias_broadcast\n        x = jnp.tanh(x)\n        # Transpose back to (batch, channels, height, width)\n        x = jnp.transpose(x, (0, 3, 1, 2))\n        return x\n\nbatch_size = 32\nin_channels  = 64  \nout_channels = 64  \nheight = width = 256 \nkernel_size = 4\nbias_shape = (out_channels, 1, 1)\n\ndef get_inputs():\n    # Return a list with a single input array, shape (batch, in_channels, height, width)\n    key = jax.random.PRNGKey(0)\n    x = jax.random.uniform(key, (batch_size, in_channels, height, width))\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, bias_shape]"}
{"kb_id": "kb_level_2_0056", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0056.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0056_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, applies Swish activation, \n    group normalization, and then HardSwish activation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, groups, eps, bias=True):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, bias=bias)\n        self.group_norm = nn.GroupNorm(num_groups=groups, num_channels=out_channels, eps=eps)\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = torch.sigmoid(x) * x  # Swish activation\n        x = self.group_norm(x)\n        x = torch.nn.functional.hardswish(x)  # HardSwish activation\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\ngroups = 4\neps = 1e-5\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, groups, eps]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, applies Swish activation, \n    group normalization, and then HardSwish activation.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    stride: int\n    padding: int\n    groups: int\n    eps: float\n    bias: bool = True\n\n    @nn.compact\n    def __call__(self, x):\n        # Flax ConvTranspose3D expects (N, D, H, W, C), so we need to permute\n        # PyTorch: (N, C, D, H, W) -> Flax: (N, D, H, W, C)\n        x = jnp.transpose(x, (0, 2, 3, 4, 1))\n        x = nn.ConvTranspose(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size, self.kernel_size),\n            strides=(self.stride, self.stride, self.stride),\n            padding=[(self.padding, self.padding)]*3,\n            use_bias=self.bias,\n            dimension_numbers=('NDHWC', 'DHWIO', 'NDHWC')\n        )(x)\n        # Swish activation: sigmoid(x) * x\n        x = jax.nn.sigmoid(x) * x\n        # GroupNorm expects (N, ..., C) so NDHWC is fine\n        x = nn.GroupNorm(num_groups=self.groups, epsilon=self.eps)(x)\n        # HardSwish: x * relu6(x + 3) / 6\n        x = x * jnp.clip(x + 3, 0, 6) / 6\n        # Back to (N, C, D, H, W)\n        x = jnp.transpose(x, (0, 4, 1, 2, 3))\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\ngroups = 4\neps = 1e-5\n\ndef get_inputs():\n    # PyTorch: (N, C, D, H, W)\n    return [jnp.random.rand(batch_size, in_channels, depth, height, width).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, groups, eps]"}
{"kb_id": "kb_level_2_0057", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0057.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0057_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed 3D convolution, applies ReLU, and then applies group normalization.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, groups, bias=False):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, bias=bias)\n        self.relu = nn.ReLU()\n        self.group_norm = nn.GroupNorm(num_groups=groups, num_channels=out_channels)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, D, H, W).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, D, H, W).\n        \"\"\"\n        x = self.conv_transpose(x)\n        x = self.relu(x)\n        x = self.group_norm(x)\n        return x\n\nbatch_size = 16\nin_channels = 64\nout_channels = 128\nD, H, W = 32, 32, 32\nkernel_size = 3\ngroups = 8\nbias = False\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, D, H, W)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, groups, bias]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass GroupNorm3D(nn.Module):\n    num_groups: int\n    num_channels: int\n    eps: float = 1e-5\n    use_bias: bool = True\n    use_scale: bool = True\n\n    @nn.compact\n    def __call__(self, x):\n        # x: (batch, channels, D, H, W)\n        B, C, D, H, W = x.shape\n        assert C == self.num_channels, \"Input channels must match num_channels\"\n        G = self.num_groups\n        assert C % G == 0, \"num_channels must be divisible by num_groups\"\n        x = x.reshape(B, G, C // G, D, H, W)\n        mean = jnp.mean(x, axis=(2,3,4,5), keepdims=True)\n        var = jnp.var(x, axis=(2,3,4,5), keepdims=True)\n        x = (x - mean) / jnp.sqrt(var + self.eps)\n        x = x.reshape(B, C, D, H, W)\n        if self.use_scale:\n            gamma = self.param('gamma', nn.initializers.ones, (1, C, 1, 1, 1))\n            x = x * gamma\n        if self.use_bias:\n            beta = self.param('beta', nn.initializers.zeros, (1, C, 1, 1, 1))\n            x = x + beta\n        return x\n\nclass ConvTranspose3d(nn.Module):\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    bias: bool = False\n\n    @nn.compact\n    def __call__(self, x):\n        # x: (batch, in_channels, D, H, W)\n        # Flax ConvTranspose expects (batch, D, H, W, in_channels)\n        x = jnp.transpose(x, (0,2,3,4,1))\n        conv = nn.ConvTranspose(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size, self.kernel_size),\n            strides=(1,1,1),\n            padding='SAME',\n            use_bias=self.bias,\n            feature_group_count=1,\n            dtype=x.dtype,\n            dimension_numbers=('NDHWC', 'DHWIO', 'NDHWC')\n        )\n        x = conv(x)\n        # Back to (batch, out_channels, D, H, W)\n        x = jnp.transpose(x, (0,4,1,2,3))\n        return x\n\nclass Model(nn.Module):\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    groups: int\n    bias: bool = False\n\n    @nn.compact\n    def __call__(self, x):\n        x = ConvTranspose3d(\n            in_channels=self.in_channels,\n            out_channels=self.out_channels,\n            kernel_size=self.kernel_size,\n            bias=self.bias\n        )(x)\n        x = nn.relu(x)\n        x = GroupNorm3D(\n            num_groups=self.groups,\n            num_channels=self.out_channels\n        )(x)\n        return x\n\nbatch_size = 16\nin_channels = 64\nout_channels = 128\nD, H, W = 32, 32, 32\nkernel_size = 3\ngroups = 8\nbias = False\n\ndef get_inputs():\n    # Return a list with a single input array of shape (batch, in_channels, D, H, W)\n    key = jax.random.PRNGKey(0)\n    x = jax.random.uniform(key, (batch_size, in_channels, D, H, W))\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, groups, bias]"}
{"kb_id": "kb_level_2_0058", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0058.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0058_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a matrix multiplication, group normalization, leaky ReLU activation, and element-wise sum.\n    \"\"\"\n    def __init__(self, input_size, hidden_size, num_groups, eps=1e-5, negative_slope=0.01):\n        super(Model, self).__init__()\n        self.fc = nn.Linear(input_size, hidden_size)\n        self.gn = nn.GroupNorm(num_groups=num_groups, num_channels=hidden_size, eps=eps)\n        self.leaky_relu = nn.LeakyReLU(negative_slope=negative_slope)\n\n    def forward(self, x):\n        \"\"\"\n        Performs the forward pass of the model.\n\n        Args:\n            x: Input tensor of shape (batch_size, input_size).\n\n        Returns:\n            Output tensor of shape (batch_size, hidden_size).\n        \"\"\"\n        x = self.fc(x)\n        x = self.gn(x)\n        x = self.leaky_relu(x)\n        x = x + x\n        return x\n\n\nbatch_size = 1024\ninput_size = 8192\nhidden_size = 8192\nnum_groups = 512\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, num_groups]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a matrix multiplication, group normalization, leaky ReLU activation, and element-wise sum.\n    \"\"\"\n    input_size: int\n    hidden_size: int\n    num_groups: int\n    eps: float = 1e-5\n    negative_slope: float = 0.01\n\n    @nn.compact\n    def __call__(self, x):\n        # Linear layer\n        x = nn.Dense(self.hidden_size)(x)\n        # GroupNorm expects (batch, ..., channels), so we add a dummy spatial dim\n        # to match (batch, 1, channels), then remove it after normalization\n        x = x[:, None, :]\n        x = nn.GroupNorm(num_groups=self.num_groups, epsilon=self.eps)(x)\n        x = x[:, 0, :]\n        # LeakyReLU\n        x = jnp.where(x > 0, x, self.negative_slope * x)\n        # Element-wise sum (x + x)\n        x = x + x\n        return x\n\nbatch_size = 1024\ninput_size = 8192\nhidden_size = 8192\nnum_groups = 512\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, num_groups]"}
{"kb_id": "kb_level_2_0059", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0059.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0059_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, applies ReLU, and divides by a constant.\n    \"\"\"\n    def __init__(self, in_features, out_features, divisor):\n        super(Model, self).__init__()\n        self.linear = nn.Linear(in_features, out_features)\n        self.divisor = divisor\n\n    def forward(self, x):\n        x = self.linear(x)\n        x = torch.relu(x)\n        x = x / self.divisor\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\ndivisor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, divisor]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, applies ReLU, and divides by a constant.\n    \"\"\"\n    in_features: int\n    out_features: int\n    divisor: float\n\n    @nn.compact\n    def __call__(self, x):\n        x = nn.Dense(self.out_features)(x)\n        x = jax.nn.relu(x)\n        x = x / self.divisor\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\ndivisor = 2.0\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, in_features).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [in_features, out_features, divisor]"}
{"kb_id": "kb_level_2_0060", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0060.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0060_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a matrix multiplication (Gemm), followed by LogSumExp, LeakyReLU, \n    LeakyReLU, GELU, and GELU activations.\n    \"\"\"\n    def __init__(self, in_features, out_features, bias=True):\n        super(Model, self).__init__()\n        self.linear = nn.Linear(in_features, out_features, bias=bias)\n\n    def forward(self, x):\n        # Gemm\n        x = self.linear(x)\n        # LogSumExp\n        x = torch.logsumexp(x, dim=1, keepdim=True)\n        # LeakyReLU\n        x = torch.nn.functional.leaky_relu(x, negative_slope=0.01)\n        # LeakyReLU\n        x = torch.nn.functional.leaky_relu(x, negative_slope=0.01)\n        # GELU\n        x = torch.nn.functional.gelu(x)\n        # GELU\n        x = torch.nn.functional.gelu(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a matrix multiplication (Gemm), followed by LogSumExp, LeakyReLU, \n    LeakyReLU, GELU, and GELU activations.\n    \"\"\"\n    in_features: int\n    out_features: int\n    bias: bool = True\n\n    @nn.compact\n    def __call__(self, x):\n        # Gemm\n        x = nn.Dense(self.out_features, use_bias=self.bias)(x)\n        # LogSumExp\n        x = jax.nn.logsumexp(x, axis=1, keepdims=True)\n        # LeakyReLU\n        x = jax.nn.leaky_relu(x, negative_slope=0.01)\n        # LeakyReLU\n        x = jax.nn.leaky_relu(x, negative_slope=0.01)\n        # GELU\n        x = jax.nn.gelu(x)\n        # GELU\n        x = jax.nn.gelu(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, in_features).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [in_features, out_features]"}
{"kb_id": "kb_level_2_0061", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0061.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0061_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    This model performs a convolution, average pooling, applies sigmoid, and sums the result.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, pool_kernel_size):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.avg_pool = nn.AvgPool2d(pool_kernel_size)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.avg_pool(x)\n        x = torch.sigmoid(x)\n        x = torch.sum(x, dim=[1,2,3]) # Sum over all spatial dimensions\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 384, 384\nkernel_size = 3\npool_kernel_size = 4\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, pool_kernel_size]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    This model performs a convolution, average pooling, applies sigmoid, and sums the result.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    pool_kernel_size: int\n\n    @nn.compact\n    def __call__(self, x):\n        x = nn.Conv(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size),\n            strides=(1, 1),\n            padding='SAME',\n            use_bias=True\n        )(x)\n        x = nn.avg_pool(\n            x,\n            window_shape=(self.pool_kernel_size, self.pool_kernel_size),\n            strides=(self.pool_kernel_size, self.pool_kernel_size),\n            padding='VALID'\n        )\n        x = jax.nn.sigmoid(x)\n        x = jnp.sum(x, axis=(1, 2, 3))  # Sum over all spatial dimensions\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 384, 384\nkernel_size = 3\npool_kernel_size = 4\n\ndef get_inputs():\n    # Flax expects NHWC by default, but Conv2d in PyTorch uses NCHW.\n    # We'll keep NCHW for compatibility, and set data_format='NCHW' in Conv if needed.\n    # But Flax's nn.Conv expects NHWC, so we need to transpose.\n    x = jax.random.uniform(\n        jax.random.PRNGKey(0),\n        (batch_size, in_channels, height, width),\n        minval=0.0,\n        maxval=1.0\n    )\n    # Transpose to NHWC for Flax\n    x = jnp.transpose(x, (0, 2, 3, 1))\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, pool_kernel_size]"}
{"kb_id": "kb_level_2_0062", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0062.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0062_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs matrix multiplication, applies dropout, and then applies softmax.\n    \"\"\"\n    def __init__(self, in_features, out_features, dropout_p):\n        super(Model, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.dropout = nn.Dropout(dropout_p)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.matmul(x)\n        x = self.dropout(x)\n        x = torch.softmax(x, dim=1)  # Softmax over features\n        return x\n\nbatch_size = 128\nin_features = 16384\nout_features = 16384\ndropout_p = 0.2\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, dropout_p]\n", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\nfrom typing import Any, Callable\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs matrix multiplication, applies dropout, and then applies softmax.\n    \"\"\"\n    in_features: int\n    out_features: int\n    dropout_p: float\n\n    @nn.compact\n    def __call__(self, x, *, train: bool, rng=None):\n        x = nn.Dense(self.out_features)(x)\n        x = nn.Dropout(rate=self.dropout_p, deterministic=not train)(x, deterministic=not train, rng=rng)\n        x = nn.softmax(x, axis=1)  # Softmax over features\n        return x\n\nbatch_size = 128\nin_features = 16384\nout_features = 16384\ndropout_p = 0.2\n\ndef get_inputs():\n    # Returns a list with a single JAX array of shape (batch_size, in_features)\n    key = jax.random.PRNGKey(0)\n    x = jax.random.uniform(key, (batch_size, in_features))\n    return [x]\n\ndef get_init_inputs():\n    # Returns a list of model init arguments\n    return [in_features, out_features, dropout_p]"}
{"kb_id": "kb_level_2_0063", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 67.55671902268762, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0063.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0063_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, applies GELU, and then performs global average pooling.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x: Input tensor of shape (batch_size, in_channels, height, width)\n        Returns:\n            Output tensor of shape (batch_size, out_channels)\n        \"\"\"\n        x = self.conv(x)\n        x = torch.nn.functional.gelu(x)\n        x = torch.nn.functional.adaptive_avg_pool2d(x, 1)\n        x = x.squeeze(-1).squeeze(-1)\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 256, 256\nkernel_size = 3\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, applies GELU, and then performs global average pooling.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n\n    @nn.compact\n    def __call__(self, x):\n        \"\"\"\n        Args:\n            x: Input tensor of shape (batch_size, in_channels, height, width)\n        Returns:\n            Output tensor of shape (batch_size, out_channels)\n        \"\"\"\n        # Flax Conv expects (N, H, W, C), so we need to transpose\n        x = jnp.transpose(x, (0, 2, 3, 1))  # (N, H, W, C)\n        x = nn.Conv(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size),\n            strides=(1, 1),\n            padding='SAME',\n            use_bias=True,\n        )(x)\n        x = nn.gelu(x)\n        # Global average pooling over spatial dims (H, W)\n        x = jnp.mean(x, axis=(1, 2))  # (N, out_channels)\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 256, 256\nkernel_size = 3\n\ndef get_inputs():\n    # Return a list with a single input array, shape (batch_size, in_channels, height, width)\n    key = jax.random.PRNGKey(0)\n    x = jax.random.uniform(key, (batch_size, in_channels, height, width))\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]"}
{"kb_id": "kb_level_2_0064", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 67.4390243902439, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0064.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0064_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, applies minimum, and subtracts a constant.\n    \"\"\"\n    def __init__(self, in_features, out_features, constant):\n        super(Model, self).__init__()\n        self.linear = nn.Linear(in_features, out_features)\n        self.constant = nn.Parameter(torch.tensor(constant))\n\n    def forward(self, x):\n        x = self.linear(x)\n        x = torch.min(x, self.constant)\n        x = x - self.constant\n        return x\n\nbatch_size = 128\nin_features = 16384\nout_features = 16384\nconstant = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, constant]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, applies minimum, and subtracts a constant.\n    \"\"\"\n    in_features: int\n    out_features: int\n    constant: float\n\n    @nn.compact\n    def __call__(self, x):\n        x = nn.Dense(self.out_features)(x)\n        const = self.constant\n        x = jnp.minimum(x, const)\n        x = x - const\n        return x\n\nbatch_size = 128\nin_features = 16384\nout_features = 16384\nconstant = 2.0\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, in_features).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [in_features, out_features, constant]"}
{"kb_id": "kb_level_2_0065", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 67.55671902268762, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0065.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0065_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a convolution, applies HardSwish, and then ReLU.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height, width).\n        \"\"\"\n        x = self.conv(x)\n        x = torch.nn.functional.hardswish(x)\n        x = torch.relu(x)\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 128, 128\nkernel_size = 3\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a convolution, applies HardSwish, and then ReLU.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n\n    @nn.compact\n    def __call__(self, x):\n        x = nn.Conv(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size),\n            strides=(1, 1),\n            padding='SAME',\n            use_bias=True,\n        )(x)\n        # HardSwish: x * relu6(x + 3) / 6\n        x = x * jnp.clip(x + 3, 0, 6) / 6\n        x = jnp.maximum(x, 0)\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 128, 128\nkernel_size = 3\n\ndef get_inputs():\n    # Flax expects NHWC by default, but we keep NCHW for parity with PyTorch\n    # So we will use data_format='NCHW' in Conv if needed, but Flax Conv expects NHWC\n    # Let's transpose input to NHWC for Flax\n    x = jax.random.uniform(\n        jax.random.PRNGKey(0),\n        (batch_size, in_channels, height, width),\n        minval=0.0,\n        maxval=1.0\n    )\n    # Transpose to NHWC for Flax Conv\n    x = jnp.transpose(x, (0, 2, 3, 1))\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]"}
{"kb_id": "kb_level_2_0066", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 68.75666074600356, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0066.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0066_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, applies Softmax, and performs two max pooling operations.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, pool_kernel_size):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size)\n        self.pool1 = nn.MaxPool3d(pool_kernel_size)\n        self.pool2 = nn.MaxPool3d(pool_kernel_size)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x: Input tensor of shape (batch_size, in_channels, depth, height, width)\n        Returns:\n            Output tensor of shape (batch_size, out_channels, depth', height', width') where depth', height', width' are the dimensions after pooling.\n        \"\"\"\n        x = self.conv(x)\n        x = torch.softmax(x, dim=1)\n        x = self.pool1(x)\n        x = self.pool2(x)\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 3\npool_kernel_size = 2\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, pool_kernel_size]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, applies Softmax, and performs two max pooling operations.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    pool_kernel_size: int\n\n    @nn.compact\n    def __call__(self, x):\n        # Conv3D in Flax expects (N, D, H, W, C), so we need to transpose\n        # Input: (N, C, D, H, W) -> (N, D, H, W, C)\n        x = jnp.transpose(x, (0, 2, 3, 4, 1))\n        x = nn.Conv(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size, self.kernel_size),\n            strides=(1, 1, 1),\n            padding='SAME',\n            use_bias=True,\n        )(x)\n        # Softmax along channel axis (last axis after transpose)\n        x = nn.softmax(x, axis=-1)\n        # MaxPool3D: pool over (D, H, W)\n        x = nn.max_pool(\n            x,\n            window_shape=(self.pool_kernel_size, self.pool_kernel_size, self.pool_kernel_size),\n            strides=(self.pool_kernel_size, self.pool_kernel_size, self.pool_kernel_size),\n            padding='SAME'\n        )\n        x = nn.max_pool(\n            x,\n            window_shape=(self.pool_kernel_size, self.pool_kernel_size, self.pool_kernel_size),\n            strides=(self.pool_kernel_size, self.pool_kernel_size, self.pool_kernel_size),\n            padding='SAME'\n        )\n        # Transpose back to (N, C, D, H, W)\n        x = jnp.transpose(x, (0, 4, 1, 2, 3))\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 3\npool_kernel_size = 2\n\ndef get_inputs():\n    # Return a list with a single input array of shape (batch_size, in_channels, depth, height, width)\n    key = jax.random.PRNGKey(0)\n    x = jax.random.uniform(\n        key,\n        (batch_size, in_channels, depth, height, width),\n        minval=0.0,\n        maxval=1.0\n    )\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, pool_kernel_size]"}
{"kb_id": "kb_level_2_0067", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 68.03163444639719, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0067.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0067_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model implementing the pattern \"Gemm_Sigmoid_Scaling_ResidualAdd\".\n    \"\"\"\n    def __init__(self, input_size, hidden_size, scaling_factor):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(input_size, hidden_size)\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        \"\"\"\n        Forward pass of the model.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, input_size).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, hidden_size).\n        \"\"\"\n        x = self.gemm(x)\n        original_x = x\n        x = torch.sigmoid(x)\n        x = x * self.scaling_factor\n        x = x + original_x\n        return x\n\nbatch_size = 1024\ninput_size = 8192\nhidden_size = 8192\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, scaling_factor]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model implementing the pattern \"Gemm_Sigmoid_Scaling_ResidualAdd\".\n    \"\"\"\n    input_size: int\n    hidden_size: int\n    scaling_factor: float\n\n    @nn.compact\n    def __call__(self, x):\n        \"\"\"\n        Forward pass of the model.\n\n        Args:\n            x (jnp.ndarray): Input tensor of shape (batch_size, input_size).\n\n        Returns:\n            jnp.ndarray: Output tensor of shape (batch_size, hidden_size).\n        \"\"\"\n        x = nn.Dense(self.hidden_size)(x)\n        original_x = x\n        x = jax.nn.sigmoid(x)\n        x = x * self.scaling_factor\n        x = x + original_x\n        return x\n\nbatch_size = 1024\ninput_size = 8192\nhidden_size = 8192\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, scaling_factor]"}
{"kb_id": "kb_level_2_0068", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 68.3922261484099, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0068.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0068_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, divides by a constant, and applies LeakyReLU.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, divisor):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.divisor = divisor\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x / self.divisor\n        x = torch.nn.functional.leaky_relu(x, negative_slope=0.01)\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 128, 128\nkernel_size = 3\ndivisor = 2\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, divisor]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, divides by a constant, and applies LeakyReLU.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    divisor: float\n\n    @nn.compact\n    def __call__(self, x):\n        x = nn.Conv(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size),\n            strides=(1, 1),\n            padding='SAME',\n            use_bias=True\n        )(x)\n        x = x / self.divisor\n        x = jax.nn.leaky_relu(x, negative_slope=0.01)\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 128, 128\nkernel_size = 3\ndivisor = 2\n\ndef get_inputs():\n    # Flax expects NHWC by default, but we use NCHW to match PyTorch, so set data_format in Conv if needed.\n    # Here, we use NCHW to match the original.\n    return [jnp.random.rand(batch_size, in_channels, height, width).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, divisor]"}
{"kb_id": "kb_level_2_0069", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0069.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0069_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a 3D transposed convolution, followed by batch normalization, \n    two average pooling layers.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bias_shape):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n        self.batch_norm = nn.BatchNorm3d(out_channels)\n        self.avg_pool1 = nn.AvgPool3d(kernel_size=2)\n        self.avg_pool2 = nn.AvgPool3d(kernel_size=2)\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = self.batch_norm(x)\n        x = self.avg_pool1(x)\n        x = self.avg_pool2(x)\n        return x\n\n\nbatch_size = 64\nin_channels = 3\nout_channels = 16\ndepth, height, width = 32, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\nbias_shape = (out_channels, 1, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, bias_shape]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a 3D transposed convolution, followed by batch normalization, \n    two average pooling layers.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    stride: int\n    padding: int\n    bias_shape: tuple\n\n    @nn.compact\n    def __call__(self, x, train=True):\n        # Flax ConvTranspose3D expects (N, D, H, W, C), so we need to transpose\n        # PyTorch uses (N, C, D, H, W)\n        x = jnp.transpose(x, (0, 2, 3, 4, 1))\n        x = nn.ConvTranspose(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size, self.kernel_size),\n            strides=(self.stride, self.stride, self.stride),\n            padding=[(self.padding, self.padding)]*3,\n            use_bias=True,\n            dimension_numbers=('NDHWC', 'DHWIO', 'NDHWC')\n        )(x)\n        x = nn.BatchNorm(use_running_average=not train, axis=-1)(x)\n        # Average pooling in Flax expects (N, D, H, W, C)\n        x = nn.avg_pool(x, window_shape=(2, 2, 2), strides=(2, 2, 2), padding='VALID')\n        x = nn.avg_pool(x, window_shape=(2, 2, 2), strides=(2, 2, 2), padding='VALID')\n        # Transpose back to (N, C, D, H, W)\n        x = jnp.transpose(x, (0, 4, 1, 2, 3))\n        return x\n\nbatch_size = 64\nin_channels = 3\nout_channels = 16\ndepth, height, width = 32, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\nbias_shape = (out_channels, 1, 1, 1)\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, in_channels, depth, height, width).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, bias_shape]"}
{"kb_id": "kb_level_2_0070", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 68.63475177304966, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0070.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0070_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, applies Batch Normalization, and scales the output.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, scaling_factor):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.bn = nn.BatchNorm2d(out_channels)\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        x = x * self.scaling_factor\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 128, 128\nkernel_size = 3\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, scaling_factor]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, applies Batch Normalization, and scales the output.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    scaling_factor: float\n\n    @nn.compact\n    def __call__(self, x, *, train=True):\n        x = nn.Conv(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size),\n            use_bias=True,\n            padding='SAME'\n        )(x)\n        x = nn.BatchNorm(use_running_average=not train, axis=1)(x)\n        x = x * self.scaling_factor\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 128, 128\nkernel_size = 3\nscaling_factor = 2.0\n\ndef get_inputs():\n    # Flax expects NCHW by default for Conv/BatchNorm if axis=1\n    return [jnp.random.rand(batch_size, in_channels, height, width).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, scaling_factor]"}
{"kb_id": "kb_level_2_0072", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.49730700179532, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0072.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0072_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a GEMM, Group Normalization, Minimum operation, and Bias addition.\n    \"\"\"\n    def __init__(self, in_features, out_features, num_groups, bias_shape):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.group_norm = nn.GroupNorm(num_groups, out_features)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n\n    def forward(self, x):\n        x = self.gemm(x)\n        x = self.group_norm(x)\n        x = torch.min(x, dim=1, keepdim=True)[0] \n        x = x + self.bias\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nnum_groups = 512\nbias_shape = (1, out_features, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, num_groups, bias_shape]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a GEMM, Group Normalization, Minimum operation, and Bias addition.\n    \"\"\"\n    in_features: int\n    out_features: int\n    num_groups: int\n    bias_shape: tuple\n\n    @nn.compact\n    def __call__(self, x):\n        # GEMM (Linear)\n        x = nn.Dense(self.out_features)(x)\n        # GroupNorm expects (N, ..., C), so add a dummy spatial dimension to match PyTorch's (N, C, H, W)\n        x = x[:, None, :]  # (N, 1, C)\n        # Flax GroupNorm expects features as the last dim, so transpose to (N, 1, C)\n        x = nn.GroupNorm(num_groups=self.num_groups, epsilon=1e-5, use_bias=True, use_scale=True)(x)\n        # Min over the \"spatial\" dimension (axis=1), keepdim=True\n        x = jnp.min(x, axis=1, keepdims=True)  # (N, 1, C)\n        # Add bias: bias shape is (1, out_features, 1, 1), need to broadcast to (N, 1, C)\n        # We'll define bias as a parameter\n        bias = self.param('bias', nn.initializers.normal(), self.bias_shape)\n        # Reshape bias to (1, 1, C) to match (N, 1, C)\n        bias_reshaped = jnp.reshape(bias, (1, 1, self.out_features))\n        x = x + bias_reshaped\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nnum_groups = 512\nbias_shape = (1, out_features, 1, 1)\n\ndef get_inputs():\n    # Return a list with a single input array of shape (batch_size, in_features)\n    return [jnp.random.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, num_groups, bias_shape]"}
{"kb_id": "kb_level_2_0073", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0073.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0073_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, adds a bias term, and applies ReLU.\n    \"\"\"\n    def __init__(self, in_features, out_features, bias_shape):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features, bias=False)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor with shape (batch_size, in_features).\n        Returns:\n            torch.Tensor: Output tensor with shape (batch_size, out_features).\n        \"\"\"\n        x = self.gemm(x)\n        x = x + self.bias\n        x = torch.relu(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nbias_shape = (out_features,)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, bias_shape]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, adds a bias term, and applies ReLU.\n    \"\"\"\n    in_features: int\n    out_features: int\n    bias_shape: tuple\n\n    @nn.compact\n    def __call__(self, x):\n        # Linear layer without bias\n        x = nn.Dense(self.out_features, use_bias=False)(x)\n        # Custom bias parameter\n        bias = self.param('bias', jax.nn.initializers.normal(), self.bias_shape)\n        x = x + bias\n        x = jax.nn.relu(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nbias_shape = (out_features,)\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, bias_shape]"}
{"kb_id": "kb_level_2_0074", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0074.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0074_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, scales the output, applies batch normalization, \n    and then performs global average pooling. \n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, scale_factor, eps=1e-5, momentum=0.1):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size)\n        self.scale_factor = scale_factor\n        self.batch_norm = nn.BatchNorm3d(out_channels, eps=eps, momentum=momentum)\n        self.global_avg_pool = nn.AdaptiveAvgPool3d((1, 1, 1))\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = x * self.scale_factor\n        x = self.batch_norm(x)\n        x = self.global_avg_pool(x)\n        return x\n\nbatch_size = 16\nin_channels = 64\nout_channels = 128\ndepth, height, width = 16, 32, 32\nkernel_size = 5\nscale_factor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, scale_factor]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, scales the output, applies batch normalization, \n    and then performs global average pooling. \n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    scale_factor: float\n    eps: float = 1e-5\n    momentum: float = 0.1\n\n    @nn.compact\n    def __call__(self, x, train=True):\n        # ConvTranspose3d in PyTorch uses (N, C, D, H, W)\n        x = nn.ConvTranspose(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size, self.kernel_size),\n            strides=(1, 1, 1),\n            padding='SAME',\n            use_bias=True,\n            dimension_numbers=('NCDHW', 'OIDHW', 'NCDHW')\n        )(x)\n        x = x * self.scale_factor\n        x = nn.BatchNorm(\n            use_running_average=not train,\n            momentum=self.momentum,\n            epsilon=self.eps,\n            axis=1,  # channel axis for NCDHW\n        )(x)\n        # Global average pooling over D, H, W (axes 2, 3, 4)\n        x = jnp.mean(x, axis=(2, 3, 4), keepdims=True)\n        return x\n\nbatch_size = 16\nin_channels = 64\nout_channels = 128\ndepth, height, width = 16, 32, 32\nkernel_size = 5\nscale_factor = 2.0\n\ndef get_inputs():\n    # Return a list with a single input array, matching PyTorch's shape (N, C, D, H, W)\n    key = jax.random.PRNGKey(0)\n    x = jax.random.uniform(\n        key, (batch_size, in_channels, depth, height, width), minval=0.0, maxval=1.0\n    )\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, scale_factor]"}
{"kb_id": "kb_level_2_0075", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0075.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0075_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, followed by two max pooling layers and a sum operation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n        self.max_pool1 = nn.MaxPool3d(kernel_size=2)\n        self.max_pool2 = nn.MaxPool3d(kernel_size=3)\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = self.max_pool1(x)\n        x = self.max_pool2(x)\n        x = torch.sum(x, dim=1, keepdim=True) \n        return x\n\nbatch_size = 16\nin_channels = 32\nout_channels = 64\ndepth, height, width = 32, 32, 32\nkernel_size = 5\nstride = 2\npadding = 2\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, followed by two max pooling layers and a sum operation.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    stride: int\n    padding: int\n\n    @nn.compact\n    def __call__(self, x):\n        # ConvTranspose3d in PyTorch: (N, C_in, D, H, W) -> (N, C_out, D_out, H_out, W_out)\n        x = nn.ConvTranspose(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size, self.kernel_size),\n            strides=(self.stride, self.stride, self.stride),\n            padding=[(self.padding, self.padding)]*3,\n            use_bias=True,\n            dimension_numbers=('NCDHW', 'OIDHW', 'NCDHW')\n        )(x)\n        # MaxPool3d with kernel_size=2\n        x = nn.max_pool(\n            x,\n            window_shape=(1, 2, 2, 2, 1),\n            strides=(1, 2, 2, 2, 1),\n            padding='VALID'\n        )\n        # MaxPool3d with kernel_size=3\n        x = nn.max_pool(\n            x,\n            window_shape=(1, 3, 3, 3, 1),\n            strides=(1, 3, 3, 3, 1),\n            padding='VALID'\n        )\n        # Sum over channel dimension (axis=1), keepdim=True\n        x = jnp.sum(x, axis=1, keepdims=True)\n        return x\n\nbatch_size = 16\nin_channels = 32\nout_channels = 64\ndepth, height, width = 32, 32, 32\nkernel_size = 5\nstride = 2\npadding = 2\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, in_channels, depth, height, width).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding]"}
{"kb_id": "kb_level_2_0076", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0076.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0076_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A 3D convolutional layer followed by multiplication, instance normalization, clamping, multiplication, and a max operation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, multiplier_shape, clamp_min, clamp_max):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size)\n        self.multiplier = nn.Parameter(torch.randn(multiplier_shape))\n        self.instance_norm = nn.InstanceNorm3d(out_channels)\n        self.clamp_min = clamp_min\n        self.clamp_max = clamp_max\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x * self.multiplier\n        x = self.instance_norm(x)\n        x = torch.clamp(x, self.clamp_min, self.clamp_max)\n        x = x * self.multiplier\n        x = torch.max(x, dim=1)[0]\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nmultiplier_shape = (out_channels, 1, 1, 1)\nclamp_min = -1.0\nclamp_max = 1.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, multiplier_shape, clamp_min, clamp_max]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A 3D convolutional layer followed by multiplication, instance normalization, clamping, multiplication, and a max operation.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    multiplier_shape: tuple\n    clamp_min: float\n    clamp_max: float\n\n    @nn.compact\n    def __call__(self, x):\n        # Conv3D: Flax expects (N, D, H, W, C), PyTorch uses (N, C, D, H, W)\n        # So we need to transpose before and after\n        x = jnp.transpose(x, (0, 2, 3, 4, 1))  # (N, D, H, W, C)\n        x = nn.Conv(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size, self.kernel_size),\n            strides=(1, 1, 1),\n            padding='SAME',\n            use_bias=True,\n        )(x)\n        # multiplier shape: (out_channels, 1, 1, 1)\n        # Flax param: (out_channels, 1, 1, 1)\n        multiplier = self.param('multiplier', nn.initializers.normal(), self.multiplier_shape)\n        # Broadcast multiplier to (1, D, H, W, out_channels)\n        multiplier_broadcast = multiplier.reshape((1,) + self.multiplier_shape)\n        x = x * multiplier_broadcast\n        # InstanceNorm3d: normalize over (D, H, W) for each sample and channel\n        # Flax nn.InstanceNorm expects (N, ..., C)\n        x = nn.InstanceNorm(axis=(1,2,3), use_scale=True, use_bias=True)(x)\n        x = jnp.clip(x, self.clamp_min, self.clamp_max)\n        x = x * multiplier_broadcast\n        # Max over channel dimension (last axis)\n        x = jnp.max(x, axis=-1)\n        # Transpose back to (N, D, H, W)\n        x = jnp.transpose(x, (0, 1, 2, 3))\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nmultiplier_shape = (out_channels, 1, 1, 1)\nclamp_min = -1.0\nclamp_max = 1.0\n\ndef get_inputs():\n    # Return a list with a single input array, shape (batch_size, in_channels, depth, height, width)\n    key = jax.random.PRNGKey(0)\n    x = jax.random.uniform(\n        key,\n        (batch_size, in_channels, depth, height, width),\n        minval=0.0,\n        maxval=1.0\n    )\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, multiplier_shape, clamp_min, clamp_max]"}
{"kb_id": "kb_level_2_0077", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.37275985663082, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0077.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0077_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, applies ReLU, LeakyReLU, GELU, Sigmoid activations, and bias in sequence.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, bias_shape):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size)\n        self.bias = nn.Parameter(torch.randn(bias_shape)) \n\n    def forward(self, x):\n        x = self.conv(x)\n        x = torch.relu(x)\n        x = torch.nn.functional.leaky_relu(x, negative_slope=0.01)\n        x = torch.nn.functional.gelu(x)\n        x = torch.sigmoid(x)\n        x = x + self.bias\n        return x\n\nbatch_size = 64\nin_channels = 8\nout_channels = 32\ndepth, height, width = 32, 64, 64\nkernel_size = 3\nbias_shape = (out_channels, 1, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, bias_shape]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, applies ReLU, LeakyReLU, GELU, Sigmoid activations, and bias in sequence.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    bias_shape: tuple\n\n    @nn.compact\n    def __call__(self, x):\n        # Flax Conv3D expects (N, D, H, W, C), so we need to transpose\n        # PyTorch: (N, C, D, H, W) -> Flax: (N, D, H, W, C)\n        x = jnp.transpose(x, (0, 2, 3, 4, 1))\n        x = nn.Conv(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size, self.kernel_size),\n            use_bias=False,\n            padding='SAME'\n        )(x)\n        x = nn.relu(x)\n        x = nn.leaky_relu(x, negative_slope=0.01)\n        x = nn.gelu(x)\n        x = nn.sigmoid(x)\n        # Add learnable bias\n        bias = self.param('bias', nn.initializers.normal(), self.bias_shape)\n        # bias shape: (out_channels, 1, 1, 1)\n        # x shape: (N, D, H, W, out_channels)\n        # Reshape bias to (1, 1, 1, 1, out_channels) for broadcasting\n        bias = jnp.reshape(bias, (1, 1, 1, 1, self.out_channels))\n        x = x + bias\n        # Transpose back to (N, C, D, H, W)\n        x = jnp.transpose(x, (0, 4, 1, 2, 3))\n        return x\n\nbatch_size = 64\nin_channels = 8\nout_channels = 32\ndepth, height, width = 32, 64, 64\nkernel_size = 3\nbias_shape = (out_channels, 1, 1, 1)\n\ndef get_inputs():\n    # Return a list with a single input array, matching PyTorch's shape: (N, C, D, H, W)\n    key = jax.random.PRNGKey(0)\n    x = jax.random.uniform(key, (batch_size, in_channels, depth, height, width))\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, bias_shape]"}
{"kb_id": "kb_level_2_0078", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.87364620938628, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0078.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0078_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a GEMM, followed by a max operation, subtraction, and GELU activation.\n    \"\"\"\n    def __init__(self, in_features, out_features, max_dim):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.max_dim = max_dim\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x: Input tensor of shape (batch_size, in_features)\n\n        Returns:\n            Output tensor of shape (batch_size, out_features)\n        \"\"\"\n        x = self.gemm(x)\n        x = torch.max(x, dim=self.max_dim, keepdim=True).values\n        x = x - x.mean(dim=1, keepdim=True)\n        x = torch.nn.functional.gelu(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nmax_dim = 1\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, max_dim]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a GEMM, followed by a max operation, subtraction, and GELU activation.\n    \"\"\"\n    in_features: int\n    out_features: int\n    max_dim: int\n\n    @nn.compact\n    def __call__(self, x):\n        \"\"\"\n        Args:\n            x: Input tensor of shape (batch_size, in_features)\n\n        Returns:\n            Output tensor of shape (batch_size, out_features)\n        \"\"\"\n        x = nn.Dense(self.out_features)(x)\n        x = jnp.max(x, axis=self.max_dim, keepdims=True)\n        x = x - jnp.mean(x, axis=1, keepdims=True)\n        x = nn.gelu(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nmax_dim = 1\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, in_features).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [in_features, out_features, max_dim]"}
{"kb_id": "kb_level_2_0079", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0079.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0079_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a gemm, swish, divide, clamp, tanh, and clamp operations.\n    \"\"\"\n    def __init__(self, in_features, out_features, bias=True):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features, bias=bias)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.gemm(x)\n        x = x * torch.sigmoid(x)  # Swish activation\n        x = x / 2.0\n        x = torch.clamp(x, min=-1.0, max=1.0)  # Clamp between -1 and 1\n        x = torch.tanh(x)  # Tanh activation\n        x = torch.clamp(x, min=-1.0, max=1.0)  # Clamp between -1 and 1\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a gemm, swish, divide, clamp, tanh, and clamp operations.\n    \"\"\"\n    in_features: int\n    out_features: int\n    bias: bool = True\n\n    @nn.compact\n    def __call__(self, x):\n        x = nn.Dense(self.out_features, use_bias=self.bias)(x)\n        x = x * jax.nn.sigmoid(x)  # Swish activation\n        x = x / 2.0\n        x = jnp.clip(x, a_min=-1.0, a_max=1.0)  # Clamp between -1 and 1\n        x = jnp.tanh(x)  # Tanh activation\n        x = jnp.clip(x, a_min=-1.0, a_max=1.0)  # Clamp between -1 and 1\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]"}
{"kb_id": "kb_level_2_0080", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0080.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0080_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a convolution, applies tanh, scaling, adds a bias term, and then max-pools.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, scaling_factor, bias_shape, pool_kernel_size):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.scaling_factor = scaling_factor\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.max_pool = nn.MaxPool2d(pool_kernel_size)\n\n    def forward(self, x):\n        # Convolution\n        x = self.conv(x)\n        # Tanh activation\n        x = torch.tanh(x)\n        # Scaling\n        x = x * self.scaling_factor\n        # Bias addition\n        x = x + self.bias\n        # Max-pooling\n        x = self.max_pool(x)\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 256, 256\nkernel_size = 3\nscaling_factor = 2.0\nbias_shape = (out_channels, 1, 1)\npool_kernel_size = 4\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, scaling_factor, bias_shape, pool_kernel_size]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a convolution, applies tanh, scaling, adds a bias term, and then max-pools.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    scaling_factor: float\n    bias_shape: tuple\n    pool_kernel_size: int\n\n    @nn.compact\n    def __call__(self, x):\n        # Convolution\n        x = nn.Conv(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size),\n            strides=(1, 1),\n            padding='SAME',\n            use_bias=False\n        )(x)\n        # Tanh activation\n        x = jnp.tanh(x)\n        # Scaling\n        x = x * self.scaling_factor\n        # Bias addition (broadcasted)\n        bias = self.param('bias', nn.initializers.normal(), self.bias_shape)\n        x = x + bias\n        # Max-pooling\n        x = nn.max_pool(\n            x,\n            window_shape=(self.pool_kernel_size, self.pool_kernel_size),\n            strides=(self.pool_kernel_size, self.pool_kernel_size),\n            padding='VALID'\n        )\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 256, 256\nkernel_size = 3\nscaling_factor = 2.0\nbias_shape = (out_channels, 1, 1)\npool_kernel_size = 4\n\ndef get_inputs():\n    # Flax expects NHWC by default, but Conv2d in PyTorch uses NCHW.\n    # We'll use NCHW for compatibility, and set Conv to use NCHW.\n    # However, Flax's nn.Conv expects NHWC, so we need to transpose.\n    # To keep the logic close to PyTorch, we generate NCHW and transpose in the model.\n    x = jax.random.uniform(jax.random.PRNGKey(0), (batch_size, in_channels, height, width))\n    # Transpose to NHWC for Flax Conv\n    x = jnp.transpose(x, (0, 2, 3, 1))\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, scaling_factor, bias_shape, pool_kernel_size]"}
{"kb_id": "kb_level_2_0081", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.37275985663082, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0081.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0081_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, applies Group Normalization, minimum, clamp, and dropout.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, groups, min_value, max_value, dropout_p):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size)\n        self.norm = nn.GroupNorm(groups, out_channels)\n        self.dropout = nn.Dropout(dropout_p)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.norm(x)\n        x = torch.min(x, torch.tensor(min_value, device=x.device))\n        x = torch.clamp(x, min=min_value, max=max_value)\n        x = self.dropout(x)\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 64, 64\nkernel_size = 3\ngroups = 8\nmin_value = 0.0\nmax_value = 1.0\ndropout_p = 0.2\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, groups, min_value, max_value, dropout_p]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\nfrom typing import Any, Callable, Sequence\n\nclass GroupNorm(nn.Module):\n    num_groups: int\n    num_channels: int\n    eps: float = 1e-5\n    affine: bool = True\n\n    @nn.compact\n    def __call__(self, x):\n        # x: (N, C, D, H, W)\n        N, C, D, H, W = x.shape\n        G = self.num_groups\n        assert C % G == 0, \"num_channels must be divisible by num_groups\"\n        x = x.reshape((N, G, C // G, D, H, W))\n        mean = jnp.mean(x, axis=(2, 3, 4, 5), keepdims=True)\n        var = jnp.var(x, axis=(2, 3, 4, 5), keepdims=True)\n        x = (x - mean) / jnp.sqrt(var + self.eps)\n        x = x.reshape((N, C, D, H, W))\n        if self.affine:\n            gamma = self.param('gamma', nn.initializers.ones, (1, C, 1, 1, 1))\n            beta = self.param('beta', nn.initializers.zeros, (1, C, 1, 1, 1))\n            x = x * gamma + beta\n        return x\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, applies Group Normalization, minimum, clamp, and dropout.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    groups: int\n    min_value: float\n    max_value: float\n    dropout_p: float\n\n    @nn.compact\n    def __call__(self, x, *, deterministic: bool = False):\n        x = nn.Conv(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size, self.kernel_size),\n            strides=(1, 1, 1),\n            padding='SAME',\n            use_bias=True\n        )(x)\n        x = GroupNorm(self.groups, self.out_channels)(x)\n        x = jnp.minimum(x, self.min_value)\n        x = jnp.clip(x, a_min=self.min_value, a_max=self.max_value)\n        x = nn.Dropout(rate=self.dropout_p)(x, deterministic=deterministic)\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 64, 64\nkernel_size = 3\ngroups = 8\nmin_value = 0.0\nmax_value = 1.0\ndropout_p = 0.2\n\ndef get_inputs():\n    # Flax expects (N, C, D, H, W) by default for Conv3D\n    return [jnp.random.rand(batch_size, in_channels, depth, height, width).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, groups, min_value, max_value, dropout_p]"}
{"kb_id": "kb_level_2_0082", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0082.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0082_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a matrix multiplication (Gemm), Batch Normalization, scaling, and Softmax.\n    \"\"\"\n    def __init__(self, in_features, out_features, bn_eps=1e-5, bn_momentum=0.1, scale_shape=(1,)):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.bn = nn.BatchNorm1d(out_features, eps=bn_eps, momentum=bn_momentum)\n        self.scale = nn.Parameter(torch.ones(scale_shape))\n        self.softmax = nn.Softmax(dim=1)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.gemm(x)\n        x = self.bn(x)\n        x = self.scale * x\n        x = self.softmax(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nbn_eps = 1e-5\nbn_momentum = 0.1\nscale_shape = (1,)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, bn_eps, bn_momentum, scale_shape]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a matrix multiplication (Gemm), Batch Normalization, scaling, and Softmax.\n    \"\"\"\n    in_features: int\n    out_features: int\n    bn_eps: float = 1e-5\n    bn_momentum: float = 0.1\n    scale_shape: tuple = (1,)\n\n    @nn.compact\n    def __call__(self, x, train: bool = True):\n        x = nn.Dense(self.out_features)(x)\n        x = nn.BatchNorm(use_running_average=not train, \n                         momentum=1.0 - self.bn_momentum, \n                         epsilon=self.bn_eps)(x)\n        scale = self.param('scale', nn.initializers.ones, self.scale_shape)\n        x = scale * x\n        x = nn.softmax(x, axis=1)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nbn_eps = 1e-5\nbn_momentum = 0.1\nscale_shape = (1,)\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, in_features).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [in_features, out_features, bn_eps, bn_momentum, scale_shape]"}
{"kb_id": "kb_level_2_0083", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.87364620938628, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0083.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0083_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs convolution, group normalization, scaling, max pooling, and clamping.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, num_groups, scale_shape, maxpool_kernel_size, clamp_min, clamp_max):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.group_norm = nn.GroupNorm(num_groups, out_channels)\n        self.scale = nn.Parameter(torch.ones(scale_shape))\n        self.maxpool = nn.MaxPool2d(kernel_size=maxpool_kernel_size)\n        self.clamp_min = clamp_min\n        self.clamp_max = clamp_max\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x: Input tensor of shape (batch_size, in_channels, height, width).\n        Returns:\n            Output tensor of shape (batch_size, out_channels, height', width').\n        \"\"\"\n        x = self.conv(x)\n        x = self.group_norm(x)\n        x = x * self.scale\n        x = self.maxpool(x)\n        x = torch.clamp(x, self.clamp_min, self.clamp_max)\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 128, 128 \nkernel_size = 3\nnum_groups = 16\nscale_shape = (out_channels, 1, 1)\nmaxpool_kernel_size = 4\nclamp_min = 0.0\nclamp_max = 1.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, num_groups, scale_shape, maxpool_kernel_size, clamp_min, clamp_max]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs convolution, group normalization, scaling, max pooling, and clamping.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    num_groups: int\n    scale_shape: tuple\n    maxpool_kernel_size: int\n    clamp_min: float\n    clamp_max: float\n\n    @nn.compact\n    def __call__(self, x):\n        # Conv2D: (batch, in_channels, height, width) -> (batch, out_channels, height', width')\n        x = nn.Conv(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size),\n            use_bias=True,\n            padding='SAME'\n        )(x)\n        # GroupNorm: num_groups, axis=1 (channel axis)\n        x = nn.GroupNorm(\n            num_groups=self.num_groups,\n            axis=1,\n            epsilon=1e-5,\n            use_bias=True,\n            use_scale=True\n        )(x)\n        # Learnable scale parameter (broadcasted)\n        scale = self.param('scale', nn.initializers.ones, self.scale_shape)\n        x = x * scale\n        # MaxPool2D: kernel_size\n        x = nn.max_pool(\n            x,\n            window_shape=(self.maxpool_kernel_size, self.maxpool_kernel_size),\n            strides=(self.maxpool_kernel_size, self.maxpool_kernel_size),\n            padding='VALID'\n        )\n        # Clamp\n        x = jnp.clip(x, self.clamp_min, self.clamp_max)\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 128, 128 \nkernel_size = 3\nnum_groups = 16\nscale_shape = (out_channels, 1, 1)\nmaxpool_kernel_size = 4\nclamp_min = 0.0\nclamp_max = 1.0\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, in_channels, height, width).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, num_groups, scale_shape, maxpool_kernel_size, clamp_min, clamp_max]"}
{"kb_id": "kb_level_2_0084", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0084.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0084_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a matrix multiplication, divides by a scalar, and applies GELU activation.\n    \"\"\"\n    def __init__(self, input_size, output_size, divisor):\n        super(Model, self).__init__()\n        self.linear = nn.Linear(input_size, output_size)\n        self.divisor = divisor\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, input_size).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, output_size).\n        \"\"\"\n        x = self.linear(x)\n        x = x / self.divisor\n        x = torch.nn.functional.gelu(x)\n        return x\n\nbatch_size = 1024\ninput_size = 8192\noutput_size = 8192\ndivisor = 10.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, output_size, divisor]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a matrix multiplication, divides by a scalar, and applies GELU activation.\n    \"\"\"\n    input_size: int\n    output_size: int\n    divisor: float\n\n    @nn.compact\n    def __call__(self, x):\n        \"\"\"\n        Args:\n            x (jnp.ndarray): Input tensor of shape (batch_size, input_size).\n        Returns:\n            jnp.ndarray: Output tensor of shape (batch_size, output_size).\n        \"\"\"\n        x = nn.Dense(self.output_size)(x)\n        x = x / self.divisor\n        x = nn.gelu(x)\n        return x\n\nbatch_size = 1024\ninput_size = 8192\noutput_size = 8192\ndivisor = 10.0\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, output_size, divisor]"}
{"kb_id": "kb_level_2_0085", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.87364620938628, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0085.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0085_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a convolution, subtracts two values, applies Mish activation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, subtract_value_1, subtract_value_2):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.subtract_value_1 = subtract_value_1\n        self.subtract_value_2 = subtract_value_2\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x - self.subtract_value_1\n        x = x - self.subtract_value_2\n        x = torch.nn.functional.mish(x)\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 256, 256\nkernel_size = 3\nsubtract_value_1 = 0.5\nsubtract_value_2 = 0.2\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, subtract_value_1, subtract_value_2]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a convolution, subtracts two values, applies Mish activation.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    subtract_value_1: float\n    subtract_value_2: float\n\n    @nn.compact\n    def __call__(self, x):\n        x = nn.Conv(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size),\n            strides=(1, 1),\n            padding='SAME',\n            use_bias=True\n        )(x)\n        x = x - self.subtract_value_1\n        x = x - self.subtract_value_2\n        x = mish(x)\n        return x\n\ndef mish(x):\n    return x * jnp.tanh(jax.nn.softplus(x))\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 256, 256\nkernel_size = 3\nsubtract_value_1 = 0.5\nsubtract_value_2 = 0.2\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, in_channels, height, width).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, subtract_value_1, subtract_value_2]"}
{"kb_id": "kb_level_2_0086", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0086.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0086_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a GEMM, GroupNorm, Swish, Multiply, and Swish operations.\n    \"\"\"\n    def __init__(self, in_features, out_features, num_groups, multiply_weight_shape):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.group_norm = nn.GroupNorm(num_groups, out_features)\n        self.multiply_weight = nn.Parameter(torch.randn(multiply_weight_shape)) \n\n    def forward(self, x):\n        # (batch_size, in_features) -> (batch_size, out_features)\n        x = self.gemm(x)\n        # (batch_size, out_features) -> (batch_size, out_features)\n        x = self.group_norm(x)\n        # (batch_size, out_features) -> (batch_size, out_features)\n        x = x * torch.sigmoid(x)\n        # (batch_size, out_features) -> (batch_size, out_features)\n        x = x * self.multiply_weight\n        # (batch_size, out_features) -> (batch_size, out_features)\n        x = x * torch.sigmoid(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nnum_groups = 256\nmultiply_weight_shape = (out_features,)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, num_groups, multiply_weight_shape]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a GEMM, GroupNorm, Swish, Multiply, and Swish operations.\n    \"\"\"\n    in_features: int\n    out_features: int\n    num_groups: int\n    multiply_weight_shape: tuple\n\n    @nn.compact\n    def __call__(self, x):\n        # (batch_size, in_features) -> (batch_size, out_features)\n        x = nn.Dense(self.out_features)(x)\n        # (batch_size, out_features) -> (batch_size, out_features)\n        x = nn.GroupNorm(num_groups=self.num_groups, epsilon=1e-5, use_bias=True, use_scale=True)(x)\n        # (batch_size, out_features) -> (batch_size, out_features)\n        x = x * jax.nn.sigmoid(x)\n        # (batch_size, out_features) -> (batch_size, out_features)\n        multiply_weight = self.param('multiply_weight', nn.initializers.normal(), self.multiply_weight_shape)\n        x = x * multiply_weight\n        # (batch_size, out_features) -> (batch_size, out_features)\n        x = x * jax.nn.sigmoid(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nnum_groups = 256\nmultiply_weight_shape = (out_features,)\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, in_features).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [in_features, out_features, num_groups, multiply_weight_shape]"}
{"kb_id": "kb_level_2_0087", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.37275985663082, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0087.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0087_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a sequence of operations:\n        - ConvTranspose3d\n        - MaxPool3d\n        - Softmax\n        - Subtract\n        - Swish\n        - Max\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, pool_kernel_size, pool_stride, pool_padding):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.max_pool = nn.MaxPool3d(kernel_size=pool_kernel_size, stride=pool_stride, padding=pool_padding)\n        self.subtract = nn.Parameter(torch.randn(out_channels)) # Assuming subtraction is element-wise across channels\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = self.max_pool(x)\n        x = torch.softmax(x, dim=1) # Apply softmax across channels (dim=1)\n        x = x - self.subtract.view(1, -1, 1, 1, 1) # Subtract across channels\n        x = torch.sigmoid(x) * x # Swish activation\n        x = torch.max(x, dim=1)[0] # Max pooling across channels\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\npool_kernel_size = 2\npool_stride = 2\npool_padding = 0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, pool_kernel_size, pool_stride, pool_padding]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass ConvTranspose3d(nn.Module):\n    features: int\n    kernel_size: int\n    strides: int\n    padding: int\n    output_padding: int\n\n    @nn.compact\n    def __call__(self, x):\n        # x: (N, C, D, H, W) -> (N, D, H, W, C)\n        x = jnp.transpose(x, (0, 2, 3, 4, 1))\n        kernel_shape = (self.kernel_size, self.kernel_size, self.kernel_size)\n        strides = (self.strides, self.strides, self.strides)\n        # Flax ConvTranspose expects NHWDC, so we use dimension_numbers accordingly\n        conv = nn.ConvTranspose(\n            features=self.features,\n            kernel_size=kernel_shape,\n            strides=strides,\n            padding=[(self.padding, self.padding)]*3,\n            kernel_init=nn.initializers.lecun_normal(),\n            use_bias=True,\n            dimension_numbers=('NDHWC', 'DHWIO', 'NDHWC'),\n        )\n        x = conv(x)\n        # Output padding: manually pad if needed\n        if self.output_padding > 0:\n            pad = [(0, 0)]\n            for _ in range(3):\n                pad.append((0, self.output_padding))\n            pad.append((0, 0))\n            x = jnp.pad(x, pad)\n        # Back to (N, C, D, H, W)\n        x = jnp.transpose(x, (0, 4, 1, 2, 3))\n        return x\n\nclass MaxPool3d(nn.Module):\n    kernel_size: int\n    stride: int\n    padding: int\n\n    @nn.compact\n    def __call__(self, x):\n        # x: (N, C, D, H, W)\n        window_shape = (1, 1, self.kernel_size, self.kernel_size, self.kernel_size)\n        strides = (1, 1, self.stride, self.stride, self.stride)\n        pad = [(0, 0), (0, 0)]\n        for _ in range(3):\n            pad.append((self.padding, self.padding))\n        x = jax.lax.reduce_window(\n            x,\n            -jnp.inf,\n            jax.lax.max,\n            window_shape,\n            strides,\n            pad\n        )\n        return x\n\nclass Model(nn.Module):\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    stride: int\n    padding: int\n    output_padding: int\n    pool_kernel_size: int\n    pool_stride: int\n    pool_padding: int\n\n    def setup(self):\n        self.conv_transpose = ConvTranspose3d(\n            features=self.out_channels,\n            kernel_size=self.kernel_size,\n            strides=self.stride,\n            padding=self.padding,\n            output_padding=self.output_padding\n        )\n        self.max_pool = MaxPool3d(\n            kernel_size=self.pool_kernel_size,\n            stride=self.pool_stride,\n            padding=self.pool_padding\n        )\n        self.subtract = self.param(\n            'subtract',\n            nn.initializers.normal(),\n            (self.out_channels,)\n        )\n\n    def __call__(self, x):\n        x = self.conv_transpose(x)\n        x = self.max_pool(x)\n        # Softmax across channels (axis=1)\n        x = jax.nn.softmax(x, axis=1)\n        # Subtract across channels\n        x = x - self.subtract.reshape((1, -1, 1, 1, 1))\n        # Swish activation\n        x = jax.nn.sigmoid(x) * x\n        # Max across channels (axis=1)\n        x = jnp.max(x, axis=1)\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\npool_kernel_size = 2\npool_stride = 2\npool_padding = 0\n\ndef get_inputs():\n    key = jax.random.PRNGKey(0)\n    x = jax.random.uniform(\n        key,\n        (batch_size, in_channels, depth, height, width),\n        minval=0.0,\n        maxval=1.0\n    )\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, pool_kernel_size, pool_stride, pool_padding]"}
{"kb_id": "kb_level_2_0088", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 68.75666074600356, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0088.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0088_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, divides by a constant, applies max pooling,\n    global average pooling, adds a bias term, and sums along a specific dimension.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, divisor, pool_size, bias_shape, sum_dim):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size)\n        self.divisor = divisor\n        self.max_pool = nn.MaxPool3d(pool_size)\n        self.global_avg_pool = nn.AdaptiveAvgPool3d((1, 1, 1))\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.sum_dim = sum_dim\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x / self.divisor\n        x = self.max_pool(x)\n        x = self.global_avg_pool(x)\n        x = x + self.bias\n        x = torch.sum(x, dim=self.sum_dim)\n        return x\n\nbatch_size   = 128  \nin_channels  = 8            \nout_channels = 16  \ndepth = 16; height = width = 64 \nkernel_size = (3, 3, 3)\ndivisor = 2.0\npool_size = (2, 2, 2)\nbias_shape = (out_channels, 1, 1, 1)\nsum_dim = 1\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, divisor, pool_size, bias_shape, sum_dim]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, divides by a constant, applies max pooling,\n    global average pooling, adds a bias term, and sums along a specific dimension.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: tuple\n    divisor: float\n    pool_size: tuple\n    bias_shape: tuple\n    sum_dim: int\n\n    @nn.compact\n    def __call__(self, x):\n        # Conv3D: Flax expects (N, D, H, W, C), so we need to transpose\n        # Input: (N, C, D, H, W) -> (N, D, H, W, C)\n        x = jnp.transpose(x, (0, 2, 3, 4, 1))\n        x = nn.Conv(\n            features=self.out_channels,\n            kernel_size=self.kernel_size,\n            strides=(1, 1, 1),\n            padding='VALID',\n            use_bias=False,\n        )(x)\n        x = x / self.divisor\n        # MaxPool3D\n        x = nn.max_pool(\n            x,\n            window_shape=self.pool_size,\n            strides=self.pool_size,\n            padding='VALID'\n        )\n        # Global average pooling to (N, 1, 1, 1, C)\n        x = jnp.mean(x, axis=(1, 2, 3), keepdims=True)\n        # Add bias: bias shape is (out_channels, 1, 1, 1)\n        # Flax param: (C, 1, 1, 1) -> (1, 1, 1, 1, C) for broadcasting\n        bias = self.param('bias', nn.initializers.normal(), self.bias_shape)\n        bias = jnp.reshape(bias, (1, 1, 1, 1, self.out_channels))\n        x = x + bias\n        # Sum along sum_dim (original PyTorch: sum_dim=1 means channel dim)\n        # After transpose, dims: (N, 1, 1, 1, C), so sum_dim=1 is correct if user wants to sum over D\n        x = jnp.sum(x, axis=self.sum_dim)\n        # Transpose back if needed (not needed here, as output is (N, 1, 1, C))\n        return x\n\nbatch_size   = 128  \nin_channels  = 8            \nout_channels = 16  \ndepth = 16\nheight = width = 64 \nkernel_size = (3, 3, 3)\ndivisor = 2.0\npool_size = (2, 2, 2)\nbias_shape = (out_channels, 1, 1, 1)\nsum_dim = 1\n\ndef get_inputs():\n    # Return a list with a single input array, shape (batch_size, in_channels, depth, height, width)\n    key = jax.random.PRNGKey(0)\n    x = jax.random.uniform(\n        key,\n        (batch_size, in_channels, depth, height, width),\n        minval=0.0,\n        maxval=1.0\n    )\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, divisor, pool_size, bias_shape, sum_dim]"}
{"kb_id": "kb_level_2_0089", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.74774774774775, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0089.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0089_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, applies LeakyReLU, sums with a tensor, clamps, and applies GELU activation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, sum_tensor_shape):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size)\n        self.sum_tensor = nn.Parameter(torch.randn(sum_tensor_shape))\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = torch.nn.functional.leaky_relu(x, negative_slope=0.2)\n        x = x + self.sum_tensor\n        x = torch.clamp(x, min=-1.0, max=1.0)\n        x = torch.nn.functional.gelu(x)\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\ndepth, height, width = 16, 64, 64\nkernel_size = 3\nsum_tensor_shape = (out_channels, 1, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, sum_tensor_shape]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, applies LeakyReLU, sums with a tensor, clamps, and applies GELU activation.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    sum_tensor_shape: tuple\n\n    @nn.compact\n    def __call__(self, x):\n        x = nn.Conv(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size, self.kernel_size),\n            strides=(1, 1, 1),\n            padding='SAME',\n            use_bias=True\n        )(x)\n        x = jax.nn.leaky_relu(x, negative_slope=0.2)\n        sum_tensor = self.param(\n            'sum_tensor',\n            nn.initializers.normal(),\n            self.sum_tensor_shape\n        )\n        x = x + sum_tensor\n        x = jnp.clip(x, a_min=-1.0, a_max=1.0)\n        x = jax.nn.gelu(x)\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\ndepth, height, width = 16, 64, 64\nkernel_size = 3\nsum_tensor_shape = (out_channels, 1, 1, 1)\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, in_channels, depth, height, width).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, sum_tensor_shape]"}
{"kb_id": "kb_level_2_0090", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 66.97231833910034, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0090.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0090_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, applies softmax, adds a bias term, scales the result, and applies sigmoid.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape, scaling_factor):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.bias = nn.Parameter(torch.randn(bias_shape)) \n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = torch.softmax(x, dim=1)\n        x = x + self.bias\n        x = x * self.scaling_factor\n        x = torch.sigmoid(x)\n        return x\n\nbatch_size = 128\nin_channels = 64\nout_channels = 128\nheight, width = 64, 64\nkernel_size = 4\nstride = 2\npadding = 1\noutput_padding = 1\nbias_shape = (out_channels, 1, 1)\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape, scaling_factor]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, applies softmax, adds a bias term, scales the result, and applies sigmoid.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    stride: int\n    padding: int\n    output_padding: int\n    bias_shape: tuple\n    scaling_factor: float\n\n    def setup(self):\n        self.conv_transpose = nn.ConvTranspose(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size),\n            strides=(self.stride, self.stride),\n            padding=[(self.padding, self.padding), (self.padding, self.padding)],\n            kernel_init=nn.initializers.lecun_normal(),\n            use_bias=False,\n        )\n        self.bias = self.param('bias', nn.initializers.normal(), self.bias_shape)\n\n    def __call__(self, x):\n        x = self.conv_transpose(x)\n        x = jax.nn.softmax(x, axis=1)\n        x = x + self.bias\n        x = x * self.scaling_factor\n        x = jax.nn.sigmoid(x)\n        return x\n\nbatch_size = 128\nin_channels = 64\nout_channels = 128\nheight, width = 64, 64\nkernel_size = 4\nstride = 2\npadding = 1\noutput_padding = 1\nbias_shape = (out_channels, 1, 1)\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, in_channels, height, width).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape, scaling_factor]"}
{"kb_id": "kb_level_2_0091", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0091.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0091_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a convolution, applies Group Normalization, Tanh, HardSwish, \n    Residual Addition, and LogSumExp.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, groups, eps=1e-5):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.group_norm = nn.GroupNorm(groups, out_channels, eps=eps)\n        self.tanh = nn.Tanh()\n        self.hard_swish = nn.Hardswish()\n\n    def forward(self, x):\n        # Convolution\n        x_conv = self.conv(x)\n        # Group Normalization\n        x_norm = self.group_norm(x_conv)\n        # Tanh\n        x_tanh = self.tanh(x_norm)\n        # HardSwish\n        x_hard_swish = self.hard_swish(x_tanh)\n        # Residual Addition\n        x_res = x_conv + x_hard_swish\n        # LogSumExp\n        x_logsumexp = torch.logsumexp(x_res, dim=1, keepdim=True)\n        return x_logsumexp\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 128, 128\nkernel_size = 3\ngroups = 16\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, groups]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass GroupNorm(nn.Module):\n    num_groups: int\n    num_channels: int\n    eps: float = 1e-5\n\n    @nn.compact\n    def __call__(self, x):\n        # x: (N, C, H, W)\n        N, C, H, W = x.shape\n        G = self.num_groups\n        assert C % G == 0, \"num_channels must be divisible by num_groups\"\n        x = x.reshape(N, G, C // G, H, W)\n        mean = jnp.mean(x, axis=(2, 3, 4), keepdims=True)\n        var = jnp.var(x, axis=(2, 3, 4), keepdims=True)\n        x = (x - mean) / jnp.sqrt(var + self.eps)\n        x = x.reshape(N, C, H, W)\n        gamma = self.param('gamma', nn.initializers.ones, (1, C, 1, 1))\n        beta = self.param('beta', nn.initializers.zeros, (1, C, 1, 1))\n        return x * gamma + beta\n\nclass Model(nn.Module):\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    groups: int\n    eps: float = 1e-5\n\n    @nn.compact\n    def __call__(self, x):\n        # Convolution\n        x_conv = nn.Conv(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size),\n            use_bias=True,\n            padding='SAME'\n        )(x)\n        # Group Normalization\n        x_norm = GroupNorm(self.groups, self.out_channels, eps=self.eps)(x_conv)\n        # Tanh\n        x_tanh = jnp.tanh(x_norm)\n        # HardSwish: x * relu6(x + 3) / 6\n        x_hard_swish = x_tanh * jnp.clip(x_tanh + 3, 0, 6) / 6\n        # Residual Addition\n        x_res = x_conv + x_hard_swish\n        # LogSumExp over channel dimension (axis=1), keepdim=True\n        x_logsumexp = jax.scipy.special.logsumexp(x_res, axis=1, keepdims=True)\n        return x_logsumexp\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 128, 128\nkernel_size = 3\ngroups = 16\n\ndef get_inputs():\n    # JAX expects float32 by default\n    return [jnp.random.rand(batch_size, in_channels, height, width).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, groups]"}
{"kb_id": "kb_level_2_0092", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.37275985663082, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0092.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0092_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, adds a value, takes the minimum, applies GELU, and multiplies by a value.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, add_value, multiply_value):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride)\n        self.add_value = add_value\n        self.multiply_value = multiply_value\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = x + self.add_value\n        x = torch.min(x, torch.tensor(0.0, device=x.device))\n        x = torch.nn.functional.gelu(x)\n        x = x * self.multiply_value\n        return x\n\nbatch_size = 128\nin_channels = 64\nout_channels = 128\nheight, width = 64, 64\nkernel_size = 4\nstride = 2\nadd_value = 0.5\nmultiply_value = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, add_value, multiply_value]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, adds a value, takes the minimum, applies GELU, and multiplies by a value.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    stride: int\n    add_value: float\n    multiply_value: float\n\n    @nn.compact\n    def __call__(self, x):\n        # Flax ConvTranspose uses (batch, height, width, channels) by default\n        # Input is (batch, channels, height, width), so transpose to NHWC\n        x = jnp.transpose(x, (0, 2, 3, 1))\n        x = nn.ConvTranspose(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size),\n            strides=(self.stride, self.stride),\n            padding='SAME',\n            use_bias=True,\n        )(x)\n        x = x + self.add_value\n        x = jnp.minimum(x, 0.0)\n        x = nn.gelu(x)\n        x = x * self.multiply_value\n        # Transpose back to NCHW\n        x = jnp.transpose(x, (0, 3, 1, 2))\n        return x\n\nbatch_size = 128\nin_channels = 64\nout_channels = 128\nheight, width = 64, 64\nkernel_size = 4\nstride = 2\nadd_value = 0.5\nmultiply_value = 2.0\n\ndef get_inputs():\n    # Return a list with a single JAX array of shape (batch, channels, height, width)\n    key = jax.random.PRNGKey(0)\n    x = jax.random.uniform(key, (batch_size, in_channels, height, width))\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, add_value, multiply_value]"}
{"kb_id": "kb_level_2_0093", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0093.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0093_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a GEMM, BiasAdd, Hardtanh, Mish, and GroupNorm operations in sequence.\n    \"\"\"\n    def __init__(self, in_features, out_features, bias_shape, num_groups):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.hardtanh = nn.Hardtanh()\n        self.mish = nn.Mish()\n        self.groupnorm = nn.GroupNorm(num_groups=num_groups, num_channels=out_features)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.gemm(x)\n        x = x + self.bias\n        x = self.hardtanh(x)\n        x = self.mish(x)\n        x = self.groupnorm(x)\n        return x\n\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nbias_shape = (out_features,)\nnum_groups = 256\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, bias_shape, num_groups]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Hardtanh(nn.Module):\n    min_val: float = -1.0\n    max_val: float = 1.0\n\n    @nn.compact\n    def __call__(self, x):\n        return jnp.clip(x, self.min_val, self.max_val)\n\nclass Mish(nn.Module):\n    @nn.compact\n    def __call__(self, x):\n        return x * jnp.tanh(jax.nn.softplus(x))\n\nclass GroupNorm(nn.Module):\n    num_groups: int\n    num_channels: int\n    eps: float = 1e-5\n\n    @nn.compact\n    def __call__(self, x):\n        # x: (batch, features)\n        # Reshape to (batch, num_groups, group_size)\n        assert x.shape[-1] == self.num_channels\n        group_size = self.num_channels // self.num_groups\n        x_reshaped = x.reshape(x.shape[0], self.num_groups, group_size)\n        mean = jnp.mean(x_reshaped, axis=(2,), keepdims=True)\n        var = jnp.var(x_reshaped, axis=(2,), keepdims=True)\n        x_norm = (x_reshaped - mean) / jnp.sqrt(var + self.eps)\n        x_norm = x_norm.reshape(x.shape)\n        gamma = self.param('gamma', nn.initializers.ones, (self.num_channels,))\n        beta = self.param('beta', nn.initializers.zeros, (self.num_channels,))\n        return x_norm * gamma + beta\n\nclass Model(nn.Module):\n    in_features: int\n    out_features: int\n    bias_shape: tuple\n    num_groups: int\n\n    @nn.compact\n    def __call__(self, x):\n        x = nn.Dense(self.out_features, use_bias=False)(x)\n        bias = self.param('bias', nn.initializers.normal(), self.bias_shape)\n        x = x + bias\n        x = Hardtanh()(x)\n        x = Mish()(x)\n        x = GroupNorm(num_groups=self.num_groups, num_channels=self.out_features)(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nbias_shape = (out_features,)\nnum_groups = 256\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, in_features).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [in_features, out_features, bias_shape, num_groups]"}
{"kb_id": "kb_level_2_0094", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.62230215827337, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0094.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0094_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, adds a value, applies Swish, Tanh, GELU, and Hardtanh activation functions.\n    \"\"\"\n    def __init__(self, in_features, out_features, add_value_shape):\n        super(Model, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.add_value = nn.Parameter(torch.randn(add_value_shape)) \n\n    def forward(self, x):\n        x = self.matmul(x)\n        x = x + self.add_value\n        x = torch.sigmoid(x) * x # Swish\n        x = torch.tanh(x)\n        x = torch.nn.functional.gelu(x) # GELU\n        x = torch.nn.functional.hardtanh(x, min_val=-1, max_val=1) # Hardtanh\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nadd_value_shape = (out_features,)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, add_value_shape]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, adds a value, applies Swish, Tanh, GELU, and Hardtanh activation functions.\n    \"\"\"\n    in_features: int\n    out_features: int\n    add_value_shape: tuple\n\n    def setup(self):\n        self.matmul = nn.Dense(self.out_features)\n        self.add_value = self.param('add_value', jax.nn.initializers.normal(), self.add_value_shape)\n\n    def __call__(self, x):\n        x = self.matmul(x)\n        x = x + self.add_value\n        x = jax.nn.sigmoid(x) * x  # Swish\n        x = jnp.tanh(x)\n        x = jax.nn.gelu(x)\n        x = jnp.clip(x, -1, 1)  # Hardtanh\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nadd_value_shape = (out_features,)\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, add_value_shape]"}
{"kb_id": "kb_level_2_0095", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0095.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0095_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed 3D convolution, multiplies by a scalar, applies max pooling, \n    global average pooling, and clamps the output.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, scale, maxpool_kernel_size):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n        self.scale = scale\n        self.maxpool = nn.MaxPool3d(kernel_size=maxpool_kernel_size)\n        self.global_avg_pool = nn.AdaptiveAvgPool3d((1, 1, 1))\n        self.clamp_min = 0\n        self.clamp_max = 1\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = x * self.scale\n        x = self.maxpool(x)\n        x = self.global_avg_pool(x)\n        x = torch.clamp(x, min=self.clamp_min, max=self.clamp_max)\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\nscale = 0.5\nmaxpool_kernel_size = 2\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, scale, maxpool_kernel_size]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed 3D convolution, multiplies by a scalar, applies max pooling, \n    global average pooling, and clamps the output.\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    stride: int\n    padding: int\n    scale: float\n    maxpool_kernel_size: int\n\n    @nn.compact\n    def __call__(self, x):\n        # ConvTranspose3d in PyTorch: (N, C_in, D, H, W) -> (N, C_out, D_out, H_out, W_out)\n        # Flax does not have ConvTranspose3d, so we use ConvTranspose with 3 spatial dims\n        x = nn.ConvTranspose(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size, self.kernel_size),\n            strides=(self.stride, self.stride, self.stride),\n            padding=[(self.padding, self.padding)]*3,\n            use_bias=True,\n            dimension_numbers=('NCDHW', 'OIDHW', 'NCDHW')\n        )(x)\n        x = x * self.scale\n        # MaxPool3d\n        x = nn.max_pool(\n            x,\n            window_shape=(self.maxpool_kernel_size, self.maxpool_kernel_size, self.maxpool_kernel_size),\n            strides=(self.maxpool_kernel_size, self.maxpool_kernel_size, self.maxpool_kernel_size),\n            padding='VALID'\n        )\n        # Global average pooling to (N, C, 1, 1, 1)\n        x = jnp.mean(x, axis=(2, 3, 4), keepdims=True)\n        x = jnp.clip(x, a_min=0, a_max=1)\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\nscale = 0.5\nmaxpool_kernel_size = 2\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, in_channels, depth, height, width).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, scale, maxpool_kernel_size]"}
{"kb_id": "kb_level_2_0096", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.74774774774775, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0096.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0096_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a matrix multiplication, batch normalization, bias addition, division, and Swish activation.\n    \"\"\"\n    def __init__(self, in_features, out_features, bn_eps=1e-5, bn_momentum=0.1, bias_shape=(1,), divide_value=1.0):\n        super(Model, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.bn = nn.BatchNorm1d(out_features, eps=bn_eps, momentum=bn_momentum)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.divide_value = divide_value\n\n    def forward(self, x):\n        x = self.matmul(x)\n        x = self.bn(x)\n        x = x + self.bias\n        x = x / self.divide_value\n        x = x * torch.sigmoid(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nbn_eps = 1e-5\nbn_momentum = 0.1\nbias_shape = (1,)\ndivide_value = 1.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, bn_eps, bn_momentum, bias_shape, divide_value]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a matrix multiplication, batch normalization, bias addition, division, and Swish activation.\n    \"\"\"\n    in_features: int\n    out_features: int\n    bn_eps: float = 1e-5\n    bn_momentum: float = 0.1\n    bias_shape: tuple = (1,)\n    divide_value: float = 1.0\n\n    def setup(self):\n        self.matmul = nn.Dense(self.out_features, use_bias=False)\n        self.bn = nn.BatchNorm(use_running_average=False, momentum=1.0 - self.bn_momentum, epsilon=self.bn_eps)\n        self.bias = self.param('bias', nn.initializers.normal(), self.bias_shape)\n\n    def __call__(self, x, *, train=True):\n        x = self.matmul(x)\n        x = self.bn(x, use_running_average=not train)\n        x = x + self.bias\n        x = x / self.divide_value\n        x = x * jax.nn.sigmoid(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nbn_eps = 1e-5\nbn_momentum = 0.1\nbias_shape = (1,)\ndivide_value = 1.0\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, in_features).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [in_features, out_features, bn_eps, bn_momentum, bias_shape, divide_value]"}
{"kb_id": "kb_level_2_0097", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0097.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0097_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model implementing the pattern \"Matmul_AvgPool_GELU_Scale_Max\".\n    \"\"\"\n    def __init__(self, in_features, out_features, pool_kernel_size, scale_factor):\n        super(Model, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.avg_pool = nn.AvgPool1d(kernel_size=pool_kernel_size)\n        self.scale_factor = scale_factor\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.matmul(x)\n        x = self.avg_pool(x.unsqueeze(1)).squeeze(1)\n        x = torch.nn.functional.gelu(x)\n        x = x * self.scale_factor\n        x = torch.max(x, dim=1).values\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\npool_kernel_size = 16\nscale_factor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, pool_kernel_size, scale_factor]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model implementing the pattern \"Matmul_AvgPool_GELU_Scale_Max\".\n    \"\"\"\n    in_features: int\n    out_features: int\n    pool_kernel_size: int\n    scale_factor: float\n\n    @nn.compact\n    def __call__(self, x):\n        # x: (batch_size, in_features)\n        x = nn.Dense(self.out_features)(x)  # (batch_size, out_features)\n        # Reshape for 1D pooling: (batch, channels=1, features)\n        x = x[:, None, :]  # (batch_size, 1, out_features)\n        # AvgPool1d: window_shape=(pool_kernel_size,), strides=(pool_kernel_size,)\n        x = nn.avg_pool(\n            x,\n            window_shape=(1, self.pool_kernel_size),\n            strides=(1, self.pool_kernel_size),\n            padding='VALID'\n        )  # (batch_size, 1, new_features)\n        x = jnp.squeeze(x, axis=1)  # (batch_size, new_features)\n        x = jax.nn.gelu(x)\n        x = x * self.scale_factor\n        x = jnp.max(x, axis=1)  # (batch_size,)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\npool_kernel_size = 16\nscale_factor = 2.0\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, in_features).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [in_features, out_features, pool_kernel_size, scale_factor]"}
{"kb_id": "kb_level_2_0098", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0098.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0098_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, applies GELU, and then applies Softmax.\n    \"\"\"\n    def __init__(self, in_features, out_features):\n        super(Model, self).__init__()\n        self.linear = nn.Linear(in_features, out_features)\n\n    def forward(self, x):\n        x = self.linear(x)\n        x = torch.nn.functional.gelu(x)\n        x = torch.nn.functional.softmax(x, dim=1)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, applies GELU, and then applies Softmax.\n    \"\"\"\n    in_features: int\n    out_features: int\n\n    @nn.compact\n    def __call__(self, x):\n        x = nn.Dense(self.out_features)(x)\n        x = nn.gelu(x)\n        x = nn.softmax(x, axis=1)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]"}
{"kb_id": "kb_level_2_0099", "level": "level_2", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/pytorch_samples/kb_level_2_0099.py", "jax_path": "results/runs/2025-11-23-18h23_level_2_gpt41_strict_full_v2_n100/jax_outputs/kb_level_2_0099_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a matrix multiplication, subtraction, multiplication, and ReLU activation.\n    \"\"\"\n    def __init__(self, in_features, out_features, subtract_value, multiply_value):\n        super(Model, self).__init__()\n        self.linear = nn.Linear(in_features, out_features)\n        self.subtract_value = subtract_value\n        self.multiply_value = multiply_value\n\n    def forward(self, x):\n        x = self.linear(x)\n        x = x - self.subtract_value\n        x = x * self.multiply_value\n        x = torch.relu(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nsubtract_value = 2.0\nmultiply_value = 1.5\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, subtract_value, multiply_value]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a matrix multiplication, subtraction, multiplication, and ReLU activation.\n    \"\"\"\n    in_features: int\n    out_features: int\n    subtract_value: float\n    multiply_value: float\n\n    @nn.compact\n    def __call__(self, x):\n        x = nn.Dense(self.out_features)(x)\n        x = x - self.subtract_value\n        x = x * self.multiply_value\n        x = jax.nn.relu(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nsubtract_value = 2.0\nmultiply_value = 1.5\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, subtract_value, multiply_value]"}
{"kb_id": "kb_level_3_0000", "level": "level_3", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.0017825311943, "success": true, "pytorch_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/pytorch_samples/kb_level_3_0000.py", "jax_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/jax_outputs/kb_level_3_0000_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n        \"\"\"\n        :param in_channels: Number of input channels\n        :param out_channels: Number of output channels\n        :param stride: Stride for the first convolutional layer\n        :param downsample: Downsample layer for the shortcut connection\n        \"\"\"\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor, shape (batch_size, in_channels, height, width)\n        :return: Output tensor, shape (batch_size, out_channels * expansion, height, width)\n        \"\"\"\n        identity = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            identity = self.downsample(x)\n\n        out += identity\n        out = self.relu(out)\n\n        return out\n\nclass Model(nn.Module):\n    def __init__(self, layers, num_classes=1000):\n        \"\"\"\n        :param block: Type of block to use (BasicBlock or Bottleneck)\n        :param layers: List of integers specifying the number of blocks in each layer\n        :param num_classes: Number of output classes\n        \"\"\"\n        super(Model, self).__init__()\n        self.in_channels = 64\n\n        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size=7, stride=2, padding=3, bias=False)\n        self.bn1 = nn.BatchNorm2d(self.in_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        block = Bottleneck\n\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\n    def _make_layer(self, block, out_channels, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.in_channels != out_channels * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.in_channels, out_channels, stride, downsample))\n        self.in_channels = out_channels * block.expansion\n        for _ in range(1, blocks):\n            layers.append(block(self.in_channels, out_channels))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor, shape (batch_size, 3, height, width)\n        :return: Output tensor, shape (batch_size, num_classes)\n        \"\"\"\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n\n        return x\n\n# Test code\nbatch_size = 10\nheight = 224\nwidth = 224\nlayers = [3, 4, 23, 3]\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.rand(batch_size, 3, height, width)]\n\ndef get_init_inputs():\n    return [layers, num_classes]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Bottleneck(nn.Module):\n    in_channels: int\n    out_channels: int\n    stride: int = 1\n    downsample: nn.Module = None\n\n    expansion: int = 4\n\n    @nn.compact\n    def __call__(self, x, train=True):\n        identity = x\n\n        out = nn.Conv(features=self.out_channels, kernel_size=(1,1), strides=(1,1), use_bias=False)(x)\n        out = nn.BatchNorm(use_running_average=not train)(out)\n        out = nn.relu(out)\n\n        out = nn.Conv(features=self.out_channels, kernel_size=(3,3), strides=(self.stride, self.stride), padding='SAME', use_bias=False)(out)\n        out = nn.BatchNorm(use_running_average=not train)(out)\n        out = nn.relu(out)\n\n        out = nn.Conv(features=self.out_channels * self.expansion, kernel_size=(1,1), strides=(1,1), use_bias=False)(out)\n        out = nn.BatchNorm(use_running_average=not train)(out)\n\n        if self.downsample is not None:\n            identity = self.downsample(identity, train=train)\n\n        out = out + identity\n        out = nn.relu(out)\n        return out\n\nclass DownsampleLayer(nn.Module):\n    in_channels: int\n    out_channels: int\n    stride: int\n\n    @nn.compact\n    def __call__(self, x, train=True):\n        x = nn.Conv(features=self.out_channels, kernel_size=(1,1), strides=(self.stride, self.stride), use_bias=False)(x)\n        x = nn.BatchNorm(use_running_average=not train)(x)\n        return x\n\nclass Sequential(nn.Module):\n    layers: list\n\n    def setup(self):\n        self.layers_ = self.layers\n\n    def __call__(self, x, train=True):\n        for layer in self.layers_:\n            x = layer(x, train=train)\n        return x\n\nclass Model(nn.Module):\n    layers_cfg: list\n    num_classes: int = 1000\n\n    def setup(self):\n        self.in_channels = 64\n        self.conv1 = nn.Conv(features=self.in_channels, kernel_size=(7,7), strides=(2,2), padding='SAME', use_bias=False)\n        self.bn1 = nn.BatchNorm()\n        self.maxpool = nn.max_pool\n        self.relu = nn.relu\n\n        self.layer1 = self._make_layer(64, self.layers_cfg[0])\n        self.layer2 = self._make_layer(128, self.layers_cfg[1], stride=2)\n        self.layer3 = self._make_layer(256, self.layers_cfg[2], stride=2)\n        self.layer4 = self._make_layer(512, self.layers_cfg[3], stride=2)\n\n        self.avgpool = lambda x: jnp.mean(x, axis=(2,3), keepdims=True)\n        self.fc = nn.Dense(features=self.num_classes)\n\n    def _make_layer(self, out_channels, blocks, stride=1):\n        layers = []\n        expansion = Bottleneck.expansion\n        downsample = None\n        if stride != 1 or self.in_channels != out_channels * expansion:\n            downsample = DownsampleLayer(self.in_channels, out_channels * expansion, stride)\n        layers.append(Bottleneck(self.in_channels, out_channels, stride, downsample))\n        self.in_channels = out_channels * expansion\n        for _ in range(1, blocks):\n            layers.append(Bottleneck(self.in_channels, out_channels))\n        return Sequential(layers)\n\n    def __call__(self, x, train=True):\n        x = self.conv1(x)\n        x = self.bn1(x, use_running_average=not train)\n        x = self.relu(x)\n        x = self.maxpool(x, window_shape=(3,3), strides=(2,2), padding='SAME')\n\n        x = self.layer1(x, train=train)\n        x = self.layer2(x, train=train)\n        x = self.layer3(x, train=train)\n        x = self.layer4(x, train=train)\n\n        x = self.avgpool(x)\n        x = x.reshape((x.shape[0], -1))\n        x = self.fc(x)\n        return x\n\n# Test code\nbatch_size = 10\nheight = 224\nwidth = 224\nlayers = [3, 4, 23, 3]\nnum_classes = 1000\n\ndef get_inputs():\n    return [jnp.ones((batch_size, 3, height, width), dtype=jnp.float32)]\n\ndef get_init_inputs():\n    return [layers, num_classes]"}
{"kb_id": "kb_level_3_0001", "level": "level_3", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/pytorch_samples/kb_level_3_0001.py", "jax_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/jax_outputs/kb_level_3_0001_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, num_classes=1000):\n        \"\"\"\n        Initialize the VGG16 model.\n        \n        :param num_classes: The number of output classes (default is 1000 for ImageNet)\n        \"\"\"\n        super(Model, self).__init__()\n        \n        # VGG16 architecture: 5 blocks of convolutional layers followed by max pooling\n        self.features = nn.Sequential(\n            # Block 1\n            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            # Block 2\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            # Block 3\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            # Block 4\n            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            # Block 5\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        \n        # Fully connected layers\n        self.classifier = nn.Sequential(\n            nn.Linear(512 * 7 * 7, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=0.0),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=0.0),\n            nn.Linear(4096, num_classes)\n        )\n    \n    def forward(self, x):\n        \"\"\"\n        Forward pass of the VGG16 model.\n        \n        :param x: The input tensor, shape (batch_size, 3, 224, 224)\n        :return: The output tensor, shape (batch_size, num_classes)\n        \"\"\"\n        x = self.features(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# Test code\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.rand(batch_size, 3, 224, 224)]\n\ndef get_init_inputs():\n    return [num_classes]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    num_classes: int = 1000\n\n    @nn.compact\n    def __call__(self, x, *, train: bool = False):\n        # Block 1\n        x = nn.Conv(features=64, kernel_size=(3,3), padding='SAME')(x)\n        x = nn.relu(x)\n        x = nn.Conv(features=64, kernel_size=(3,3), padding='SAME')(x)\n        x = nn.relu(x)\n        x = nn.max_pool(x, window_shape=(2,2), strides=(2,2), padding='VALID')\n\n        # Block 2\n        x = nn.Conv(features=128, kernel_size=(3,3), padding='SAME')(x)\n        x = nn.relu(x)\n        x = nn.Conv(features=128, kernel_size=(3,3), padding='SAME')(x)\n        x = nn.relu(x)\n        x = nn.max_pool(x, window_shape=(2,2), strides=(2,2), padding='VALID')\n\n        # Block 3\n        x = nn.Conv(features=256, kernel_size=(3,3), padding='SAME')(x)\n        x = nn.relu(x)\n        x = nn.Conv(features=256, kernel_size=(3,3), padding='SAME')(x)\n        x = nn.relu(x)\n        x = nn.Conv(features=256, kernel_size=(3,3), padding='SAME')(x)\n        x = nn.relu(x)\n        x = nn.max_pool(x, window_shape=(2,2), strides=(2,2), padding='VALID')\n\n        # Block 4\n        x = nn.Conv(features=512, kernel_size=(3,3), padding='SAME')(x)\n        x = nn.relu(x)\n        x = nn.Conv(features=512, kernel_size=(3,3), padding='SAME')(x)\n        x = nn.relu(x)\n        x = nn.Conv(features=512, kernel_size=(3,3), padding='SAME')(x)\n        x = nn.relu(x)\n        x = nn.max_pool(x, window_shape=(2,2), strides=(2,2), padding='VALID')\n\n        # Block 5\n        x = nn.Conv(features=512, kernel_size=(3,3), padding='SAME')(x)\n        x = nn.relu(x)\n        x = nn.Conv(features=512, kernel_size=(3,3), padding='SAME')(x)\n        x = nn.relu(x)\n        x = nn.Conv(features=512, kernel_size=(3,3), padding='SAME')(x)\n        x = nn.relu(x)\n        x = nn.max_pool(x, window_shape=(2,2), strides=(2,2), padding='VALID')\n\n        # Flatten\n        x = x.reshape((x.shape[0], -1))\n\n        # Classifier\n        x = nn.Dense(features=4096)(x)\n        x = nn.relu(x)\n        x = nn.Dropout(rate=0.0)(x, deterministic=not train)\n        x = nn.Dense(features=4096)(x)\n        x = nn.relu(x)\n        x = nn.Dropout(rate=0.0)(x, deterministic=not train)\n        x = nn.Dense(features=self.num_classes)(x)\n        return x\n\n# Test code\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    # JAX expects NHWC by default, but Flax Conv2D supports NCHW if input is NCHW.\n    # We'll keep NCHW to match PyTorch.\n    key = jax.random.PRNGKey(0)\n    x = jax.random.uniform(key, (batch_size, 3, 224, 224))\n    return [x]\n\ndef get_init_inputs():\n    return [num_classes]"}
{"kb_id": "kb_level_3_0002", "level": "level_3", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/pytorch_samples/kb_level_3_0002.py", "jax_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/jax_outputs/kb_level_3_0002_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    def __init__(self, num_classes=1000):\n        \"\"\"\n        Initialize the VGG19 model.\n\n        :param num_classes: The number of output classes (default is 1000 for ImageNet)\n        \"\"\"\n        super(Model, self).__init__()\n        \n        # VGG19 architecture: 16 Conv layers + 5 MaxPool layers + 3 Fully Connected layers\n        self.features = nn.Sequential(\n            # Block 1\n            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            # Block 2\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            # Block 3\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            # Block 4\n            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            # Block 5\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        \n        self.classifier = nn.Sequential(\n            nn.Linear(512 * 7 * 7, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=0.0),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=0.0),\n            nn.Linear(4096, num_classes)\n        )\n    \n    def forward(self, x):\n        \"\"\"\n        Forward pass of the VGG19 model.\n\n        :param x: The input tensor, shape (batch_size, 3, 224, 224)\n        :return: The output tensor, shape (batch_size, num_classes)\n        \"\"\"\n        x = self.features(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# Test code\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.rand(batch_size, 3, 224, 224)]\n\ndef get_init_inputs():\n    return [num_classes]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass VGG19Features(nn.Module):\n    @nn.compact\n    def __call__(self, x):\n        # Block 1\n        x = nn.Conv(features=64, kernel_size=(3,3), padding='SAME')(x)\n        x = nn.relu(x)\n        x = nn.Conv(features=64, kernel_size=(3,3), padding='SAME')(x)\n        x = nn.relu(x)\n        x = nn.max_pool(x, window_shape=(2,2), strides=(2,2), padding='VALID')\n        # Block 2\n        x = nn.Conv(features=128, kernel_size=(3,3), padding='SAME')(x)\n        x = nn.relu(x)\n        x = nn.Conv(features=128, kernel_size=(3,3), padding='SAME')(x)\n        x = nn.relu(x)\n        x = nn.max_pool(x, window_shape=(2,2), strides=(2,2), padding='VALID')\n        # Block 3\n        x = nn.Conv(features=256, kernel_size=(3,3), padding='SAME')(x)\n        x = nn.relu(x)\n        x = nn.Conv(features=256, kernel_size=(3,3), padding='SAME')(x)\n        x = nn.relu(x)\n        x = nn.Conv(features=256, kernel_size=(3,3), padding='SAME')(x)\n        x = nn.relu(x)\n        x = nn.Conv(features=256, kernel_size=(3,3), padding='SAME')(x)\n        x = nn.relu(x)\n        x = nn.max_pool(x, window_shape=(2,2), strides=(2,2), padding='VALID')\n        # Block 4\n        x = nn.Conv(features=512, kernel_size=(3,3), padding='SAME')(x)\n        x = nn.relu(x)\n        x = nn.Conv(features=512, kernel_size=(3,3), padding='SAME')(x)\n        x = nn.relu(x)\n        x = nn.Conv(features=512, kernel_size=(3,3), padding='SAME')(x)\n        x = nn.relu(x)\n        x = nn.Conv(features=512, kernel_size=(3,3), padding='SAME')(x)\n        x = nn.relu(x)\n        x = nn.max_pool(x, window_shape=(2,2), strides=(2,2), padding='VALID')\n        # Block 5\n        x = nn.Conv(features=512, kernel_size=(3,3), padding='SAME')(x)\n        x = nn.relu(x)\n        x = nn.Conv(features=512, kernel_size=(3,3), padding='SAME')(x)\n        x = nn.relu(x)\n        x = nn.Conv(features=512, kernel_size=(3,3), padding='SAME')(x)\n        x = nn.relu(x)\n        x = nn.Conv(features=512, kernel_size=(3,3), padding='SAME')(x)\n        x = nn.relu(x)\n        x = nn.max_pool(x, window_shape=(2,2), strides=(2,2), padding='VALID')\n        return x\n\nclass VGG19Classifier(nn.Module):\n    num_classes: int\n\n    @nn.compact\n    def __call__(self, x):\n        x = x.reshape((x.shape[0], -1))  # flatten\n        x = nn.Dense(features=4096)(x)\n        x = nn.relu(x)\n        x = nn.Dropout(rate=0.0, deterministic=True)(x)\n        x = nn.Dense(features=4096)(x)\n        x = nn.relu(x)\n        x = nn.Dropout(rate=0.0, deterministic=True)(x)\n        x = nn.Dense(features=self.num_classes)(x)\n        return x\n\nclass Model(nn.Module):\n    num_classes: int = 1000\n\n    @nn.compact\n    def __call__(self, x, *, train=False):\n        # Input x: (batch, 3, 224, 224)\n        # Flax expects (batch, H, W, C)\n        if x.shape[1] == 3:\n            x = jnp.transpose(x, (0,2,3,1))\n        x = VGG19Features()(x)\n        # x: (batch, 7, 7, 512)\n        x = jnp.transpose(x, (0,3,1,2))  # (batch, 512, 7, 7)\n        x = x.reshape((x.shape[0], -1))  # flatten\n        x = VGG19Classifier(self.num_classes)(x)\n        return x\n\n# Test code\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    # Return a list with a single input array of shape (batch_size, 3, 224, 224)\n    return [jnp.random.rand(batch_size, 3, 224, 224).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [num_classes]"}
{"kb_id": "kb_level_3_0003", "level": "level_3", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.87364620938628, "success": true, "pytorch_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/pytorch_samples/kb_level_3_0003.py", "jax_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/jax_outputs/kb_level_3_0003_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, num_input_features: int, num_output_features: int):\n        \"\"\"\n        :param num_input_features: The number of input feature maps\n        :param num_output_features: The number of output feature maps\n        \"\"\"\n        super(Model, self).__init__()\n        self.transition = nn.Sequential(\n            nn.BatchNorm2d(num_input_features),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(num_input_features, num_output_features, kernel_size=1, bias=False),\n            nn.AvgPool2d(kernel_size=2, stride=2)\n        )\n\n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor of shape (batch_size, num_input_features, height, width)\n        :return: Downsampled tensor with reduced number of feature maps\n        \"\"\"\n        return self.transition(x)\n\nbatch_size = 128\nnum_input_features = 32\nnum_output_features = 64\nheight, width = 256, 256\n\ndef get_inputs():\n    return [torch.rand(batch_size, num_input_features, height, width)]\n\ndef get_init_inputs():\n    return [num_input_features, num_output_features]\n", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    num_input_features: int\n    num_output_features: int\n\n    @nn.compact\n    def __call__(self, x):\n        # BatchNorm over channel axis (axis=1 for NCHW)\n        x = nn.BatchNorm(use_running_average=False, axis=1, momentum=0.1, epsilon=1e-5)(x)\n        x = nn.relu(x)\n        x = nn.Conv(\n            features=self.num_output_features,\n            kernel_size=(1, 1),\n            strides=(1, 1),\n            use_bias=False\n        )(x)\n        # AvgPool2d with kernel_size=2, stride=2, NCHW\n        x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2), padding='VALID', data_format='NCHW')\n        return x\n\nbatch_size = 128\nnum_input_features = 32\nnum_output_features = 64\nheight, width = 256, 256\n\ndef get_inputs():\n    # Return a list with a single input array, shape (batch, channels, height, width)\n    key = jax.random.PRNGKey(0)\n    x = jax.random.uniform(\n        key,\n        (batch_size, num_input_features, height, width),\n        minval=0.0,\n        maxval=1.0\n    )\n    return [x]\n\ndef get_init_inputs():\n    return [num_input_features, num_output_features]"}
{"kb_id": "kb_level_3_0004", "level": "level_3", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/pytorch_samples/kb_level_3_0004.py", "jax_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/jax_outputs/kb_level_3_0004_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, num_layers: int, num_input_features: int, growth_rate: int):\n        \"\"\"\n        :param num_layers: The number of layers in the dense block\n        :param num_input_features: The number of input feature maps\n        :param growth_rate: The growth rate for the dense block (new features added per layer)\n        \"\"\"\n        super(Model, self).__init__()\n        layers = []\n        for i in range(num_layers):\n            layers.append(self._make_layer(num_input_features + i * growth_rate, growth_rate))\n        self.layers = nn.ModuleList(layers)\n\n    def _make_layer(self, in_features: int, growth_rate: int):\n        \"\"\"\n        Creates a single layer with BatchNorm, ReLU, Conv2D, and Dropout.\n        \"\"\"\n        return nn.Sequential(\n            nn.BatchNorm2d(in_features),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_features, growth_rate, kernel_size=3, padding=1, bias=False),\n            nn.Dropout(0.0)\n        )\n    \n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor of shape (batch_size, num_input_features, height, width)\n        :return: Concatenated output tensor with shape (batch_size, num_output_features, height, width)\n        \"\"\"\n        features = [x]\n        for layer in self.layers:\n            new_feature = layer(x)\n            features.append(new_feature)\n            x = torch.cat(features, 1)  # Concatenate along channel axis\n        return x\n    \nbatch_size = 10\nnum_layers = 6\nnum_input_features = 32\ngrowth_rate = 32\nheight, width = 224, 224\n\ndef get_inputs():\n    return [torch.rand(batch_size, num_input_features, height, width)]\n\ndef get_init_inputs():\n    return [num_layers, num_input_features , growth_rate]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\nfrom typing import List\n\nclass Model(nn.Module):\n    num_layers: int\n    num_input_features: int\n    growth_rate: int\n\n    @nn.compact\n    def __call__(self, x):\n        features = [x]\n        for i in range(self.num_layers):\n            in_features = self.num_input_features + i * self.growth_rate\n            new_feature = self._make_layer(in_features, self.growth_rate)(x)\n            features.append(new_feature)\n            x = jnp.concatenate(features, axis=1)\n        return x\n\n    def _make_layer(self, in_features, growth_rate):\n        return nn.Sequential([\n            nn.BatchNorm(use_running_average=False, axis=1),\n            nn.relu,\n            nn.Conv(features=growth_rate, kernel_size=(3, 3), padding='SAME', use_bias=False),\n            nn.Dropout(rate=0.0, deterministic=True)\n        ])\n\nbatch_size = 10\nnum_layers = 6\nnum_input_features = 32\ngrowth_rate = 32\nheight, width = 224, 224\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, num_input_features, height, width)]\n\ndef get_init_inputs():\n    return [num_layers, num_input_features, growth_rate]"}
{"kb_id": "kb_level_3_0005", "level": "level_3", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/pytorch_samples/kb_level_3_0005.py", "jax_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/jax_outputs/kb_level_3_0005_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass DenseBlock(nn.Module):\n    def __init__(self, num_layers: int, num_input_features: int, growth_rate: int):\n        \"\"\"\n        :param num_layers: The number of layers in the dense block\n        :param num_input_features: The number of input feature maps\n        :param growth_rate: The growth rate for the dense block (new features added per layer)\n        \"\"\"\n        super(DenseBlock, self).__init__()\n        layers = []\n        for i in range(num_layers):\n            layers.append(self._make_layer(num_input_features + i * growth_rate, growth_rate))\n        self.layers = nn.ModuleList(layers)\n\n    def _make_layer(self, in_features: int, growth_rate: int):\n        \"\"\"\n        Creates a single layer with BatchNorm, ReLU, Conv2D, and Dropout.\n        \"\"\"\n        return nn.Sequential(\n            nn.BatchNorm2d(in_features),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_features, growth_rate, kernel_size=3, padding=1, bias=False),\n            nn.Dropout(0.0)\n        )\n\n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor of shape (batch_size, num_input_features, height, width)\n        :return: Concatenated output tensor with shape (batch_size, num_output_features, height, width)\n        \"\"\"\n        features = [x]\n        for layer in self.layers:\n            new_feature = layer(x)\n            features.append(new_feature)\n            x = torch.cat(features, 1)  # Concatenate along channel axis\n        return x\n\nclass TransitionLayer(nn.Module):\n    def __init__(self, num_input_features: int, num_output_features: int):\n        \"\"\"\n        :param num_input_features: The number of input feature maps\n        :param num_output_features: The number of output feature maps\n        \"\"\"\n        super(TransitionLayer, self).__init__()\n        self.transition = nn.Sequential(\n            nn.BatchNorm2d(num_input_features),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(num_input_features, num_output_features, kernel_size=1, bias=False),\n            nn.AvgPool2d(kernel_size=2, stride=2)\n        )\n\n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor of shape (batch_size, num_input_features, height, width)\n        :return: Downsampled tensor with reduced number of feature maps\n        \"\"\"\n        return self.transition(x)\n\nclass Model(nn.Module):\n    def __init__(self, growth_rate: int = 32, num_classes: int = 1000):\n        \"\"\"\n        :param growth_rate: The growth rate of the DenseNet (new features added per layer)\n        :param num_classes: The number of output classes for classification\n        \"\"\"\n        super(Model, self).__init__()\n\n        # Initial convolution and pooling\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        )\n\n        # Each dense block is followed by a transition layer, except the last one\n        num_features = 64\n        block_layers = [6, 12, 24, 16]  # Corresponding layers in DenseNet121\n\n        self.dense_blocks = nn.ModuleList()\n        self.transition_layers = nn.ModuleList()\n\n        for i, num_layers in enumerate(block_layers):\n            block = DenseBlock(num_layers=num_layers, num_input_features=num_features, growth_rate=growth_rate)\n            self.dense_blocks.append(block)\n            num_features = num_features + num_layers * growth_rate\n\n            if i != len(block_layers) - 1:\n                transition = TransitionLayer(num_input_features=num_features, num_output_features=num_features // 2)\n                self.transition_layers.append(transition)\n                num_features = num_features // 2\n\n        # Final batch norm and classifier\n        self.final_bn = nn.BatchNorm2d(num_features)\n        self.classifier = nn.Linear(num_features, num_classes)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        :param x: Input tensor of shape (batch_size, 3, height, width)\n        :return: Output tensor of shape (batch_size, num_classes)\n        \"\"\"\n        x = self.features(x)\n\n        for i, block in enumerate(self.dense_blocks):\n            x = block(x)\n            if i != len(self.dense_blocks) - 1:\n                x = self.transition_layers[i](x)\n\n        x = self.final_bn(x)\n        x = F.relu(x, inplace=True)\n        x = F.adaptive_avg_pool2d(x, (1, 1)).view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\n# Testing the DenseNet121 model\nbatch_size = 10\nnum_classes = 10\nheight, width = 224, 224  # Standard input size for DenseNet\n\ndef get_inputs():\n    return [torch.rand(batch_size, 3, height, width)]\n\ndef get_init_inputs():\n    return [32, num_classes]\n", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass DenseBlock(nn.Module):\n    num_layers: int\n    num_input_features: int\n    growth_rate: int\n\n    @nn.compact\n    def __call__(self, x):\n        features = [x]\n        for i in range(self.num_layers):\n            in_features = self.num_input_features + i * self.growth_rate\n            # BatchNorm + ReLU + Conv2D + Dropout\n            y = nn.BatchNorm(use_running_average=False, axis=1)(x)\n            y = nn.relu(y)\n            y = nn.Conv(self.growth_rate, kernel_size=(3,3), padding='SAME', use_bias=False, feature_group_count=1)(y)\n            y = nn.Dropout(0.0, deterministic=True)(y)\n            features.append(y)\n            x = jnp.concatenate(features, axis=1)\n        return x\n\nclass TransitionLayer(nn.Module):\n    num_input_features: int\n    num_output_features: int\n\n    @nn.compact\n    def __call__(self, x):\n        x = nn.BatchNorm(use_running_average=False, axis=1)(x)\n        x = nn.relu(x)\n        x = nn.Conv(self.num_output_features, kernel_size=(1,1), use_bias=False)(x)\n        # AvgPool2d(kernel_size=2, stride=2)\n        x = nn.avg_pool(x, window_shape=(2,2), strides=(2,2), padding='VALID')\n        return x\n\nclass Model(nn.Module):\n    growth_rate: int = 32\n    num_classes: int = 1000\n\n    @nn.compact\n    def __call__(self, x, train: bool = False):\n        # Initial convolution and pooling\n        x = nn.Conv(64, kernel_size=(7,7), strides=(2,2), padding='SAME', use_bias=False)(x)\n        x = nn.BatchNorm(use_running_average=not train, axis=1)(x)\n        x = nn.relu(x)\n        # MaxPool2d(kernel_size=3, stride=2, padding=1)\n        x = nn.max_pool(x, window_shape=(3,3), strides=(2,2), padding='SAME')\n\n        num_features = 64\n        block_layers = [6, 12, 24, 16]  # DenseNet121\n\n        dense_blocks = []\n        transition_layers = []\n        for i, num_layers in enumerate(block_layers):\n            dense_blocks.append(\n                DenseBlock(num_layers=num_layers, num_input_features=num_features, growth_rate=self.growth_rate)\n            )\n            num_features = num_features + num_layers * self.growth_rate\n            if i != len(block_layers) - 1:\n                transition_layers.append(\n                    TransitionLayer(num_input_features=num_features, num_output_features=num_features // 2)\n                )\n                num_features = num_features // 2\n\n        # Sequentially apply dense blocks and transition layers\n        for i, block in enumerate(dense_blocks):\n            x = block(x)\n            if i != len(dense_blocks) - 1:\n                x = transition_layers[i](x)\n\n        x = nn.BatchNorm(use_running_average=not train, axis=1)(x)\n        x = nn.relu(x)\n        # Adaptive avg pool to (1,1)\n        x = jnp.mean(x, axis=(2,3), keepdims=True)\n        x = x.reshape((x.shape[0], -1))\n        x = nn.Dense(self.num_classes)(x)\n        return x\n\n# Testing the DenseNet121 model\nbatch_size = 10\nnum_classes = 10\nheight, width = 224, 224  # Standard input size for DenseNet\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, 3, height, width).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [32, num_classes]"}
{"kb_id": "kb_level_3_0006", "level": "level_3", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.125, "success": true, "pytorch_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/pytorch_samples/kb_level_3_0006.py", "jax_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/jax_outputs/kb_level_3_0006_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass DenseBlock(nn.Module):\n    def __init__(self, num_layers: int, num_input_features: int, growth_rate: int):\n        \"\"\"\n        :param num_layers: The number of layers in the dense block\n        :param num_input_features: The number of input feature maps\n        :param growth_rate: The growth rate for the dense block (new features added per layer)\n        \"\"\"\n        super(DenseBlock, self).__init__()\n        layers = []\n        for i in range(num_layers):\n            layers.append(self._make_layer(num_input_features + i * growth_rate, growth_rate))\n        self.layers = nn.ModuleList(layers)\n\n    def _make_layer(self, in_features: int, growth_rate: int):\n        \"\"\"\n        Creates a single layer with BatchNorm, ReLU, Conv2D, and Dropout.\n        \"\"\"\n        return nn.Sequential(\n            nn.BatchNorm2d(in_features),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_features, growth_rate, kernel_size=3, padding=1, bias=False),\n            nn.Dropout(0.0)\n        )\n\n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor of shape (batch_size, num_input_features, height, width)\n        :return: Concatenated output tensor with shape (batch_size, num_output_features, height, width)\n        \"\"\"\n        features = [x]\n        for layer in self.layers:\n            new_feature = layer(x)\n            features.append(new_feature)\n            x = torch.cat(features, 1)  # Concatenate along channel axis\n        return x\n\nclass TransitionLayer(nn.Module):\n    def __init__(self, num_input_features: int, num_output_features: int):\n        \"\"\"\n        :param num_input_features: The number of input feature maps\n        :param num_output_features: The number of output feature maps\n        \"\"\"\n        super(TransitionLayer, self).__init__()\n        self.transition = nn.Sequential(\n            nn.BatchNorm2d(num_input_features),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(num_input_features, num_output_features, kernel_size=1, bias=False),\n            nn.AvgPool2d(kernel_size=2, stride=2)\n        )\n\n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor of shape (batch_size, num_input_features, height, width)\n        :return: Downsampled tensor with reduced number of feature maps\n        \"\"\"\n        return self.transition(x)\n\nclass Model(nn.Module):\n    def __init__(self, growth_rate: int = 32, num_classes: int = 1000):\n        \"\"\"\n        :param growth_rate: The growth rate of the DenseNet (new features added per layer)\n        :param num_classes: The number of output classes for classification\n        \"\"\"\n        super(Model, self).__init__()\n\n        # Initial convolution and pooling\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        )\n\n        # Each dense block is followed by a transition layer, except the last one\n        num_features = 64\n        block_layers = [6, 12, 48, 32]  # Corresponding layers in DenseNet201\n\n        self.dense_blocks = nn.ModuleList()\n        self.transition_layers = nn.ModuleList()\n\n        for i, num_layers in enumerate(block_layers):\n            block = DenseBlock(num_layers=num_layers, num_input_features=num_features, growth_rate=growth_rate)\n            self.dense_blocks.append(block)\n            num_features = num_features + num_layers * growth_rate\n\n            if i != len(block_layers) - 1:\n                transition = TransitionLayer(num_input_features=num_features, num_output_features=num_features // 2)\n                self.transition_layers.append(transition)\n                num_features = num_features // 2\n\n        # Final batch norm and classifier\n        self.final_bn = nn.BatchNorm2d(num_features)\n        self.classifier = nn.Linear(num_features, num_classes)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        :param x: Input tensor of shape (batch_size, 3, height, width)\n        :return: Output tensor of shape (batch_size, num_classes)\n        \"\"\"\n        x = self.features(x)\n\n        for i, block in enumerate(self.dense_blocks):\n            x = block(x)\n            if i != len(self.dense_blocks) - 1:\n                x = self.transition_layers[i](x)\n\n        x = self.final_bn(x)\n        x = F.relu(x, inplace=True)\n        x = F.adaptive_avg_pool2d(x, (1, 1)).view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\n# Testing the DenseNet201 model\nbatch_size = 10\nnum_classes = 10\nheight, width = 224, 224  # Standard input size for DenseNet\n\ndef get_inputs():\n    return [torch.rand(batch_size, 3, height, width)]\n\ndef get_init_inputs():\n    return [32, num_classes]\n", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass DenseBlock(nn.Module):\n    num_layers: int\n    num_input_features: int\n    growth_rate: int\n\n    @nn.compact\n    def __call__(self, x):\n        features = [x]\n        for i in range(self.num_layers):\n            in_features = self.num_input_features + i * self.growth_rate\n            new_feature = self._make_layer(in_features, self.growth_rate)(x)\n            features.append(new_feature)\n            x = jnp.concatenate(features, axis=1)\n        return x\n\n    def _make_layer(self, in_features, growth_rate):\n        return nn.Sequential([\n            nn.BatchNorm(use_running_average=False, axis=1),\n            nn.relu,\n            nn.Conv(features=growth_rate, kernel_size=(3,3), padding='SAME', use_bias=False),\n            nn.Dropout(rate=0.0, deterministic=True)\n        ])\n\nclass TransitionLayer(nn.Module):\n    num_input_features: int\n    num_output_features: int\n\n    @nn.compact\n    def __call__(self, x):\n        x = nn.BatchNorm(use_running_average=False, axis=1)(x)\n        x = nn.relu(x)\n        x = nn.Conv(features=self.num_output_features, kernel_size=(1,1), use_bias=False)(x)\n        x = nn.avg_pool(x, window_shape=(2,2), strides=(2,2), padding='VALID')\n        return x\n\nclass Model(nn.Module):\n    growth_rate: int = 32\n    num_classes: int = 1000\n\n    @nn.compact\n    def __call__(self, x):\n        # Initial convolution and pooling\n        x = nn.Conv(features=64, kernel_size=(7,7), strides=(2,2), padding='SAME', use_bias=False)(x)\n        x = nn.BatchNorm(use_running_average=False, axis=1)(x)\n        x = nn.relu(x)\n        x = nn.max_pool(x, window_shape=(3,3), strides=(2,2), padding='SAME')\n\n        num_features = 64\n        block_layers = [6, 12, 48, 32]\n        dense_blocks = []\n        transition_layers = []\n\n        for i, num_layers in enumerate(block_layers):\n            x = DenseBlock(num_layers=num_layers, num_input_features=num_features, growth_rate=self.growth_rate)(x)\n            num_features = num_features + num_layers * self.growth_rate\n            if i != len(block_layers) - 1:\n                x = TransitionLayer(num_input_features=num_features, num_output_features=num_features // 2)(x)\n                num_features = num_features // 2\n\n        x = nn.BatchNorm(use_running_average=False, axis=1)(x)\n        x = nn.relu(x)\n        # Adaptive avg pool to (1,1)\n        x = jnp.mean(x, axis=(2,3), keepdims=True)\n        x = x.reshape((x.shape[0], -1))\n        x = nn.Dense(features=self.num_classes)(x)\n        return x\n\n# Testing the DenseNet201 model\nbatch_size = 10\nnum_classes = 10\nheight, width = 224, 224\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, 3, height, width).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [32, num_classes]"}
{"kb_id": "kb_level_3_0008", "level": "level_3", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.87364620938628, "success": true, "pytorch_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/pytorch_samples/kb_level_3_0008.py", "jax_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/jax_outputs/kb_level_3_0008_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass FireModule(nn.Module):\n    def __init__(self, in_channels, squeeze_channels, expand1x1_channels, expand3x3_channels):\n        \"\"\"\n        :param in_channels: Number of input channels\n        :param squeeze_channels: Number of output channels for the squeeze layer\n        :param expand1x1_channels: Number of output channels for the 1x1 expand layer\n        :param expand3x3_channels: Number of output channels for the 3x3 expand layer\n        \"\"\"\n        super(FireModule, self).__init__()\n        \n        self.squeeze = nn.Conv2d(in_channels, squeeze_channels, kernel_size=1)\n        self.squeeze_activation = nn.ReLU(inplace=True)\n        \n        self.expand1x1 = nn.Conv2d(squeeze_channels, expand1x1_channels, kernel_size=1)\n        self.expand1x1_activation = nn.ReLU(inplace=True)\n        \n        self.expand3x3 = nn.Conv2d(squeeze_channels, expand3x3_channels, kernel_size=3, padding=1)\n        self.expand3x3_activation = nn.ReLU(inplace=True)\n    \n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor, shape (batch_size, in_channels, height, width)\n        :return: Output tensor, shape (batch_size, expand1x1_channels + expand3x3_channels, height, width)\n        \"\"\"\n        x = self.squeeze_activation(self.squeeze(x))\n        return torch.cat([\n            self.expand1x1_activation(self.expand1x1(x)),\n            self.expand3x3_activation(self.expand3x3(x))\n        ], 1)\n\nclass Model(nn.Module):\n    def __init__(self, num_classes=1000):\n        \"\"\"\n        :param num_classes: Number of output classes\n        \"\"\"\n        super(Model, self).__init__()\n        \n        self.features = nn.Sequential(\n            nn.Conv2d(3, 96, kernel_size=7, stride=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n            FireModule(96, 16, 64, 64),\n            FireModule(128, 16, 64, 64),\n            FireModule(128, 32, 128, 128),\n            nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n            FireModule(256, 32, 128, 128),\n            FireModule(256, 48, 192, 192),\n            FireModule(384, 48, 192, 192),\n            FireModule(384, 64, 256, 256),\n            nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n            FireModule(512, 64, 256, 256),\n        )\n        \n        self.classifier = nn.Sequential(\n            nn.Dropout(p=0.0),\n            nn.Conv2d(512, num_classes, kernel_size=1),\n            nn.ReLU(inplace=True),\n            nn.AdaptiveAvgPool2d((1, 1))\n        )\n    \n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor, shape (batch_size, 3, height, width)\n        :return: Output tensor, shape (batch_size, num_classes)\n        \"\"\"\n        x = self.features(x)\n        x = self.classifier(x)\n        return torch.flatten(x, 1)\n\n# Test code\nbatch_size = 64\ninput_channels = 3\nheight = 512\nwidth = 512\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_channels, height, width)]\n\ndef get_init_inputs():\n    return [num_classes]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass FireModule(nn.Module):\n    in_channels: int\n    squeeze_channels: int\n    expand1x1_channels: int\n    expand3x3_channels: int\n\n    @nn.compact\n    def __call__(self, x):\n        # Squeeze layer\n        x = nn.Conv(self.squeeze_channels, kernel_size=(1,1), strides=(1,1), use_bias=True)(x)\n        x = nn.relu(x)\n        # Expand 1x1\n        x1 = nn.Conv(self.expand1x1_channels, kernel_size=(1,1), strides=(1,1), use_bias=True)(x)\n        x1 = nn.relu(x1)\n        # Expand 3x3\n        x3 = nn.Conv(self.expand3x3_channels, kernel_size=(3,3), strides=(1,1), padding='SAME', use_bias=True)(x)\n        x3 = nn.relu(x3)\n        # Concatenate along channel axis\n        return jnp.concatenate([x1, x3], axis=1)\n\nclass Model(nn.Module):\n    num_classes: int = 1000\n\n    @nn.compact\n    def __call__(self, x, train: bool = False):\n        # Input shape: (batch, channels, height, width)\n        # Flax expects (batch, height, width, channels), so we need to transpose\n        x = jnp.transpose(x, (0,2,3,1))  # (N, H, W, C)\n\n        # Conv1\n        x = nn.Conv(96, kernel_size=(7,7), strides=(2,2), use_bias=True)(x)\n        x = nn.relu(x)\n        # MaxPool1\n        x = nn.max_pool(x, window_shape=(3,3), strides=(2,2), padding='SAME')\n        # Fire modules\n        x = FireModule(96, 16, 64, 64)(x)\n        x = FireModule(128, 16, 64, 64)(x)\n        x = FireModule(128, 32, 128, 128)(x)\n        # MaxPool2\n        x = nn.max_pool(x, window_shape=(3,3), strides=(2,2), padding='SAME')\n        x = FireModule(256, 32, 128, 128)(x)\n        x = FireModule(256, 48, 192, 192)(x)\n        x = FireModule(384, 48, 192, 192)(x)\n        x = FireModule(384, 64, 256, 256)(x)\n        # MaxPool3\n        x = nn.max_pool(x, window_shape=(3,3), strides=(2,2), padding='SAME')\n        x = FireModule(512, 64, 256, 256)(x)\n        # Classifier\n        x = nn.Dropout(rate=0.0, deterministic=not train)(x)\n        x = nn.Conv(self.num_classes, kernel_size=(1,1), strides=(1,1), use_bias=True)(x)\n        x = nn.relu(x)\n        # AdaptiveAvgPool2d((1,1)) equivalent: mean over H and W\n        x = jnp.mean(x, axis=(1,2), keepdims=True)\n        # Flatten\n        x = x.reshape((x.shape[0], -1))\n        return x\n\n# Test code\nbatch_size = 64\ninput_channels = 3\nheight = 512\nwidth = 512\nnum_classes = 1000\n\ndef get_inputs():\n    # Return a list with a single input array, shape (batch, channels, height, width)\n    return [jax.random.uniform(jax.random.PRNGKey(0), (batch_size, input_channels, height, width))]\n\ndef get_init_inputs():\n    return [num_classes]"}
{"kb_id": "kb_level_3_0009", "level": "level_3", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.37275985663082, "success": true, "pytorch_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/pytorch_samples/kb_level_3_0009.py", "jax_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/jax_outputs/kb_level_3_0009_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, num_classes=1000, input_channels=3, alpha=1.0):\n        \"\"\"\n        MobileNetV1 architecture implementation.\n\n        :param num_classes: The number of output classes (default: 1000)\n        :param input_channels: The number of input channels (default: 3 for RGB images)\n        :param alpha: Width multiplier (default: 1.0)\n        \"\"\"\n        super(Model, self).__init__()\n        \n        def conv_bn(inp, oup, stride):\n            return nn.Sequential(\n                nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n                nn.BatchNorm2d(oup),\n                nn.ReLU(inplace=True)\n            )\n        \n        def conv_dw(inp, oup, stride):\n            return nn.Sequential(\n                nn.Conv2d(inp, inp, 3, stride, 1, groups=inp, bias=False),\n                nn.BatchNorm2d(inp),\n                nn.ReLU(inplace=True),\n                \n                nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n                nn.BatchNorm2d(oup),\n                nn.ReLU(inplace=True),\n            )\n        \n        self.model = nn.Sequential(\n            conv_bn(input_channels, int(32 * alpha), 2),\n            conv_dw(int(32 * alpha), int(64 * alpha), 1),\n            conv_dw(int(64 * alpha), int(128 * alpha), 2),\n            conv_dw(int(128 * alpha), int(128 * alpha), 1),\n            conv_dw(int(128 * alpha), int(256 * alpha), 2),\n            conv_dw(int(256 * alpha), int(256 * alpha), 1),\n            conv_dw(int(256 * alpha), int(512 * alpha), 2),\n            conv_dw(int(512 * alpha), int(512 * alpha), 1),\n            conv_dw(int(512 * alpha), int(512 * alpha), 1),\n            conv_dw(int(512 * alpha), int(512 * alpha), 1),\n            conv_dw(int(512 * alpha), int(512 * alpha), 1),\n            conv_dw(int(512 * alpha), int(512 * alpha), 1),\n            conv_dw(int(512 * alpha), int(1024 * alpha), 2),\n            conv_dw(int(1024 * alpha), int(1024 * alpha), 1),\n            nn.AvgPool2d(7),\n        )\n        self.fc = nn.Linear(int(1024 * alpha), num_classes)\n    \n    def forward(self, x):\n        \"\"\"\n        :param x: The input tensor, shape (batch_size, input_channels, height, width)\n        :return: The output tensor, shape (batch_size, num_classes)\n        \"\"\"\n        x = self.model(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n\n# Test code\nbatch_size = 10\ninput_channels = 3\nheight = 224\nwidth = 224\nnum_classes = 1000\nalpha = 1.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_channels, height, width)]\n\ndef get_init_inputs():\n    return [num_classes, input_channels, alpha]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass ConvBN(nn.Module):\n    inp: int\n    oup: int\n    stride: int\n\n    @nn.compact\n    def __call__(self, x):\n        x = nn.Conv(features=self.oup, kernel_size=(3,3), strides=(self.stride, self.stride), padding='SAME', use_bias=False)(x)\n        x = nn.BatchNorm(use_running_average=False, momentum=0.9, epsilon=1e-5)(x)\n        x = nn.relu(x)\n        return x\n\nclass ConvDW(nn.Module):\n    inp: int\n    oup: int\n    stride: int\n\n    @nn.compact\n    def __call__(self, x):\n        # Depthwise conv\n        x = nn.Conv(features=self.inp, kernel_size=(3,3), strides=(self.stride, self.stride), padding='SAME', feature_group_count=self.inp, use_bias=False)(x)\n        x = nn.BatchNorm(use_running_average=False, momentum=0.9, epsilon=1e-5)(x)\n        x = nn.relu(x)\n        # Pointwise conv\n        x = nn.Conv(features=self.oup, kernel_size=(1,1), strides=(1,1), padding='VALID', use_bias=False)(x)\n        x = nn.BatchNorm(use_running_average=False, momentum=0.9, epsilon=1e-5)(x)\n        x = nn.relu(x)\n        return x\n\nclass Model(nn.Module):\n    num_classes: int = 1000\n    input_channels: int = 3\n    alpha: float = 1.0\n\n    @nn.compact\n    def __call__(self, x, train=True):\n        def ch(v):\n            return int(v * self.alpha)\n\n        x = ConvBN(self.input_channels, ch(32), 2)(x)\n        x = ConvDW(ch(32), ch(64), 1)(x)\n        x = ConvDW(ch(64), ch(128), 2)(x)\n        x = ConvDW(ch(128), ch(128), 1)(x)\n        x = ConvDW(ch(128), ch(256), 2)(x)\n        x = ConvDW(ch(256), ch(256), 1)(x)\n        x = ConvDW(ch(256), ch(512), 2)(x)\n        x = ConvDW(ch(512), ch(512), 1)(x)\n        x = ConvDW(ch(512), ch(512), 1)(x)\n        x = ConvDW(ch(512), ch(512), 1)(x)\n        x = ConvDW(ch(512), ch(512), 1)(x)\n        x = ConvDW(ch(512), ch(512), 1)(x)\n        x = ConvDW(ch(512), ch(1024), 2)(x)\n        x = ConvDW(ch(1024), ch(1024), 1)(x)\n        # AvgPool2d(7) in PyTorch is global average pooling for 224x224 input\n        # After all the strides, the feature map is 7x7, so pool over all\n        x = jnp.mean(x, axis=(2,3), keepdims=False)\n        x = nn.Dense(features=self.num_classes)(x)\n        return x\n\n# Test code\nbatch_size = 10\ninput_channels = 3\nheight = 224\nwidth = 224\nnum_classes = 1000\nalpha = 1.0\n\ndef get_inputs():\n    # Flax expects NHWC by default, but we keep NCHW for direct mapping\n    # We'll transpose to NHWC for Flax\n    x = jnp.random.rand(batch_size, input_channels, height, width).astype(jnp.float32)\n    x = jnp.transpose(x, (0,2,3,1))  # NCHW -> NHWC\n    return [x]\n\ndef get_init_inputs():\n    return [num_classes, input_channels, alpha]"}
{"kb_id": "kb_level_3_0010", "level": "level_3", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/pytorch_samples/kb_level_3_0010.py", "jax_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/jax_outputs/kb_level_3_0010_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, input_size, layer_sizes, output_size):\n        \"\"\"\n        :param input_size: The number of input features\n        :param layer_sizes: A list of ints containing the sizes of each hidden layer\n        :param output_size: The number of output features\n        \"\"\"\n        super(Model, self).__init__()\n        \n        layers = []\n        current_input_size = input_size\n        \n        for layer_size in layer_sizes:\n            layers.append(nn.Linear(current_input_size, layer_size))\n            layers.append(nn.ReLU())\n            current_input_size = layer_size\n        \n        layers.append(nn.Linear(current_input_size, output_size))\n        \n        self.network = nn.Sequential(*layers)\n    \n    def forward(self, x):\n        \"\"\"\n        :param x: The input tensor, shape (batch_size, input_size)\n        :return: The output tensor, shape (batch_size, output_size)\n        \"\"\"\n        return self.network(x)\n\n# Test code\nbatch_size = 128\ninput_size = 16384\nlayer_sizes = [16384, 16384]\noutput_size = 8192\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, layer_sizes, output_size]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    input_size: int\n    layer_sizes: list\n    output_size: int\n\n    @nn.compact\n    def __call__(self, x):\n        current_input_size = self.input_size\n        for layer_size in self.layer_sizes:\n            x = nn.Dense(features=layer_size)(x)\n            x = nn.relu(x)\n            current_input_size = layer_size\n        x = nn.Dense(features=self.output_size)(x)\n        return x\n\n# Test code\nbatch_size = 128\ninput_size = 16384\nlayer_sizes = [16384, 16384]\noutput_size = 8192\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, layer_sizes, output_size]"}
{"kb_id": "kb_level_3_0011", "level": "level_3", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/pytorch_samples/kb_level_3_0011.py", "jax_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/jax_outputs/kb_level_3_0011_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, num_classes=1000):\n        \"\"\"\n        MobileNetV2 architecture implementation in PyTorch.\n\n        :param num_classes: The number of output classes. Default is 1000.\n        \"\"\"\n        super(Model, self).__init__()\n        \n        def _make_divisible(v, divisor, min_value=None):\n            \"\"\"\n            This function ensures that the number of channels is divisible by the divisor.\n            \"\"\"\n            if min_value is None:\n                min_value = divisor\n            new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n            # Make sure that round down does not go down by more than 10%.\n            if new_v < 0.9 * v:\n                new_v += divisor\n            return new_v\n\n        def _inverted_residual_block(inp, oup, stride, expand_ratio):\n            \"\"\"\n            Inverted Residual Block for MobileNetV2.\n            \"\"\"\n            hidden_dim = int(inp * expand_ratio)\n            use_res_connect = stride == 1 and inp == oup\n\n            layers = []\n            if expand_ratio != 1:\n                # Pointwise convolution\n                layers.append(nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False))\n                layers.append(nn.BatchNorm2d(hidden_dim))\n                layers.append(nn.ReLU6(inplace=True))\n\n            layers.extend([\n                # Depthwise convolution\n                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n                nn.BatchNorm2d(hidden_dim),\n                nn.ReLU6(inplace=True),\n                # Pointwise linear convolution\n                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n                nn.BatchNorm2d(oup),\n            ])\n\n            if use_res_connect:\n                return nn.Sequential(*layers), True\n            else:\n                return nn.Sequential(*layers), False\n\n        # MobileNetV2 architecture\n        input_channel = 32\n        last_channel = 1280\n        inverted_residual_setting = [\n            # t, c, n, s\n            [1, 16, 1, 1],\n            [6, 24, 2, 2],\n            [6, 32, 3, 2],\n            [6, 64, 4, 2],\n            [6, 96, 3, 1],\n            [6, 160, 3, 2],\n            [6, 320, 1, 1],\n        ]\n\n        # Building first layer\n        features = [nn.Conv2d(3, input_channel, 3, 2, 1, bias=False),\n                    nn.BatchNorm2d(input_channel),\n                    nn.ReLU6(inplace=True)]\n\n        # Building inverted residual blocks\n        for t, c, n, s in inverted_residual_setting:\n            output_channel = _make_divisible(c, 8)\n            for i in range(n):\n                stride = s if i == 0 else 1\n                features.append(_inverted_residual_block(input_channel, output_channel, stride, expand_ratio=t)[0])\n                input_channel = output_channel\n\n        # Building last several layers\n        features.append(nn.Conv2d(input_channel, last_channel, 1, 1, 0, bias=False))\n        features.append(nn.BatchNorm2d(last_channel))\n        features.append(nn.ReLU6(inplace=True))\n\n        # Final layer\n        features.append(nn.AdaptiveAvgPool2d((1, 1)))\n\n        self.features = nn.Sequential(*features)\n\n        # Linear layer\n        self.classifier = nn.Sequential(\n            nn.Dropout(0.0),\n            nn.Linear(last_channel, num_classes),\n        )\n\n        # Weight initialization\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out')\n                if m.bias is not None:\n                    nn.init.zeros_(m.bias)\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.ones_(m.weight)\n                nn.init.zeros_(m.bias)\n            elif isinstance(m, nn.Linear):\n                nn.init.normal_(m.weight, 0, 0.01)\n                nn.init.zeros_(m.bias)\n\n    def forward(self, x):\n        \"\"\"\n        Forward pass of the MobileNetV2 model.\n\n        :param x: The input tensor, shape (batch_size, 3, 224, 224)\n        :return: The output tensor, shape (batch_size, num_classes)\n        \"\"\"\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\n# Test code\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.rand(batch_size, 3, 224, 224)]\n\ndef get_init_inputs():\n    return [num_classes]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\nfrom typing import Any, Callable, Sequence\n\ndef _make_divisible(v, divisor, min_value=None):\n    if min_value is None:\n        min_value = divisor\n    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n    if new_v < 0.9 * v:\n        new_v += divisor\n    return new_v\n\nclass ReLU6(nn.Module):\n    @nn.compact\n    def __call__(self, x):\n        return jnp.clip(x, 0, 6)\n\nclass ConvBNReLU(nn.Module):\n    out_channels: int\n    kernel_size: int\n    stride: int\n    groups: int = 1\n\n    @nn.compact\n    def __call__(self, x):\n        x = nn.Conv(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size),\n            strides=(self.stride, self.stride),\n            padding='SAME',\n            use_bias=False,\n            feature_group_count=self.groups,\n        )(x)\n        x = nn.BatchNorm(use_running_average=False)(x)\n        x = ReLU6()(x)\n        return x\n\nclass InvertedResidual(nn.Module):\n    inp: int\n    oup: int\n    stride: int\n    expand_ratio: int\n\n    @nn.compact\n    def __call__(self, x):\n        hidden_dim = int(self.inp * self.expand_ratio)\n        use_res_connect = self.stride == 1 and self.inp == self.oup\n\n        out = x\n        if self.expand_ratio != 1:\n            out = ConvBNReLU(\n                out_channels=hidden_dim,\n                kernel_size=1,\n                stride=1\n            )(out)\n        # Depthwise\n        out = ConvBNReLU(\n            out_channels=hidden_dim,\n            kernel_size=3,\n            stride=self.stride,\n            groups=hidden_dim\n        )(out)\n        # Pointwise linear\n        out = nn.Conv(\n            features=self.oup,\n            kernel_size=(1, 1),\n            strides=(1, 1),\n            padding='VALID',\n            use_bias=False\n        )(out)\n        out = nn.BatchNorm(use_running_average=False)(out)\n        if use_res_connect:\n            return x + out\n        else:\n            return out\n\nclass Model(nn.Module):\n    num_classes: int = 1000\n\n    @nn.compact\n    def __call__(self, x):\n        input_channel = 32\n        last_channel = 1280\n        inverted_residual_setting = [\n            # t, c, n, s\n            [1, 16, 1, 1],\n            [6, 24, 2, 2],\n            [6, 32, 3, 2],\n            [6, 64, 4, 2],\n            [6, 96, 3, 1],\n            [6, 160, 3, 2],\n            [6, 320, 1, 1],\n        ]\n\n        # First layer\n        x = nn.Conv(\n            features=input_channel,\n            kernel_size=(3, 3),\n            strides=(2, 2),\n            padding='SAME',\n            use_bias=False\n        )(x)\n        x = nn.BatchNorm(use_running_average=False)(x)\n        x = ReLU6()(x)\n\n        # Inverted residual blocks\n        in_c = input_channel\n        for t, c, n, s in inverted_residual_setting:\n            out_c = _make_divisible(c, 8)\n            for i in range(n):\n                stride = s if i == 0 else 1\n                x = InvertedResidual(\n                    inp=in_c,\n                    oup=out_c,\n                    stride=stride,\n                    expand_ratio=t\n                )(x)\n                in_c = out_c\n\n        # Last several layers\n        x = nn.Conv(\n            features=last_channel,\n            kernel_size=(1, 1),\n            strides=(1, 1),\n            padding='VALID',\n            use_bias=False\n        )(x)\n        x = nn.BatchNorm(use_running_average=False)(x)\n        x = ReLU6()(x)\n\n        # Global average pooling\n        x = jnp.mean(x, axis=(1, 2), keepdims=True)\n        x = x.reshape((x.shape[0], -1))\n\n        # Classifier\n        x = nn.Dropout(rate=0.0, deterministic=False)(x)\n        x = nn.Dense(features=self.num_classes)(x)\n        return x\n\n# Test code\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [jnp.ones((batch_size, 224, 224, 3), dtype=jnp.float32)]\n\ndef get_init_inputs():\n    return [num_classes]\n\n# Example usage:\n# model = Model(num_classes=num_classes)\n# rng = jax.random.PRNGKey(0)\n# variables = model.init(rng, jnp.ones((batch_size, 224, 224, 3)))\n# out = model.apply(variables, jnp.ones((batch_size, 224, 224, 3)))"}
{"kb_id": "kb_level_3_0013", "level": "level_3", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.74774774774775, "success": true, "pytorch_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/pytorch_samples/kb_level_3_0013.py", "jax_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/jax_outputs/kb_level_3_0013_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, num_classes=1000):\n        \"\"\"\n        EfficientNetB0 architecture implementation in PyTorch.\n\n        :param num_classes: The number of output classes (default is 1000 for ImageNet).\n        \"\"\"\n        super(Model, self).__init__()\n        \n        # Initial convolutional layer\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(32)\n        \n        # MBConv blocks\n        self.blocks = nn.Sequential(\n            # MBConv1 (32, 16, 1, 1)\n            MBConv(32, 16, kernel_size=3, stride=1, expand_ratio=1),\n            # MBConv6 (16, 24, 2, 6)\n            MBConv(16, 24, kernel_size=3, stride=2, expand_ratio=6),\n            # MBConv6 (24, 24, 1, 6)\n            MBConv(24, 24, kernel_size=3, stride=1, expand_ratio=6),\n            # MBConv6 (24, 40, 2, 6)\n            MBConv(24, 40, kernel_size=5, stride=2, expand_ratio=6),\n            # MBConv6 (40, 40, 1, 6)\n            MBConv(40, 40, kernel_size=5, stride=1, expand_ratio=6),\n            # MBConv6 (40, 80, 2, 6)\n            MBConv(40, 80, kernel_size=3, stride=2, expand_ratio=6),\n            # MBConv6 (80, 80, 1, 6)\n            MBConv(80, 80, kernel_size=3, stride=1, expand_ratio=6),\n            # MBConv6 (80, 112, 1, 6)\n            MBConv(80, 112, kernel_size=5, stride=1, expand_ratio=6),\n            # MBConv6 (112, 112, 1, 6)\n            MBConv(112, 112, kernel_size=5, stride=1, expand_ratio=6),\n            # MBConv6 (112, 192, 2, 6)\n            MBConv(112, 192, kernel_size=5, stride=2, expand_ratio=6),\n            # MBConv6 (192, 192, 1, 6)\n            MBConv(192, 192, kernel_size=5, stride=1, expand_ratio=6),\n            # MBConv6 (192, 192, 1, 6)\n            MBConv(192, 192, kernel_size=5, stride=1, expand_ratio=6),\n            # MBConv6 (192, 320, 1, 6)\n            MBConv(192, 320, kernel_size=3, stride=1, expand_ratio=6)\n        )\n        \n        # Final convolutional layer\n        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn2 = nn.BatchNorm2d(1280)\n        \n        # Fully connected layer\n        self.fc = nn.Linear(1280, num_classes)\n    \n    def forward(self, x):\n        \"\"\"\n        Forward pass of the EfficientNetB0 model.\n\n        :param x: The input tensor, shape (batch_size, 3, 224, 224)\n        :return: The output tensor, shape (batch_size, num_classes)\n        \"\"\"\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.blocks(x)\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = F.adaptive_avg_pool2d(x, (1, 1))\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n\nclass MBConv(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride, expand_ratio):\n        \"\"\"\n        MBConv block implementation.\n\n        :param in_channels: Number of input channels.\n        :param out_channels: Number of output channels.\n        :param kernel_size: Kernel size for the depthwise convolution.\n        :param stride: Stride for the depthwise convolution.\n        :param expand_ratio: Expansion ratio for the intermediate channels.\n        \"\"\"\n        super(MBConv, self).__init__()\n        \n        self.use_residual = (stride == 1 and in_channels == out_channels)\n        hidden_dim = in_channels * expand_ratio\n        \n        if expand_ratio != 1:\n            self.expand_conv = nn.Sequential(\n                nn.Conv2d(in_channels, hidden_dim, kernel_size=1, stride=1, padding=0, bias=False),\n                nn.BatchNorm2d(hidden_dim),\n                nn.ReLU6(inplace=True)\n            )\n        \n        self.depthwise_conv = nn.Sequential(\n            nn.Conv2d(hidden_dim, hidden_dim, kernel_size=kernel_size, stride=stride, padding=(kernel_size-1)//2, groups=hidden_dim, bias=False),\n            nn.BatchNorm2d(hidden_dim),\n            nn.ReLU6(inplace=True)\n        )\n        \n        self.project_conv = nn.Sequential(\n            nn.Conv2d(hidden_dim, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(out_channels)\n        )\n    \n    def forward(self, x):\n        \"\"\"\n        Forward pass of the MBConv block.\n\n        :param x: The input tensor, shape (batch_size, in_channels, H, W)\n        :return: The output tensor, shape (batch_size, out_channels, H', W')\n        \"\"\"\n        identity = x\n        \n        if hasattr(self, 'expand_conv'):\n            x = self.expand_conv(x)\n        \n        x = self.depthwise_conv(x)\n        x = self.project_conv(x)\n        \n        if self.use_residual:\n            x += identity\n        \n        return x\n\n# Test code\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.rand(batch_size, 3, 224, 224)]\n\ndef get_init_inputs():\n    return [num_classes]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass MBConv(nn.Module):\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    stride: int\n    expand_ratio: int\n\n    @nn.compact\n    def __call__(self, x, train=True):\n        use_residual = (self.stride == 1 and self.in_channels == self.out_channels)\n        hidden_dim = self.in_channels * self.expand_ratio\n\n        out = x\n        if self.expand_ratio != 1:\n            out = nn.Conv(features=hidden_dim, kernel_size=(1,1), strides=(1,1), padding='VALID', use_bias=False, name='expand_conv')(out)\n            out = nn.BatchNorm(use_running_average=not train, name='expand_bn')(out)\n            out = nn.relu6(out)\n\n        # Depthwise convolution\n        out = nn.Conv(\n            features=hidden_dim,\n            kernel_size=(self.kernel_size, self.kernel_size),\n            strides=(self.stride, self.stride),\n            padding=[(self.kernel_size//2, self.kernel_size//2), (self.kernel_size//2, self.kernel_size//2)],\n            feature_group_count=hidden_dim,\n            use_bias=False,\n            name='depthwise_conv'\n        )(out)\n        out = nn.BatchNorm(use_running_average=not train, name='depthwise_bn')(out)\n        out = nn.relu6(out)\n\n        # Project\n        out = nn.Conv(features=self.out_channels, kernel_size=(1,1), strides=(1,1), padding='VALID', use_bias=False, name='project_conv')(out)\n        out = nn.BatchNorm(use_running_average=not train, name='project_bn')(out)\n\n        if use_residual:\n            out = out + x\n\n        return out\n\nclass Model(nn.Module):\n    num_classes: int = 1000\n\n    @nn.compact\n    def __call__(self, x, train=True):\n        # Initial conv\n        x = nn.Conv(features=32, kernel_size=(3,3), strides=(2,2), padding=[(1,1),(1,1)], use_bias=False, name='conv1')(x)\n        x = nn.BatchNorm(use_running_average=not train, name='bn1')(x)\n        x = nn.relu(x)\n\n        # MBConv blocks\n        x = MBConv(32, 16, kernel_size=3, stride=1, expand_ratio=1, name='mbconv1')(x, train=train)\n        x = MBConv(16, 24, kernel_size=3, stride=2, expand_ratio=6, name='mbconv2')(x, train=train)\n        x = MBConv(24, 24, kernel_size=3, stride=1, expand_ratio=6, name='mbconv3')(x, train=train)\n        x = MBConv(24, 40, kernel_size=5, stride=2, expand_ratio=6, name='mbconv4')(x, train=train)\n        x = MBConv(40, 40, kernel_size=5, stride=1, expand_ratio=6, name='mbconv5')(x, train=train)\n        x = MBConv(40, 80, kernel_size=3, stride=2, expand_ratio=6, name='mbconv6')(x, train=train)\n        x = MBConv(80, 80, kernel_size=3, stride=1, expand_ratio=6, name='mbconv7')(x, train=train)\n        x = MBConv(80, 112, kernel_size=5, stride=1, expand_ratio=6, name='mbconv8')(x, train=train)\n        x = MBConv(112, 112, kernel_size=5, stride=1, expand_ratio=6, name='mbconv9')(x, train=train)\n        x = MBConv(112, 192, kernel_size=5, stride=2, expand_ratio=6, name='mbconv10')(x, train=train)\n        x = MBConv(192, 192, kernel_size=5, stride=1, expand_ratio=6, name='mbconv11')(x, train=train)\n        x = MBConv(192, 192, kernel_size=5, stride=1, expand_ratio=6, name='mbconv12')(x, train=train)\n        x = MBConv(192, 320, kernel_size=3, stride=1, expand_ratio=6, name='mbconv13')(x, train=train)\n\n        # Final conv\n        x = nn.Conv(features=1280, kernel_size=(1,1), strides=(1,1), padding='VALID', use_bias=False, name='conv2')(x)\n        x = nn.BatchNorm(use_running_average=not train, name='bn2')(x)\n        x = nn.relu(x)\n\n        # Adaptive avg pool to (1,1)\n        x = jnp.mean(x, axis=(2,3), keepdims=True)\n        x = x.reshape((x.shape[0], -1))\n\n        # FC\n        x = nn.Dense(features=self.num_classes, name='fc')(x)\n        return x\n\n# Test code\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [jnp.ones((batch_size, 3, 224, 224), dtype=jnp.float32)]\n\ndef get_init_inputs():\n    return [num_classes]"}
{"kb_id": "kb_level_3_0014", "level": "level_3", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.74774774774775, "success": true, "pytorch_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/pytorch_samples/kb_level_3_0014.py", "jax_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/jax_outputs/kb_level_3_0014_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, num_classes=1000):\n        \"\"\"\n        EfficientNetB1 architecture implementation.\n\n        :param num_classes: The number of output classes (default is 1000 for ImageNet).\n        \"\"\"\n        super(Model, self).__init__()\n        \n        # Initial convolutional layer\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(32)\n        \n        # MBConv blocks\n        self.mbconv1 = self._make_mbconv_block(32, 16, 1, 1)\n        self.mbconv2 = self._make_mbconv_block(16, 24, 2, 6)\n        self.mbconv3 = self._make_mbconv_block(24, 40, 2, 6)\n        self.mbconv4 = self._make_mbconv_block(40, 80, 2, 6)\n        self.mbconv5 = self._make_mbconv_block(80, 112, 1, 6)\n        self.mbconv6 = self._make_mbconv_block(112, 192, 2, 6)\n        self.mbconv7 = self._make_mbconv_block(192, 320, 1, 6)\n        \n        # Final convolutional layer\n        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn2 = nn.BatchNorm2d(1280)\n        \n        # Fully connected layer\n        self.fc = nn.Linear(1280, num_classes)\n    \n    def _make_mbconv_block(self, in_channels, out_channels, stride, expand_ratio):\n        \"\"\"\n        Creates a MBConv block.\n\n        :param in_channels: Number of input channels.\n        :param out_channels: Number of output channels.\n        :param stride: Stride of the depthwise convolution.\n        :param expand_ratio: Expansion ratio for the hidden layer.\n        :return: A sequential MBConv block.\n        \"\"\"\n        hidden_dim = round(in_channels * expand_ratio)\n        return nn.Sequential(\n            nn.Conv2d(in_channels, hidden_dim, kernel_size=1, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(hidden_dim),\n            nn.ReLU6(inplace=True),\n            nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, stride=stride, padding=1, groups=hidden_dim, bias=False),\n            nn.BatchNorm2d(hidden_dim),\n            nn.ReLU6(inplace=True),\n            nn.Conv2d(hidden_dim, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(out_channels),\n        )\n    \n    def forward(self, x):\n        \"\"\"\n        Forward pass of the EfficientNetB1 model.\n\n        :param x: Input tensor, shape (batch_size, 3, 240, 240)\n        :return: Output tensor, shape (batch_size, num_classes)\n        \"\"\"\n        x = F.relu(self.bn1(self.conv1(x)))\n        \n        x = self.mbconv1(x)\n        x = self.mbconv2(x)\n        x = self.mbconv3(x)\n        x = self.mbconv4(x)\n        x = self.mbconv5(x)\n        x = self.mbconv6(x)\n        x = self.mbconv7(x)\n        \n        x = F.relu(self.bn2(self.conv2(x)))\n        x = F.adaptive_avg_pool2d(x, (1, 1))\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n        \n        return x\n\n# Test code\nbatch_size = 10\ninput_shape = (3, 240, 240)\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.rand(batch_size, *input_shape)]\n\ndef get_init_inputs():\n    return [num_classes]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass ReLU6(nn.Module):\n    @nn.compact\n    def __call__(self, x):\n        return jnp.clip(x, 0, 6)\n\nclass MBConvBlock(nn.Module):\n    in_channels: int\n    out_channels: int\n    stride: int\n    expand_ratio: int\n\n    @nn.compact\n    def __call__(self, x, train=True):\n        hidden_dim = int(round(self.in_channels * self.expand_ratio))\n        # Expansion phase\n        x1 = nn.Conv(features=hidden_dim, kernel_size=(1,1), strides=(1,1), use_bias=False, padding='VALID')(x)\n        x1 = nn.BatchNorm(use_running_average=not train)(x1)\n        x1 = ReLU6()(x1)\n        # Depthwise conv\n        x1 = nn.Conv(features=hidden_dim, kernel_size=(3,3), strides=(self.stride, self.stride), \n                     use_bias=False, padding='SAME', feature_group_count=hidden_dim)(x1)\n        x1 = nn.BatchNorm(use_running_average=not train)(x1)\n        x1 = ReLU6()(x1)\n        # Projection\n        x1 = nn.Conv(features=self.out_channels, kernel_size=(1,1), strides=(1,1), use_bias=False, padding='VALID')(x1)\n        x1 = nn.BatchNorm(use_running_average=not train)(x1)\n        return x1\n\nclass Model(nn.Module):\n    num_classes: int = 1000\n\n    @nn.compact\n    def __call__(self, x, train=True):\n        # Initial conv\n        x = nn.Conv(features=32, kernel_size=(3,3), strides=(2,2), use_bias=False, padding='SAME')(x)\n        x = nn.BatchNorm(use_running_average=not train)(x)\n        x = nn.relu(x)\n        # MBConv blocks\n        x = MBConvBlock(32, 16, 1, 1)(x, train=train)\n        x = MBConvBlock(16, 24, 2, 6)(x, train=train)\n        x = MBConvBlock(24, 40, 2, 6)(x, train=train)\n        x = MBConvBlock(40, 80, 2, 6)(x, train=train)\n        x = MBConvBlock(80, 112, 1, 6)(x, train=train)\n        x = MBConvBlock(112, 192, 2, 6)(x, train=train)\n        x = MBConvBlock(192, 320, 1, 6)(x, train=train)\n        # Final conv\n        x = nn.Conv(features=1280, kernel_size=(1,1), strides=(1,1), use_bias=False, padding='VALID')(x)\n        x = nn.BatchNorm(use_running_average=not train)(x)\n        x = nn.relu(x)\n        # Adaptive avg pool to (1,1)\n        x = jnp.mean(x, axis=(2,3), keepdims=True)\n        # Flatten\n        x = x.reshape((x.shape[0], -1))\n        # FC\n        x = nn.Dense(features=self.num_classes)(x)\n        return x\n\n# Test code\nbatch_size = 10\ninput_shape = (3, 240, 240)\nnum_classes = 1000\n\ndef get_inputs():\n    # JAX expects NHWC by default, but Flax Conv2D supports NCHW if input is NCHW\n    # We'll keep NCHW to match PyTorch\n    key = jax.random.PRNGKey(0)\n    x = jax.random.uniform(key, (batch_size, *input_shape), dtype=jnp.float32)\n    return [x]\n\ndef get_init_inputs():\n    return [num_classes]"}
{"kb_id": "kb_level_3_0015", "level": "level_3", "prompt_tag": "gpt41_strict_full_v2", "aqs": 68.87900355871885, "success": true, "pytorch_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/pytorch_samples/kb_level_3_0015.py", "jax_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/jax_outputs/kb_level_3_0015_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, num_classes=1000):\n        \"\"\"\n        EfficientNetB2 architecture implementation.\n\n        :param num_classes: The number of output classes (default is 1000 for ImageNet).\n        \"\"\"\n        super(Model, self).__init__()\n        \n        # Define the EfficientNetB2 architecture components\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(32)\n        self.relu = nn.ReLU(inplace=True)\n        \n        # Define the MBConv blocks\n        self.mbconv1 = self._make_mbconv_block(32, 96, 1, 3)\n        self.mbconv2 = self._make_mbconv_block(96, 144, 2, 6)\n        self.mbconv3 = self._make_mbconv_block(144, 192, 2, 6)\n        self.mbconv4 = self._make_mbconv_block(192, 288, 2, 6)\n        self.mbconv5 = self._make_mbconv_block(288, 384, 1, 6)\n        \n        # Final layers\n        self.conv_final = nn.Conv2d(384, 1408, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn_final = nn.BatchNorm2d(1408)\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(1408, num_classes)\n    \n    def _make_mbconv_block(self, in_channels, out_channels, stride, expand_ratio):\n        \"\"\"\n        Helper function to create a MBConv block.\n\n        :param in_channels: Number of input channels.\n        :param out_channels: Number of output channels.\n        :param stride: Stride for the depthwise convolution.\n        :param expand_ratio: Expansion ratio for the MBConv block.\n        :return: A sequential container of layers forming the MBConv block.\n        \"\"\"\n        layers = []\n        expanded_channels = in_channels * expand_ratio\n        \n        # Expansion phase\n        if expand_ratio != 1:\n            layers.append(nn.Conv2d(in_channels, expanded_channels, kernel_size=1, stride=1, padding=0, bias=False))\n            layers.append(nn.BatchNorm2d(expanded_channels))\n            layers.append(nn.ReLU(inplace=True))\n        \n        # Depthwise convolution\n        layers.append(nn.Conv2d(expanded_channels, expanded_channels, kernel_size=3, stride=stride, padding=1, groups=expanded_channels, bias=False))\n        layers.append(nn.BatchNorm2d(expanded_channels))\n        layers.append(nn.ReLU(inplace=True))\n        \n        # Squeeze and Excitation\n        layers.append(nn.AdaptiveAvgPool2d((1, 1)))\n        layers.append(nn.Conv2d(expanded_channels, expanded_channels // 4, kernel_size=1, stride=1, padding=0, bias=False))\n        layers.append(nn.ReLU(inplace=True))\n        layers.append(nn.Conv2d(expanded_channels // 4, expanded_channels, kernel_size=1, stride=1, padding=0, bias=False))\n        layers.append(nn.Sigmoid())\n        \n        # Output phase\n        layers.append(nn.Conv2d(expanded_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False))\n        layers.append(nn.BatchNorm2d(out_channels))\n        \n        return nn.Sequential(*layers)\n    \n    def forward(self, x):\n        \"\"\"\n        Forward pass of the EfficientNetB2 model.\n\n        :param x: The input tensor, shape (batch_size, 3, 224, 224)\n        :return: The output tensor, shape (batch_size, num_classes)\n        \"\"\"\n        x = self.relu(self.bn1(self.conv1(x)))\n        x = self.mbconv1(x)\n        x = self.mbconv2(x)\n        x = self.mbconv3(x)\n        x = self.mbconv4(x)\n        x = self.mbconv5(x)\n        x = self.relu(self.bn_final(self.conv_final(x)))\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n        return x\n\n# Test code\nbatch_size = 2\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.rand(batch_size, 3, 224, 224)]\n\ndef get_init_inputs():\n    return [num_classes]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass SqueezeExcite(nn.Module):\n    in_channels: int\n    se_ratio: float = 0.25\n\n    @nn.compact\n    def __call__(self, x):\n        # x: (batch, H, W, C)\n        channels = self.in_channels\n        reduced_channels = max(1, int(channels * self.se_ratio))\n        # Squeeze: global average pooling\n        se = jnp.mean(x, axis=(1, 2), keepdims=True)\n        se = nn.Conv(features=reduced_channels, kernel_size=(1, 1), strides=(1, 1), use_bias=False)(se)\n        se = nn.relu(se)\n        se = nn.Conv(features=channels, kernel_size=(1, 1), strides=(1, 1), use_bias=False)(se)\n        se = nn.sigmoid(se)\n        return x * se\n\nclass MBConvBlock(nn.Module):\n    in_channels: int\n    out_channels: int\n    stride: int\n    expand_ratio: int\n\n    @nn.compact\n    def __call__(self, x):\n        # x: (batch, H, W, C)\n        residual = x\n        expanded_channels = self.in_channels * self.expand_ratio\n\n        # Expansion phase\n        if self.expand_ratio != 1:\n            x = nn.Conv(features=expanded_channels, kernel_size=(1, 1), strides=(1, 1), use_bias=False)(x)\n            x = nn.BatchNorm(use_running_average=False)(x)\n            x = nn.relu(x)\n        else:\n            expanded_channels = self.in_channels\n\n        # Depthwise convolution\n        x = nn.Conv(\n            features=expanded_channels,\n            kernel_size=(3, 3),\n            strides=(self.stride, self.stride),\n            padding='SAME',\n            feature_group_count=expanded_channels,\n            use_bias=False\n        )(x)\n        x = nn.BatchNorm(use_running_average=False)(x)\n        x = nn.relu(x)\n\n        # Squeeze and Excitation\n        x = SqueezeExcite(expanded_channels)(x)\n\n        # Output phase\n        x = nn.Conv(features=self.out_channels, kernel_size=(1, 1), strides=(1, 1), use_bias=False)(x)\n        x = nn.BatchNorm(use_running_average=False)(x)\n\n        # Residual connection if possible\n        if self.stride == 1 and self.in_channels == self.out_channels:\n            x = x + residual\n        return x\n\nclass AdaptiveAvgPool2d(nn.Module):\n    output_size: tuple\n\n    @nn.compact\n    def __call__(self, x):\n        # x: (batch, H, W, C)\n        return jnp.mean(x, axis=(1, 2), keepdims=True)\n\nclass Model(nn.Module):\n    num_classes: int = 1000\n\n    @nn.compact\n    def __call__(self, x):\n        # x: (batch, 3, 224, 224)\n        # Flax expects (batch, H, W, C)\n        x = jnp.transpose(x, (0, 2, 3, 1))\n\n        # Stem\n        x = nn.Conv(features=32, kernel_size=(3, 3), strides=(2, 2), padding='SAME', use_bias=False)(x)\n        x = nn.BatchNorm(use_running_average=False)(x)\n        x = nn.relu(x)\n\n        # MBConv blocks\n        x = MBConvBlock(32, 96, stride=1, expand_ratio=3)(x)\n        x = MBConvBlock(96, 144, stride=2, expand_ratio=6)(x)\n        x = MBConvBlock(144, 192, stride=2, expand_ratio=6)(x)\n        x = MBConvBlock(192, 288, stride=2, expand_ratio=6)(x)\n        x = MBConvBlock(288, 384, stride=1, expand_ratio=6)(x)\n\n        # Final layers\n        x = nn.Conv(features=1408, kernel_size=(1, 1), strides=(1, 1), use_bias=False)(x)\n        x = nn.BatchNorm(use_running_average=False)(x)\n        x = nn.relu(x)\n        x = AdaptiveAvgPool2d((1, 1))(x)\n        x = x.reshape((x.shape[0], -1))\n        x = nn.Dense(features=self.num_classes)(x)\n        return x\n\n# Test code\nbatch_size = 2\nnum_classes = 1000\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, 3, 224, 224).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [num_classes]"}
{"kb_id": "kb_level_3_0016", "level": "level_3", "prompt_tag": "gpt41_strict_full_v2", "aqs": 67.91228070175438, "success": true, "pytorch_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/pytorch_samples/kb_level_3_0016.py", "jax_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/jax_outputs/kb_level_3_0016_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, in_channels, out_channels, groups=3):\n        \"\"\"\n        ShuffleNet unit implementation.\n\n        :param in_channels: Number of input channels.\n        :param out_channels: Number of output channels.\n        :param groups: Number of groups for group convolution.\n        \"\"\"\n        super(Model, self).__init__()\n        \n        # Ensure the output channels are divisible by groups\n        assert out_channels % 4 == 0\n        mid_channels = out_channels // 4\n        \n        # First 1x1 group convolution\n        self.conv1 = nn.Conv2d(in_channels, mid_channels, kernel_size=1, stride=1, padding=0, groups=groups, bias=False)\n        self.bn1 = nn.BatchNorm2d(mid_channels)\n        \n        # Depthwise 3x3 convolution\n        self.conv2 = nn.Conv2d(mid_channels, mid_channels, kernel_size=3, stride=1, padding=1, groups=mid_channels, bias=False)\n        self.bn2 = nn.BatchNorm2d(mid_channels)\n        \n        # Second 1x1 group convolution\n        self.conv3 = nn.Conv2d(mid_channels, out_channels, kernel_size=1, stride=1, padding=0, groups=groups, bias=False)\n        self.bn3 = nn.BatchNorm2d(out_channels)\n        \n        # Shuffle operation\n        self.shuffle = ChannelShuffle(groups)\n        \n        # Shortcut connection if input and output channels are the same\n        if in_channels == out_channels:\n            self.shortcut = nn.Sequential()\n        else:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n                nn.BatchNorm2d(out_channels)\n            )\n    \n    def forward(self, x):\n        \"\"\"\n        Forward pass for ShuffleNet unit.\n\n        :param x: Input tensor, shape (batch_size, in_channels, height, width)\n        :return: Output tensor, shape (batch_size, out_channels, height, width)\n        \"\"\"\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out = self.shuffle(out)\n        out = F.relu(self.bn3(self.conv3(out)))\n        \n        out += self.shortcut(x)\n        return out\n\nclass ChannelShuffle(nn.Module):\n    def __init__(self, groups):\n        \"\"\"\n        Channel shuffle operation.\n\n        :param groups: Number of groups for shuffling.\n        \"\"\"\n        super(ChannelShuffle, self).__init__()\n        self.groups = groups\n    \n    def forward(self, x):\n        \"\"\"\n        Forward pass for channel shuffle.\n\n        :param x: Input tensor, shape (batch_size, channels, height, width)\n        :return: Output tensor, shape (batch_size, channels, height, width)\n        \"\"\"\n        batch_size, channels, height, width = x.size()\n        channels_per_group = channels // self.groups\n        \n        # Reshape\n        x = x.view(batch_size, self.groups, channels_per_group, height, width)\n        \n        # Transpose\n        x = x.transpose(1, 2).contiguous()\n        \n        # Flatten\n        x = x.view(batch_size, -1, height, width)\n        \n        return x\n    \nbatch_size = 10\ninput_channels = 240\nout_channels = 480\ngroups = 3\nheight = 224\nwidth = 224\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_channels, height, width)]\n\ndef get_init_inputs():\n    return [input_channels, out_channels, groups]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass ChannelShuffle(nn.Module):\n    groups: int\n\n    @nn.compact\n    def __call__(self, x):\n        # x: (batch, channels, height, width)\n        batch_size, channels, height, width = x.shape\n        channels_per_group = channels // self.groups\n        # Reshape to (batch, groups, channels_per_group, height, width)\n        x = x.reshape((batch_size, self.groups, channels_per_group, height, width))\n        # Transpose to (batch, channels_per_group, groups, height, width)\n        x = jnp.transpose(x, (0, 2, 1, 3, 4))\n        # Flatten back to (batch, channels, height, width)\n        x = x.reshape((batch_size, channels, height, width))\n        return x\n\nclass Model(nn.Module):\n    in_channels: int\n    out_channels: int\n    groups: int = 3\n\n    @nn.compact\n    def __call__(self, x, train: bool = True):\n        assert self.out_channels % 4 == 0\n        mid_channels = self.out_channels // 4\n\n        # First 1x1 group convolution\n        conv1 = nn.Conv(\n            features=mid_channels,\n            kernel_size=(1, 1),\n            strides=(1, 1),\n            padding='VALID',\n            feature_group_count=self.groups,\n            use_bias=False,\n            name='conv1'\n        )\n        bn1 = nn.BatchNorm(use_running_average=not train, name='bn1')\n        # Depthwise 3x3 convolution\n        conv2 = nn.Conv(\n            features=mid_channels,\n            kernel_size=(3, 3),\n            strides=(1, 1),\n            padding='SAME',\n            feature_group_count=mid_channels,\n            use_bias=False,\n            name='conv2'\n        )\n        bn2 = nn.BatchNorm(use_running_average=not train, name='bn2')\n        # Second 1x1 group convolution\n        conv3 = nn.Conv(\n            features=self.out_channels,\n            kernel_size=(1, 1),\n            strides=(1, 1),\n            padding='VALID',\n            feature_group_count=self.groups,\n            use_bias=False,\n            name='conv3'\n        )\n        bn3 = nn.BatchNorm(use_running_average=not train, name='bn3')\n        shuffle = ChannelShuffle(self.groups)\n\n        # Shortcut connection\n        if self.in_channels == self.out_channels:\n            def shortcut_fn(x, train):\n                return x\n        else:\n            def shortcut_fn(x, train):\n                y = nn.Conv(\n                    features=self.out_channels,\n                    kernel_size=(1, 1),\n                    strides=(1, 1),\n                    padding='VALID',\n                    use_bias=False,\n                    name='shortcut_conv'\n                )(x)\n                y = nn.BatchNorm(use_running_average=not train, name='shortcut_bn')(y)\n                return y\n\n        out = conv1(x)\n        out = bn1(out)\n        out = nn.relu(out)\n        out = conv2(out)\n        out = bn2(out)\n        out = shuffle(out)\n        out = conv3(out)\n        out = bn3(out)\n        out = nn.relu(out)\n        out = out + shortcut_fn(x, train)\n        return out\n\nbatch_size = 10\ninput_channels = 240\nout_channels = 480\ngroups = 3\nheight = 224\nwidth = 224\nnum_classes = 1000\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, input_channels, height, width).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [input_channels, out_channels, groups]"}
{"kb_id": "kb_level_3_0017", "level": "level_3", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/pytorch_samples/kb_level_3_0017.py", "jax_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/jax_outputs/kb_level_3_0017_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass ShuffleNetUnit(nn.Module):\n    def __init__(self, in_channels, out_channels, groups=3):\n        \"\"\"\n        ShuffleNet unit implementation.\n\n        :param in_channels: Number of input channels.\n        :param out_channels: Number of output channels.\n        :param groups: Number of groups for group convolution.\n        \"\"\"\n        super(ShuffleNetUnit, self).__init__()\n        \n        # Ensure the output channels are divisible by groups\n        assert out_channels % 4 == 0\n        mid_channels = out_channels // 4\n        \n        # First 1x1 group convolution\n        self.conv1 = nn.Conv2d(in_channels, mid_channels, kernel_size=1, stride=1, padding=0, groups=groups, bias=False)\n        self.bn1 = nn.BatchNorm2d(mid_channels)\n        \n        # Depthwise 3x3 convolution\n        self.conv2 = nn.Conv2d(mid_channels, mid_channels, kernel_size=3, stride=1, padding=1, groups=mid_channels, bias=False)\n        self.bn2 = nn.BatchNorm2d(mid_channels)\n        \n        # Second 1x1 group convolution\n        self.conv3 = nn.Conv2d(mid_channels, out_channels, kernel_size=1, stride=1, padding=0, groups=groups, bias=False)\n        self.bn3 = nn.BatchNorm2d(out_channels)\n        \n        # Shuffle operation\n        self.shuffle = ChannelShuffle(groups)\n        \n        # Shortcut connection if input and output channels are the same\n        if in_channels == out_channels:\n            self.shortcut = nn.Sequential()\n        else:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n                nn.BatchNorm2d(out_channels)\n            )\n    \n    def forward(self, x):\n        \"\"\"\n        Forward pass for ShuffleNet unit.\n\n        :param x: Input tensor, shape (batch_size, in_channels, height, width)\n        :return: Output tensor, shape (batch_size, out_channels, height, width)\n        \"\"\"\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out = self.shuffle(out)\n        out = F.relu(self.bn3(self.conv3(out)))\n        \n        out += self.shortcut(x)\n        return out\n\nclass ChannelShuffle(nn.Module):\n    def __init__(self, groups):\n        \"\"\"\n        Channel shuffle operation.\n\n        :param groups: Number of groups for shuffling.\n        \"\"\"\n        super(ChannelShuffle, self).__init__()\n        self.groups = groups\n    \n    def forward(self, x):\n        \"\"\"\n        Forward pass for channel shuffle.\n\n        :param x: Input tensor, shape (batch_size, channels, height, width)\n        :return: Output tensor, shape (batch_size, channels, height, width)\n        \"\"\"\n        batch_size, channels, height, width = x.size()\n        channels_per_group = channels // self.groups\n        \n        # Reshape\n        x = x.view(batch_size, self.groups, channels_per_group, height, width)\n        \n        # Transpose\n        x = x.transpose(1, 2).contiguous()\n        \n        # Flatten\n        x = x.view(batch_size, -1, height, width)\n        \n        return x\n\nclass Model(nn.Module):\n    def __init__(self, num_classes=1000, groups=3, stages_repeats=[3, 7, 3], stages_out_channels=[24, 240, 480, 960]):\n        \"\"\"\n        ShuffleNet architecture.\n\n        :param num_classes: Number of output classes.\n        :param groups: Number of groups for group convolution.\n        :param stages_repeats: List of ints specifying the number of repeats for each stage.\n        :param stages_out_channels: List of ints specifying the output channels for each stage.\n        \"\"\"\n        super(Model, self).__init__()\n        \n        self.conv1 = nn.Conv2d(3, stages_out_channels[0], kernel_size=3, stride=2, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(stages_out_channels[0])\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        \n        self.stage2 = self._make_stage(stages_out_channels[0], stages_out_channels[1], stages_repeats[0], groups)\n        self.stage3 = self._make_stage(stages_out_channels[1], stages_out_channels[2], stages_repeats[1], groups)\n        self.stage4 = self._make_stage(stages_out_channels[2], stages_out_channels[3], stages_repeats[2], groups)\n        \n        self.conv5 = nn.Conv2d(stages_out_channels[3], 1024, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn5 = nn.BatchNorm2d(1024)\n        \n        self.fc = nn.Linear(1024, num_classes)\n    \n    def _make_stage(self, in_channels, out_channels, repeats, groups):\n        \"\"\"\n        Helper function to create a stage of ShuffleNet units.\n\n        :param in_channels: Number of input channels.\n        :param out_channels: Number of output channels.\n        :param repeats: Number of ShuffleNet units in the stage.\n        :param groups: Number of groups for group convolution.\n        :return: nn.Sequential containing the stage.\n        \"\"\"\n        layers = []\n        layers.append(ShuffleNetUnit(in_channels, out_channels, groups))\n        for _ in range(1, repeats):\n            layers.append(ShuffleNetUnit(out_channels, out_channels, groups))\n        return nn.Sequential(*layers)\n    \n    def forward(self, x):\n        \"\"\"\n        Forward pass for ShuffleNet.\n\n        :param x: Input tensor, shape (batch_size, 3, height, width)\n        :return: Output tensor, shape (batch_size, num_classes)\n        \"\"\"\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.maxpool(x)\n        \n        x = self.stage2(x)\n        x = self.stage3(x)\n        x = self.stage4(x)\n        \n        x = F.relu(self.bn5(self.conv5(x)))\n        x = F.adaptive_avg_pool2d(x, (1, 1))\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        \n        return x\n\n# Test code\nbatch_size = 10\ninput_channels = 3\nheight = 224\nwidth = 224\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_channels, height, width)]\n\ndef get_init_inputs():\n    return [num_classes]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\ndef channel_shuffle(x, groups):\n    # x: (batch, channels, height, width)\n    batch_size, channels, height, width = x.shape\n    channels_per_group = channels // groups\n    # Reshape\n    x = x.reshape(batch_size, groups, channels_per_group, height, width)\n    # Transpose group and channel dims\n    x = jnp.transpose(x, (0, 2, 1, 3, 4))\n    # Flatten\n    x = x.reshape(batch_size, channels, height, width)\n    return x\n\nclass ChannelShuffle(nn.Module):\n    groups: int\n\n    @nn.compact\n    def __call__(self, x):\n        return channel_shuffle(x, self.groups)\n\nclass ShuffleNetUnit(nn.Module):\n    in_channels: int\n    out_channels: int\n    groups: int = 3\n\n    @nn.compact\n    def __call__(self, x, *, train=True):\n        assert self.out_channels % 4 == 0\n        mid_channels = self.out_channels // 4\n\n        # First 1x1 group convolution\n        conv1 = nn.Conv(\n            features=mid_channels,\n            kernel_size=(1, 1),\n            strides=(1, 1),\n            padding='VALID',\n            use_bias=False,\n            feature_group_count=self.groups,\n            name='conv1'\n        )\n        bn1 = nn.BatchNorm(use_running_average=not train, name='bn1')\n        out = conv1(x)\n        out = bn1(out)\n        out = nn.relu(out)\n\n        # Depthwise 3x3 convolution\n        conv2 = nn.Conv(\n            features=mid_channels,\n            kernel_size=(3, 3),\n            strides=(1, 1),\n            padding='SAME',\n            use_bias=False,\n            feature_group_count=mid_channels,\n            name='conv2'\n        )\n        bn2 = nn.BatchNorm(use_running_average=not train, name='bn2')\n        out = conv2(out)\n        out = bn2(out)\n\n        # Shuffle operation\n        out = ChannelShuffle(self.groups)(out)\n\n        # Second 1x1 group convolution\n        conv3 = nn.Conv(\n            features=self.out_channels,\n            kernel_size=(1, 1),\n            strides=(1, 1),\n            padding='VALID',\n            use_bias=False,\n            feature_group_count=self.groups,\n            name='conv3'\n        )\n        bn3 = nn.BatchNorm(use_running_average=not train, name='bn3')\n        out = conv3(out)\n        out = bn3(out)\n        out = nn.relu(out)\n\n        # Shortcut connection\n        if self.in_channels == self.out_channels:\n            shortcut = x\n        else:\n            shortcut = nn.Conv(\n                features=self.out_channels,\n                kernel_size=(1, 1),\n                strides=(1, 1),\n                padding='VALID',\n                use_bias=False,\n                name='shortcut_conv'\n            )(x)\n            shortcut = nn.BatchNorm(use_running_average=not train, name='shortcut_bn')(shortcut)\n\n        out = out + shortcut\n        return out\n\nclass Sequential(nn.Module):\n    layers: list\n\n    def setup(self):\n        self._layers = [layer for layer in self.layers]\n\n    def __call__(self, x, *, train=True):\n        for layer in self._layers:\n            # If the layer is a Flax module, call with train if possible\n            if hasattr(layer, '__call__'):\n                try:\n                    x = layer(x, train=train)\n                except TypeError:\n                    x = layer(x)\n            else:\n                x = layer(x)\n        return x\n\nclass Model(nn.Module):\n    num_classes: int = 1000\n    groups: int = 3\n    stages_repeats: list = (3, 7, 3)\n    stages_out_channels: list = (24, 240, 480, 960)\n\n    @nn.compact\n    def __call__(self, x, *, train=True):\n        # Initial conv\n        x = nn.Conv(\n            features=self.stages_out_channels[0],\n            kernel_size=(3, 3),\n            strides=(2, 2),\n            padding='SAME',\n            use_bias=False,\n            name='conv1'\n        )(x)\n        x = nn.BatchNorm(use_running_average=not train, name='bn1')(x)\n        x = nn.relu(x)\n        x = nn.max_pool(\n            x,\n            window_shape=(3, 3),\n            strides=(2, 2),\n            padding='SAME'\n        )\n\n        # Stages\n        x = self._make_stage(\n            self.stages_out_channels[0],\n            self.stages_out_channels[1],\n            self.stages_repeats[0],\n            self.groups,\n            name='stage2'\n        )(x, train=train)\n        x = self._make_stage(\n            self.stages_out_channels[1],\n            self.stages_out_channels[2],\n            self.stages_repeats[1],\n            self.groups,\n            name='stage3'\n        )(x, train=train)\n        x = self._make_stage(\n            self.stages_out_channels[2],\n            self.stages_out_channels[3],\n            self.stages_repeats[2],\n            self.groups,\n            name='stage4'\n        )(x, train=train)\n\n        # Final conv\n        x = nn.Conv(\n            features=1024,\n            kernel_size=(1, 1),\n            strides=(1, 1),\n            padding='VALID',\n            use_bias=False,\n            name='conv5'\n        )(x)\n        x = nn.BatchNorm(use_running_average=not train, name='bn5')(x)\n        x = nn.relu(x)\n\n        # Global average pooling\n        x = jnp.mean(x, axis=(2, 3), keepdims=True)\n        x = x.reshape((x.shape[0], -1))\n        x = nn.Dense(features=self.num_classes, name='fc')(x)\n        return x\n\n    def _make_stage(self, in_channels, out_channels, repeats, groups, name=None):\n        layers = []\n        layers.append(ShuffleNetUnit(in_channels, out_channels, groups))\n        for _ in range(1, repeats):\n            layers.append(ShuffleNetUnit(out_channels, out_channels, groups))\n        return Sequential(layers=layers, name=name)\n\n# Test code\nbatch_size = 10\ninput_channels = 3\nheight = 224\nwidth = 224\nnum_classes = 1000\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, input_channels, height, width).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [num_classes]"}
{"kb_id": "kb_level_3_0018", "level": "level_3", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/pytorch_samples/kb_level_3_0018.py", "jax_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/jax_outputs/kb_level_3_0018_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, input_channels, stages, block_widths, output_classes):\n        \"\"\"\n        :param input_channels: int, Number of input channels for the first layer\n        :param stages: int, Number of stages in the RegNet architecture\n        :param block_widths: List[int], Width (number of channels) for each block in the stages\n        :param output_classes: int, Number of output classes for classification\n        \"\"\"\n        super(Model, self).__init__()\n\n        self.stages = stages\n        self.block_widths = block_widths\n        \n        layers = []\n        current_channels = input_channels\n        \n        # Construct the stages with their respective blocks\n        for i in range(stages):\n            layers.append(self._make_stage(current_channels, block_widths[i]))\n            current_channels = block_widths[i]\n        \n        self.feature_extractor = nn.Sequential(*layers)\n        \n        # Final fully connected layer for classification\n        self.fc = nn.Linear(block_widths[-1], output_classes)\n    \n    def _make_stage(self, in_channels, out_channels):\n        \"\"\"\n        Creates a simple block for each stage.\n        :param in_channels: int, number of input channels\n        :param out_channels: int, number of output channels\n        :return: nn.Sequential block with convolutional layers\n        \"\"\"\n        return nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(),\n            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n\n    def forward(self, x):\n        \"\"\"\n        Forward pass through the RegNet model.\n        :param x: torch.Tensor of shape (batch_size, input_channels, height, width)\n        :return: torch.Tensor of shape (batch_size, output_classes)\n        \"\"\"\n        x = self.feature_extractor(x)\n        x = torch.mean(x, dim=[2, 3])  # Global Average Pooling\n        x = self.fc(x)\n        return x\n\n# Test code for the RegNet model\nbatch_size = 8\ninput_channels = 3\nimage_height, image_width = 224, 224\nstages = 3\nblock_widths = [64, 128, 256]\noutput_classes = 10\n\ndef get_inputs():\n    \"\"\" Generates random input tensor of shape (batch_size, input_channels, height, width) \"\"\"\n    return [torch.rand(batch_size, input_channels, image_height, image_width)]\n\ndef get_init_inputs():\n    \"\"\" Initializes model parameters \"\"\"\n    return [input_channels, stages, block_widths, output_classes]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    input_channels: int\n    stages: int\n    block_widths: list\n    output_classes: int\n\n    @nn.compact\n    def __call__(self, x):\n        current_channels = self.input_channels\n        for i in range(self.stages):\n            x = self._make_stage(current_channels, self.block_widths[i])(x)\n            current_channels = self.block_widths[i]\n        # Global Average Pooling over spatial dimensions (H, W)\n        x = jnp.mean(x, axis=(2, 3))\n        x = nn.Dense(self.output_classes)(x)\n        return x\n\n    def _make_stage(self, in_channels, out_channels):\n        # Returns a Flax module that applies the stage\n        return StageBlock(in_channels, out_channels)\n\nclass StageBlock(nn.Module):\n    in_channels: int\n    out_channels: int\n\n    @nn.compact\n    def __call__(self, x):\n        x = nn.Conv(self.out_channels, kernel_size=(3,3), padding='SAME', use_bias=False)(x)\n        x = nn.BatchNorm(use_running_average=False)(x)\n        x = nn.relu(x)\n        x = nn.Conv(self.out_channels, kernel_size=(3,3), padding='SAME', use_bias=False)(x)\n        x = nn.BatchNorm(use_running_average=False)(x)\n        x = nn.relu(x)\n        x = nn.max_pool(x, window_shape=(2,2), strides=(2,2), padding='VALID')\n        return x\n\n# Test code for the RegNet model\nbatch_size = 8\ninput_channels = 3\nimage_height, image_width = 224, 224\nstages = 3\nblock_widths = [64, 128, 256]\noutput_classes = 10\n\ndef get_inputs():\n    \"\"\"Generates random input tensor of shape (batch_size, input_channels, height, width)\"\"\"\n    key = jax.random.PRNGKey(0)\n    x = jax.random.uniform(key, (batch_size, input_channels, image_height, image_width))\n    return [x]\n\ndef get_init_inputs():\n    \"\"\"Initializes model parameters\"\"\"\n    return [input_channels, stages, block_widths, output_classes]"}
{"kb_id": "kb_level_3_0019", "level": "level_3", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.0017825311943, "success": true, "pytorch_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/pytorch_samples/kb_level_3_0019.py", "jax_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/jax_outputs/kb_level_3_0019_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, channels=3, dropout=0.1, emb_dropout=0.1):\n        \"\"\"\n        Vision Transformer (ViT) model.\n\n        :param image_size: The size of the input image (assumed to be square).\n        :param patch_size: The size of each patch (assumed to be square).\n        :param num_classes: The number of output classes.\n        :param dim: The dimensionality of the embedding space.\n        :param depth: The number of transformer layers.\n        :param heads: The number of attention heads.\n        :param mlp_dim: The dimensionality of the MLP (Multi-Layer Perceptron) in the transformer.\n        :param channels: The number of channels in the input image (default is 3 for RGB).\n        :param dropout: Dropout rate applied in the MLP.\n        :param emb_dropout: Dropout rate applied to the embedded patches.\n        \"\"\"\n        super(Model, self).__init__()\n        \n        assert image_size % patch_size == 0, \"Image dimensions must be divisible by the patch size.\"\n        num_patches = (image_size // patch_size) ** 2\n        patch_dim = channels * patch_size ** 2\n        \n        self.patch_size = patch_size\n        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n        self.patch_to_embedding = nn.Linear(patch_dim, dim)\n        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n        self.dropout = nn.Dropout(emb_dropout)\n        \n        self.transformer = nn.TransformerEncoder(\n            nn.TransformerEncoderLayer(d_model=dim, nhead=heads, dim_feedforward=mlp_dim, dropout=dropout),\n            num_layers=depth\n        )\n        \n        self.to_cls_token = nn.Identity()\n        self.mlp_head = nn.Sequential(\n            nn.Linear(dim, mlp_dim),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(mlp_dim, num_classes)\n        )\n    \n    def forward(self, img):\n        \"\"\"\n        Forward pass of the Vision Transformer.\n\n        :param img: The input image tensor, shape (batch_size, channels, image_size, image_size).\n        :return: The output tensor, shape (batch_size, num_classes).\n        \"\"\"\n        p = self.patch_size\n        \n        x = img.unfold(2, p, p).unfold(3, p, p).reshape(img.shape[0], -1, p*p*img.shape[1])\n        x = self.patch_to_embedding(x)\n        \n        cls_tokens = self.cls_token.expand(img.shape[0], -1, -1)\n        x = torch.cat((cls_tokens, x), dim=1)\n        x += self.pos_embedding\n        x = self.dropout(x)\n        \n        x = self.transformer(x)\n        \n        x = self.to_cls_token(x[:, 0])\n        return self.mlp_head(x)\n\n# Test code\nimage_size = 224\npatch_size = 16\nnum_classes = 10\ndim = 512\ndepth = 6\nheads = 8\nmlp_dim = 2048\nchannels = 3\ndropout = 0.0\nemb_dropout = 0.0\n\ndef get_inputs():\n    return [torch.rand(2, channels, image_size, image_size)]\n\ndef get_init_inputs():\n    return [image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, channels, dropout, emb_dropout]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\nfrom typing import Any, Callable\nimport numpy as np\n\nclass MLP(nn.Module):\n    dim: int\n    mlp_dim: int\n    dropout: float\n\n    @nn.compact\n    def __call__(self, x, train: bool):\n        x = nn.Dense(self.mlp_dim)(x)\n        x = nn.gelu(x)\n        x = nn.Dropout(self.dropout)(x, deterministic=not train)\n        x = nn.Dense(self.dim)(x)\n        x = nn.Dropout(self.dropout)(x, deterministic=not train)\n        return x\n\nclass TransformerEncoderLayer(nn.Module):\n    dim: int\n    heads: int\n    mlp_dim: int\n    dropout: float\n\n    @nn.compact\n    def __call__(self, x, train: bool):\n        # Multi-head self-attention\n        residual = x\n        x = nn.LayerNorm()(x)\n        x = nn.SelfAttention(\n            num_heads=self.heads,\n            qkv_features=self.dim,\n            out_features=self.dim,\n            dropout_rate=self.dropout,\n            deterministic=not train,\n        )(x)\n        x = nn.Dropout(self.dropout)(x, deterministic=not train)\n        x = x + residual\n\n        # MLP\n        residual = x\n        x = nn.LayerNorm()(x)\n        x = MLP(dim=self.dim, mlp_dim=self.mlp_dim, dropout=self.dropout)(x, train)\n        x = x + residual\n        return x\n\nclass TransformerEncoder(nn.Module):\n    dim: int\n    depth: int\n    heads: int\n    mlp_dim: int\n    dropout: float\n\n    @nn.compact\n    def __call__(self, x, train: bool):\n        for _ in range(self.depth):\n            x = TransformerEncoderLayer(\n                dim=self.dim,\n                heads=self.heads,\n                mlp_dim=self.mlp_dim,\n                dropout=self.dropout\n            )(x, train)\n        return x\n\nclass Model(nn.Module):\n    image_size: int\n    patch_size: int\n    num_classes: int\n    dim: int\n    depth: int\n    heads: int\n    mlp_dim: int\n    channels: int = 3\n    dropout: float = 0.1\n    emb_dropout: float = 0.1\n\n    def setup(self):\n        assert self.image_size % self.patch_size == 0, \"Image dimensions must be divisible by the patch size.\"\n        self.num_patches = (self.image_size // self.patch_size) ** 2\n        self.patch_dim = self.channels * self.patch_size ** 2\n\n        self.patch_to_embedding = nn.Dense(self.dim)\n        self.pos_embedding = self.param(\n            'pos_embedding',\n            nn.initializers.normal(stddev=1.0),\n            (1, self.num_patches + 1, self.dim)\n        )\n        self.cls_token = self.param(\n            'cls_token',\n            nn.initializers.normal(stddev=1.0),\n            (1, 1, self.dim)\n        )\n        self.dropout_layer = nn.Dropout(self.emb_dropout)\n        self.transformer = TransformerEncoder(\n            dim=self.dim,\n            depth=self.depth,\n            heads=self.heads,\n            mlp_dim=self.mlp_dim,\n            dropout=self.dropout\n        )\n        self.mlp_head = nn.Sequential([\n            nn.Dense(self.mlp_dim),\n            nn.gelu,\n            nn.Dropout(self.dropout),\n            nn.Dense(self.num_classes)\n        ])\n\n    def __call__(self, img, train: bool = True):\n        # img: (batch, channels, image_size, image_size)\n        B = img.shape[0]\n        p = self.patch_size\n        # Convert to patches\n        # (B, C, H, W) -> (B, num_patches, patch_dim)\n        h = w = self.image_size\n        assert img.shape[2] == h and img.shape[3] == w\n        # Rearrange using jax.lax APIs\n        # Step 1: reshape to (B, C, h//p, p, w//p, p)\n        img = img.reshape(B, self.channels, h // p, p, w // p, p)\n        # Step 2: transpose to (B, h//p, w//p, C, p, p)\n        img = img.transpose(0, 2, 4, 1, 3, 5)\n        # Step 3: reshape to (B, num_patches, patch_dim)\n        img = img.reshape(B, self.num_patches, self.patch_dim)\n        x = self.patch_to_embedding(img)\n        # Add class token\n        cls_tokens = jnp.tile(self.cls_token, (B, 1, 1))\n        x = jnp.concatenate([cls_tokens, x], axis=1)\n        x = x + self.pos_embedding\n        x = self.dropout_layer(x, deterministic=not train)\n        x = self.transformer(x, train)\n        x = x[:, 0]  # take cls token\n        for layer in self.mlp_head:\n            if isinstance(layer, nn.Dropout):\n                x = layer(x, deterministic=not train)\n            elif callable(layer):\n                x = layer(x)\n            else:\n                x = layer(x)\n        return x\n\n# Test code\nimage_size = 224\npatch_size = 16\nnum_classes = 10\ndim = 512\ndepth = 6\nheads = 8\nmlp_dim = 2048\nchannels = 3\ndropout = 0.0\nemb_dropout = 0.0\n\ndef get_inputs():\n    # Return a list with a single input array of shape (2, channels, image_size, image_size)\n    rng = np.random.default_rng(0)\n    arr = rng.standard_normal((2, channels, image_size, image_size), dtype=np.float32)\n    return [jnp.array(arr)]\n\ndef get_init_inputs():\n    return [image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, channels, dropout, emb_dropout]"}
{"kb_id": "kb_level_3_0020", "level": "level_3", "prompt_tag": "gpt41_strict_full_v2", "aqs": 68.3922261484099, "success": true, "pytorch_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/pytorch_samples/kb_level_3_0020.py", "jax_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/jax_outputs/kb_level_3_0020_jax.py", "pytorch_code": "# --------------------------------------------------------\n# Swin Transformer\n# Copyright (c) 2021 Microsoft\n# Licensed under The MIT License [see LICENSE for details]\n# Written by Ze Liu\n# --------------------------------------------------------\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom itertools import repeat\nimport collections.abc\n\nclass Mlp(nn.Module):\n    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n        super().__init__()\n        out_features = out_features or in_features\n        hidden_features = hidden_features or in_features\n        self.fc1 = nn.Linear(in_features, hidden_features)\n        self.act = act_layer()\n        self.fc2 = nn.Linear(hidden_features, out_features)\n        self.drop = nn.Dropout(drop)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.act(x)\n        x = self.drop(x)\n        x = self.fc2(x)\n        x = self.drop(x)\n        return x\n\n\ndef window_partition(x, window_size):\n    \"\"\"\n    Args:\n        x: (B, H, W, C)\n        window_size (int): window size\n\n    Returns:\n        windows: (num_windows*B, window_size, window_size, C)\n    \"\"\"\n    B, H, W, C = x.shape\n    x = x.view(B, H // window_size, window_size, W // window_size, window_size, C)\n    windows = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(-1, window_size, window_size, C)\n    return windows\n\n\ndef window_reverse(windows, window_size, H, W):\n    \"\"\"\n    Args:\n        windows: (num_windows*B, window_size, window_size, C)\n        window_size (int): Window size\n        H (int): Height of image\n        W (int): Width of image\n\n    Returns:\n        x: (B, H, W, C)\n    \"\"\"\n    B = int(windows.shape[0] / (H * W / window_size / window_size))\n    x = windows.view(B, H // window_size, W // window_size, window_size, window_size, -1)\n    x = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(B, H, W, -1)\n    return x\n\n\nclass SwinMLPBlock(nn.Module):\n    r\"\"\" Swin MLP Block.\n\n    Args:\n        dim (int): Number of input channels.\n        input_resolution (tuple[int]): Input resulotion.\n        num_heads (int): Number of attention heads.\n        window_size (int): Window size.\n        shift_size (int): Shift size for SW-MSA.\n        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.\n        drop (float, optional): Dropout rate. Default: 0.0\n        drop_path (float, optional): Stochastic depth rate. Default: 0.0\n        act_layer (nn.Module, optional): Activation layer. Default: nn.GELU\n        norm_layer (nn.Module, optional): Normalization layer.  Default: nn.LayerNorm\n    \"\"\"\n\n    def __init__(self, dim, input_resolution, num_heads, window_size=7, shift_size=0,\n                 mlp_ratio=4., drop=0., drop_path=0.,\n                 act_layer=nn.GELU, norm_layer=nn.LayerNorm):\n        super().__init__()\n        self.dim = dim\n        self.input_resolution = input_resolution\n        self.num_heads = num_heads\n        self.window_size = window_size\n        self.shift_size = shift_size\n        self.mlp_ratio = mlp_ratio\n        if min(self.input_resolution) <= self.window_size:\n            # if window size is larger than input resolution, we don't partition windows\n            self.shift_size = 0\n            self.window_size = min(self.input_resolution)\n        assert 0 <= self.shift_size < self.window_size, \"shift_size must in 0-window_size\"\n\n        self.padding = [self.window_size - self.shift_size, self.shift_size,\n                        self.window_size - self.shift_size, self.shift_size]  # P_l,P_r,P_t,P_b\n\n        self.norm1 = norm_layer(dim)\n        # use group convolution to implement multi-head MLP\n        self.spatial_mlp = nn.Conv1d(self.num_heads * self.window_size ** 2,\n                                     self.num_heads * self.window_size ** 2,\n                                     kernel_size=1,\n                                     groups=self.num_heads)\n\n        self.drop_path = nn.Identity()\n        self.norm2 = norm_layer(dim)\n        mlp_hidden_dim = int(dim * mlp_ratio)\n        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n\n    def forward(self, x):\n        H, W = self.input_resolution\n        B, L, C = x.shape\n        assert L == H * W, \"input feature has wrong size\"\n\n        shortcut = x\n        x = self.norm1(x)\n        x = x.view(B, H, W, C)\n\n        # shift\n        if self.shift_size > 0:\n            P_l, P_r, P_t, P_b = self.padding\n            shifted_x = F.pad(x, [0, 0, P_l, P_r, P_t, P_b], \"constant\", 0)\n        else:\n            shifted_x = x\n        _, _H, _W, _ = shifted_x.shape\n\n        # partition windows\n        x_windows = window_partition(shifted_x, self.window_size)  # nW*B, window_size, window_size, C\n        x_windows = x_windows.view(-1, self.window_size * self.window_size, C)  # nW*B, window_size*window_size, C\n\n        # Window/Shifted-Window Spatial MLP\n        x_windows_heads = x_windows.view(-1, self.window_size * self.window_size, self.num_heads, C // self.num_heads)\n        x_windows_heads = x_windows_heads.transpose(1, 2)  # nW*B, nH, window_size*window_size, C//nH\n        x_windows_heads = x_windows_heads.reshape(-1, self.num_heads * self.window_size * self.window_size,\n                                                  C // self.num_heads)\n        spatial_mlp_windows = self.spatial_mlp(x_windows_heads)  # nW*B, nH*window_size*window_size, C//nH\n        spatial_mlp_windows = spatial_mlp_windows.view(-1, self.num_heads, self.window_size * self.window_size,\n                                                       C // self.num_heads).transpose(1, 2)\n        spatial_mlp_windows = spatial_mlp_windows.reshape(-1, self.window_size * self.window_size, C)\n\n        # merge windows\n        spatial_mlp_windows = spatial_mlp_windows.reshape(-1, self.window_size, self.window_size, C)\n        shifted_x = window_reverse(spatial_mlp_windows, self.window_size, _H, _W)  # B H' W' C\n\n        # reverse shift\n        if self.shift_size > 0:\n            P_l, P_r, P_t, P_b = self.padding\n            x = shifted_x[:, P_t:-P_b, P_l:-P_r, :].contiguous()\n        else:\n            x = shifted_x\n        x = x.view(B, H * W, C)\n\n        # FFN\n        x = shortcut + self.drop_path(x)\n        x = x + self.drop_path(self.mlp(self.norm2(x)))\n\n        return x\n\n\nclass PatchMerging(nn.Module):\n    r\"\"\" Patch Merging Layer.\n\n    Args:\n        input_resolution (tuple[int]): Resolution of input feature.\n        dim (int): Number of input channels.\n        norm_layer (nn.Module, optional): Normalization layer.  Default: nn.LayerNorm\n    \"\"\"\n\n    def __init__(self, input_resolution, dim, norm_layer=nn.LayerNorm):\n        super().__init__()\n        self.input_resolution = input_resolution\n        self.dim = dim\n        self.reduction = nn.Linear(4 * dim, 2 * dim, bias=False)\n        self.norm = norm_layer(4 * dim)\n\n    def forward(self, x):\n        \"\"\"\n        x: B, H*W, C\n        \"\"\"\n        H, W = self.input_resolution\n        B, L, C = x.shape\n        assert L == H * W, \"input feature has wrong size\"\n        assert H % 2 == 0 and W % 2 == 0, f\"x size ({H}*{W}) are not even.\"\n\n        x = x.view(B, H, W, C)\n\n        x0 = x[:, 0::2, 0::2, :]  # B H/2 W/2 C\n        x1 = x[:, 1::2, 0::2, :]  # B H/2 W/2 C\n        x2 = x[:, 0::2, 1::2, :]  # B H/2 W/2 C\n        x3 = x[:, 1::2, 1::2, :]  # B H/2 W/2 C\n        x = torch.cat([x0, x1, x2, x3], -1)  # B H/2 W/2 4*C\n        x = x.view(B, -1, 4 * C)  # B H/2*W/2 4*C\n\n        x = self.norm(x)\n        x = self.reduction(x)\n\n        return x\n\nclass BasicLayer(nn.Module):\n    \"\"\" A basic Swin MLP layer for one stage.\n\n    Args:\n        dim (int): Number of input channels.\n        input_resolution (tuple[int]): Input resolution.\n        depth (int): Number of blocks.\n        num_heads (int): Number of attention heads.\n        window_size (int): Local window size.\n        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.\n        drop (float, optional): Dropout rate. Default: 0.0\n        drop_path (float | tuple[float], optional): Stochastic depth rate. Default: 0.0\n        norm_layer (nn.Module, optional): Normalization layer. Default: nn.LayerNorm\n        downsample (nn.Module | None, optional): Downsample layer at the end of the layer. Default: None\n        use_checkpoint (bool): Whether to use checkpointing to save memory. Default: False.\n    \"\"\"\n\n    def __init__(self, dim, input_resolution, depth, num_heads, window_size,\n                 mlp_ratio=4., drop=0., drop_path=0.,\n                 norm_layer=nn.LayerNorm, downsample=None, use_checkpoint=False):\n\n        super().__init__()\n        self.dim = dim\n        self.input_resolution = input_resolution\n        self.depth = depth\n        self.use_checkpoint = use_checkpoint\n\n        # build blocks\n        self.blocks = nn.ModuleList([\n            SwinMLPBlock(dim=dim, input_resolution=input_resolution,\n                         num_heads=num_heads, window_size=window_size,\n                         shift_size=0 if (i % 2 == 0) else window_size // 2,\n                         mlp_ratio=mlp_ratio,\n                         drop=drop,\n                         drop_path=drop_path[i] if isinstance(drop_path, list) else drop_path,\n                         norm_layer=norm_layer)\n            for i in range(depth)])\n\n        # patch merging layer\n        if downsample is not None:\n            self.downsample = downsample(input_resolution, dim=dim, norm_layer=norm_layer)\n        else:\n            self.downsample = None\n\n    def forward(self, x):\n        for blk in self.blocks:\n            if self.use_checkpoint:\n                x = checkpoint.checkpoint(blk, x)\n            else:\n                x = blk(x)\n        if self.downsample is not None:\n            x = self.downsample(x)\n        return x\n\ndef _ntuple(n):\n    def parse(x):\n        if isinstance(x, collections.abc.Iterable) and not isinstance(x, str):\n            return tuple(x)\n        return tuple(repeat(x, n))\n    return parse\nto_2tuple = _ntuple(2)\n\nclass PatchEmbed(nn.Module):\n    r\"\"\" Image to Patch Embedding\n\n    Args:\n        img_size (int): Image size.  Default: 224.\n        patch_size (int): Patch token size. Default: 4.\n        in_chans (int): Number of input image channels. Default: 3.\n        embed_dim (int): Number of linear projection output channels. Default: 96.\n        norm_layer (nn.Module, optional): Normalization layer. Default: None\n    \"\"\"\n\n    def __init__(self, img_size=224, patch_size=4, in_chans=3, embed_dim=96, norm_layer=None):\n        super().__init__()\n        img_size = to_2tuple(img_size)\n        patch_size = to_2tuple(patch_size)\n        patches_resolution = [img_size[0] // patch_size[0], img_size[1] // patch_size[1]]\n        self.img_size = img_size\n        self.patch_size = patch_size\n        self.patches_resolution = patches_resolution\n        self.num_patches = patches_resolution[0] * patches_resolution[1]\n\n        self.in_chans = in_chans\n        self.embed_dim = embed_dim\n\n        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n        if norm_layer is not None:\n            self.norm = norm_layer(embed_dim)\n        else:\n            self.norm = None\n\n    def forward(self, x):\n        B, C, H, W = x.shape\n        # FIXME look at relaxing size constraints\n        assert H == self.img_size[0] and W == self.img_size[1], \\\n            f\"Input image size ({H}*{W}) doesn't match model ({self.img_size[0]}*{self.img_size[1]}).\"\n        x = self.proj(x).flatten(2).transpose(1, 2)  # B Ph*Pw C\n        if self.norm is not None:\n            x = self.norm(x)\n        return x\n\n    def flops(self):\n        Ho, Wo = self.patches_resolution\n        flops = Ho * Wo * self.embed_dim * self.in_chans * (self.patch_size[0] * self.patch_size[1])\n        if self.norm is not None:\n            flops += Ho * Wo * self.embed_dim\n        return flops\n\n\nclass Model(nn.Module):\n    r\"\"\" Swin MLP\n\n    Args:\n        img_size (int | tuple(int)): Input image size. Default 224\n        patch_size (int | tuple(int)): Patch size. Default: 4\n        in_chans (int): Number of input image channels. Default: 3\n        num_classes (int): Number of classes for classification head. Default: 1000\n        embed_dim (int): Patch embedding dimension. Default: 96\n        depths (tuple(int)): Depth of each Swin MLP layer.\n        num_heads (tuple(int)): Number of attention heads in different layers.\n        window_size (int): Window size. Default: 7\n        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim. Default: 4\n        drop_rate (float): Dropout rate. Default: 0\n        drop_path_rate (float): Stochastic depth rate. Default: 0.1\n        norm_layer (nn.Module): Normalization layer. Default: nn.LayerNorm.\n        patch_norm (bool): If True, add normalization after patch embedding. Default: True\n        use_checkpoint (bool): Whether to use checkpointing to save memory. Default: False\n    \"\"\"\n\n    def __init__(self, img_size=224, patch_size=4, in_chans=3, num_classes=1000,\n                 embed_dim=96, depths=[2, 2, 6, 2], num_heads=[3, 6, 12, 24],\n                 window_size=7, mlp_ratio=4., drop_rate=0., drop_path_rate=0.1,\n                 norm_layer=nn.LayerNorm, patch_norm=True,\n                 use_checkpoint=False, **kwargs):\n        super().__init__()\n\n        self.num_classes = num_classes\n        self.num_layers = len(depths)\n        self.embed_dim = embed_dim\n        self.patch_norm = patch_norm\n        self.num_features = int(embed_dim * 2 ** (self.num_layers - 1))\n        self.mlp_ratio = mlp_ratio\n\n        # split image into non-overlapping patches\n        self.patch_embed = PatchEmbed(\n            img_size=img_size, patch_size=patch_size, in_chans=in_chans, embed_dim=embed_dim,\n            norm_layer=norm_layer if self.patch_norm else None)\n        num_patches = self.patch_embed.num_patches\n        patches_resolution = self.patch_embed.patches_resolution\n        self.patches_resolution = patches_resolution\n\n        self.pos_drop = nn.Dropout(p=drop_rate)\n\n        # stochastic depth\n        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))]  # stochastic depth decay rule\n\n        # build layers\n        self.layers = nn.ModuleList()\n        for i_layer in range(self.num_layers):\n            layer = BasicLayer(dim=int(embed_dim * 2 ** i_layer),\n                               input_resolution=(patches_resolution[0] // (2 ** i_layer),\n                                                 patches_resolution[1] // (2 ** i_layer)),\n                               depth=depths[i_layer],\n                               num_heads=num_heads[i_layer],\n                               window_size=window_size,\n                               mlp_ratio=self.mlp_ratio,\n                               drop=drop_rate,\n                               drop_path=dpr[sum(depths[:i_layer]):sum(depths[:i_layer + 1])],\n                               norm_layer=norm_layer,\n                               downsample=PatchMerging if (i_layer < self.num_layers - 1) else None,\n                               use_checkpoint=use_checkpoint)\n            self.layers.append(layer)\n\n        self.norm = norm_layer(self.num_features)\n        self.avgpool = nn.AdaptiveAvgPool1d(1)\n        self.head = nn.Linear(self.num_features, num_classes) if num_classes > 0 else nn.Identity()\n\n    def forward_features(self, x):\n        x = self.patch_embed(x)\n        x = self.pos_drop(x)\n\n        for layer in self.layers:\n            x = layer(x)\n\n        x = self.norm(x)  # B L C\n        x = self.avgpool(x.transpose(1, 2))  # B C 1\n        x = torch.flatten(x, 1)\n        return x\n\n    def forward(self, x):\n        x = self.forward_features(x)\n        x = self.head(x)\n        return x\n    \nbatch_size = 10\nimage_size = 224\n\ndef get_inputs():\n    return [torch.rand(batch_size, 3, image_size, image_size)]\n\ndef get_init_inputs():\n    return []", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\nimport numpy as np\nfrom functools import partial\nfrom itertools import repeat\nimport collections.abc\n\ndef _ntuple(n):\n    def parse(x):\n        if isinstance(x, collections.abc.Iterable) and not isinstance(x, str):\n            return tuple(x)\n        return tuple(repeat(x, n))\n    return parse\nto_2tuple = _ntuple(2)\n\nclass Mlp(nn.Module):\n    in_features: int\n    hidden_features: int = None\n    out_features: int = None\n    act_layer: callable = nn.gelu\n    drop: float = 0.\n\n    @nn.compact\n    def __call__(self, x, deterministic=True):\n        out_features = self.out_features or self.in_features\n        hidden_features = self.hidden_features or self.in_features\n        x = nn.Dense(hidden_features)(x)\n        x = self.act_layer(x)\n        x = nn.Dropout(self.drop)(x, deterministic=deterministic)\n        x = nn.Dense(out_features)(x)\n        x = nn.Dropout(self.drop)(x, deterministic=deterministic)\n        return x\n\ndef window_partition(x, window_size):\n    \"\"\"\n    Args:\n        x: (B, H, W, C)\n        window_size (int): window size\n\n    Returns:\n        windows: (num_windows*B, window_size, window_size, C)\n    \"\"\"\n    B, H, W, C = x.shape\n    x = x.reshape(B, H // window_size, window_size, W // window_size, window_size, C)\n    x = jnp.transpose(x, (0, 1, 3, 2, 4, 5))\n    windows = x.reshape(-1, window_size, window_size, C)\n    return windows\n\ndef window_reverse(windows, window_size, H, W):\n    \"\"\"\n    Args:\n        windows: (num_windows*B, window_size, window_size, C)\n        window_size (int): Window size\n        H (int): Height of image\n        W (int): Width of image\n\n    Returns:\n        x: (B, H, W, C)\n    \"\"\"\n    B = int(windows.shape[0] // (H * W // window_size // window_size))\n    x = windows.reshape(B, H // window_size, W // window_size, window_size, window_size, -1)\n    x = jnp.transpose(x, (0, 1, 3, 2, 4, 5))\n    x = x.reshape(B, H, W, -1)\n    return x\n\nclass SwinMLPBlock(nn.Module):\n    dim: int\n    input_resolution: tuple\n    num_heads: int\n    window_size: int = 7\n    shift_size: int = 0\n    mlp_ratio: float = 4.\n    drop: float = 0.\n    drop_path: float = 0.\n    act_layer: callable = nn.gelu\n    norm_layer: callable = nn.LayerNorm\n\n    @nn.compact\n    def __call__(self, x, deterministic=True):\n        H, W = self.input_resolution\n        B, L, C = x.shape\n        assert L == H * W, \"input feature has wrong size\"\n\n        shortcut = x\n        x = self.norm_layer()(x)\n        x = x.reshape(B, H, W, C)\n\n        # window/shift logic\n        window_size = self.window_size\n        shift_size = self.shift_size\n        if min(self.input_resolution) <= window_size:\n            shift_size = 0\n            window_size = min(self.input_resolution)\n        assert 0 <= shift_size < window_size, \"shift_size must in 0-window_size\"\n\n        padding = [window_size - shift_size, shift_size,\n                   window_size - shift_size, shift_size]  # P_l,P_r,P_t,P_b\n\n        # shift\n        if shift_size > 0:\n            P_l, P_r, P_t, P_b = padding\n            # pad order: ((before_H, after_H), (before_W, after_W))\n            x = jnp.pad(x, ((0,0), (P_t, P_b), (P_l, P_r), (0,0)), mode='constant')\n        _B, _H, _W, _C = x.shape\n\n        # partition windows\n        x_windows = window_partition(x, window_size)  # nW*B, window_size, window_size, C\n        x_windows = x_windows.reshape(-1, window_size * window_size, C)  # nW*B, window_size*window_size, C\n\n        # Window/Shifted-Window Spatial MLP\n        nH = self.num_heads\n        x_windows_heads = x_windows.reshape(-1, window_size * window_size, nH, C // nH)\n        x_windows_heads = jnp.transpose(x_windows_heads, (0, 2, 1, 3))  # nW*B, nH, window_size*window_size, C//nH\n        x_windows_heads = x_windows_heads.reshape(-1, nH * window_size * window_size, C // nH)\n\n        # Grouped Conv1D: implement as DenseGeneral with axis splitting\n        # (batch, length, features) -> (batch, length, features)\n        # groups = nH, features = C//nH\n        def grouped_dense(x, features, groups, name=None):\n            # x: (batch, length, features)\n            in_features = x.shape[-1]\n            assert in_features * groups == features\n            x = x.reshape(x.shape[0], x.shape[1] * groups, in_features // groups)\n            x = nn.DenseGeneral(features=(features//groups,), axis=-1, name=name)(x)\n            x = x.reshape(x.shape[0], features)\n            return x\n\n        # Instead, use Conv1D with groups\n        spatial_mlp = nn.Conv(features=nH * window_size * window_size,\n                              kernel_size=(1,),\n                              feature_group_count=nH,\n                              name='spatial_mlp')\n        # But Flax Conv expects (batch, length, channels)\n        # So swap axes\n        x_windows_heads = jnp.transpose(x_windows_heads, (0,2,1))  # (batch, features, length)\n        spatial_mlp_windows = spatial_mlp(x_windows_heads)\n        spatial_mlp_windows = jnp.transpose(spatial_mlp_windows, (0,2,1))  # (batch, length, features)\n        spatial_mlp_windows = spatial_mlp_windows.reshape(-1, nH, window_size * window_size, C // nH)\n        spatial_mlp_windows = jnp.transpose(spatial_mlp_windows, (0,2,1,3))\n        spatial_mlp_windows = spatial_mlp_windows.reshape(-1, window_size * window_size, C)\n\n        # merge windows\n        spatial_mlp_windows = spatial_mlp_windows.reshape(-1, window_size, window_size, C)\n        x = window_reverse(spatial_mlp_windows, window_size, _H, _W)  # B H' W' C\n\n        # reverse shift\n        if shift_size > 0:\n            P_l, P_r, P_t, P_b = padding\n            x = x[:, P_t:_H-P_b, P_l:_W-P_r, :]\n        x = x.reshape(B, H * W, C)\n\n        # FFN\n        x = shortcut + x\n        x = x + Mlp(self.dim, int(self.dim * self.mlp_ratio), act_layer=self.act_layer, drop=self.drop)(self.norm_layer()(x), deterministic=deterministic)\n        return x\n\nclass PatchMerging(nn.Module):\n    input_resolution: tuple\n    dim: int\n    norm_layer: callable = nn.LayerNorm\n\n    @nn.compact\n    def __call__(self, x):\n        H, W = self.input_resolution\n        B, L, C = x.shape\n        assert L == H * W, \"input feature has wrong size\"\n        assert H % 2 == 0 and W % 2 == 0, f\"x size ({H}*{W}) are not even.\"\n\n        x = x.reshape(B, H, W, C)\n        x0 = x[:, 0::2, 0::2, :]  # B H/2 W/2 C\n        x1 = x[:, 1::2, 0::2, :]  # B H/2 W/2 C\n        x2 = x[:, 0::2, 1::2, :]  # B H/2 W/2 C\n        x3 = x[:, 1::2, 1::2, :]  # B H/2 W/2 C\n        x = jnp.concatenate([x0, x1, x2, x3], axis=-1)  # B H/2 W/2 4*C\n        x = x.reshape(B, -1, 4 * C)  # B H/2*W/2 4*C\n\n        x = self.norm_layer()(x)\n        x = nn.Dense(2 * C, use_bias=False)(x)\n        return x\n\nclass BasicLayer(nn.Module):\n    dim: int\n    input_resolution: tuple\n    depth: int\n    num_heads: int\n    window_size: int\n    mlp_ratio: float = 4.\n    drop: float = 0.\n    drop_path: float = 0.\n    norm_layer: callable = nn.LayerNorm\n    downsample: callable = None\n    use_checkpoint: bool = False\n\n    @nn.compact\n    def __call__(self, x, deterministic=True):\n        for i in range(self.depth):\n            x = SwinMLPBlock(\n                dim=self.dim,\n                input_resolution=self.input_resolution,\n                num_heads=self.num_heads,\n                window_size=self.window_size,\n                shift_size=0 if (i % 2 == 0) else self.window_size // 2,\n                mlp_ratio=self.mlp_ratio,\n                drop=self.drop,\n                drop_path=self.drop_path if not isinstance(self.drop_path, (list, tuple)) else self.drop_path[i],\n                norm_layer=self.norm_layer\n            )(x, deterministic=deterministic)\n        if self.downsample is not None:\n            x = self.downsample(self.input_resolution, dim=self.dim, norm_layer=self.norm_layer)(x)\n        return x\n\nclass PatchEmbed(nn.Module):\n    img_size: int = 224\n    patch_size: int = 4\n    in_chans: int = 3\n    embed_dim: int = 96\n    norm_layer: callable = None\n\n    def setup(self):\n        img_size = to_2tuple(self.img_size)\n        patch_size = to_2tuple(self.patch_size)\n        patches_resolution = [img_size[0] // patch_size[0], img_size[1] // patch_size[1]]\n        self.img_size = img_size\n        self.patch_size = patch_size\n        self.patches_resolution = patches_resolution\n        self.num_patches = patches_resolution[0] * patches_resolution[1]\n        self.proj = nn.Conv(self.embed_dim, kernel_size=self.patch_size, strides=self.patch_size)\n        if self.norm_layer is not None:\n            self.norm = self.norm_layer()\n        else:\n            self.norm = None\n\n    def __call__(self, x):\n        B, C, H, W = x.shape\n        assert H == self.img_size[0] and W == self.img_size[1], \\\n            f\"Input image size ({H}*{W}) doesn't match model ({self.img_size[0]}*{self.img_size[1]}).\"\n        x = jnp.transpose(x, (0,2,3,1))  # (B, H, W, C)\n        x = self.proj(x)  # (B, H', W', embed_dim)\n        x = x.reshape(B, -1, self.embed_dim)  # (B, Ph*Pw, C)\n        if self.norm is not None:\n            x = self.norm(x)\n        return x\n\n    def flops(self):\n        Ho, Wo = self.patches_resolution\n        flops = Ho * Wo * self.embed_dim * self.in_chans * (self.patch_size[0] * self.patch_size[1])\n        if self.norm is not None:\n            flops += Ho * Wo * self.embed_dim\n        return flops\n\nclass Model(nn.Module):\n    img_size: int = 224\n    patch_size: int = 4\n    in_chans: int = 3\n    num_classes: int = 1000\n    embed_dim: int = 96\n    depths: list = (2, 2, 6, 2)\n    num_heads: list = (3, 6, 12, 24)\n    window_size: int = 7\n    mlp_ratio: float = 4.\n    drop_rate: float = 0.\n    drop_path_rate: float = 0.1\n    norm_layer: callable = nn.LayerNorm\n    patch_norm: bool = True\n    use_checkpoint: bool = False\n\n    def setup(self):\n        self.num_layers = len(self.depths)\n        self.num_features = int(self.embed_dim * 2 ** (self.num_layers - 1))\n        self.mlp_ratio = self.mlp_ratio\n\n        self.patch_embed = PatchEmbed(\n            img_size=self.img_size, patch_size=self.patch_size, in_chans=self.in_chans, embed_dim=self.embed_dim,\n            norm_layer=self.norm_layer if self.patch_norm else None)\n        num_patches = self.patch_embed.num_patches\n        patches_resolution = self.patch_embed.patches_resolution\n        self.patches_resolution = patches_resolution\n\n        self.pos_drop = nn.Dropout(self.drop_rate)\n\n        # stochastic depth\n        dpr = np.linspace(0, self.drop_path_rate, sum(self.depths)).tolist()\n\n        # build layers\n        self.layers = []\n        for i_layer in range(self.num_layers):\n            downsample = PatchMerging if (i_layer < self.num_layers - 1) else None\n            layer = BasicLayer(\n                dim=int(self.embed_dim * 2 ** i_layer),\n                input_resolution=(patches_resolution[0] // (2 ** i_layer),\n                                  patches_resolution[1] // (2 ** i_layer)),\n                depth=self.depths[i_layer],\n                num_heads=self.num_heads[i_layer],\n                window_size=self.window_size,\n                mlp_ratio=self.mlp_ratio,\n                drop=self.drop_rate,\n                drop_path=dpr[sum(self.depths[:i_layer]):sum(self.depths[:i_layer + 1])],\n                norm_layer=self.norm_layer,\n                downsample=downsample,\n                use_checkpoint=self.use_checkpoint\n            )\n            self.layers.append(layer)\n        self.layers = self.layers\n\n        self.norm = self.norm_layer()\n        self.head = nn.Dense(self.num_classes) if self.num_classes > 0 else lambda x: x\n\n    def __call__(self, x, deterministic=True):\n        x = self.patch_embed(x)\n        x = self.pos_drop(x, deterministic=deterministic)\n        for layer in self.layers:\n            x = layer(x, deterministic=deterministic)\n        x = self.norm(x)  # B L C\n        x = jnp.mean(x, axis=1)  # global average pooling over sequence\n        x = self.head(x)\n        return x\n\nbatch_size = 10\nimage_size = 224\n\ndef get_inputs():\n    return [jnp.array(np.random.rand(batch_size, 3, image_size, image_size), dtype=jnp.float32)]\n\ndef get_init_inputs():\n    return []"}
{"kb_id": "kb_level_3_0021", "level": "level_3", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.37275985663082, "success": true, "pytorch_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/pytorch_samples/kb_level_3_0021.py", "jax_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/jax_outputs/kb_level_3_0021_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, input_size, hidden_layer_sizes, output_size):\n        \"\"\"\n        :param input_size: The number of input features\n        :param hidden_layer_sizes: A list of ints containing the sizes of each hidden layer\n        :param output_size: The number of output features\n        \"\"\"\n        super(Model, self).__init__()\n        \n        layers = []\n        current_input_size = input_size\n        \n        for hidden_size in hidden_layer_sizes:\n            layers.append(nn.Linear(current_input_size, hidden_size))\n            layers.append(nn.ReLU())\n            current_input_size = hidden_size\n        \n        layers.append(nn.Linear(current_input_size, output_size))\n        \n        self.network = nn.Sequential(*layers)\n    \n    def forward(self, x):\n        \"\"\"\n        :param x: The input tensor, shape (batch_size, input_size)\n        :return: The output tensor, shape (batch_size, output_size)\n        \"\"\"\n        return self.network(x)\n\n# Test code\nbatch_size = 128\ninput_size = 16384\nhidden_layer_sizes = [32768, 32768]\noutput_size = 16384\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_layer_sizes, output_size]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    input_size: int\n    hidden_layer_sizes: list\n    output_size: int\n\n    @nn.compact\n    def __call__(self, x):\n        current_input_size = self.input_size\n        for hidden_size in self.hidden_layer_sizes:\n            x = nn.Dense(hidden_size)(x)\n            x = nn.relu(x)\n            current_input_size = hidden_size\n        x = nn.Dense(self.output_size)(x)\n        return x\n\n# Test code\nbatch_size = 128\ninput_size = 16384\nhidden_layer_sizes = [32768, 32768]\noutput_size = 16384\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_layer_sizes, output_size]"}
{"kb_id": "kb_level_3_0022", "level": "level_3", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.24865831842575, "success": true, "pytorch_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/pytorch_samples/kb_level_3_0022.py", "jax_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/jax_outputs/kb_level_3_0022_jax.py", "pytorch_code": "# --------------------------------------------------------\n# Swin Transformer V2\n# Copyright (c) 2022 Microsoft\n# Licensed under The MIT License [see LICENSE for details]\n# Written by Ze Liu\n# --------------------------------------------------------\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nimport collections\nfrom itertools import repeat\n\ndef _ntuple(n):\n    def parse(x):\n        if isinstance(x, collections.abc.Iterable) and not isinstance(x, str):\n            return tuple(x)\n        return tuple(repeat(x, n))\n    return parse\nto_2tuple = _ntuple(2)\n\nclass Mlp(nn.Module):\n    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n        super().__init__()\n        out_features = out_features or in_features\n        hidden_features = hidden_features or in_features\n        self.fc1 = nn.Linear(in_features, hidden_features)\n        self.act = act_layer()\n        self.fc2 = nn.Linear(hidden_features, out_features)\n        self.drop = nn.Dropout(drop)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.act(x)\n        x = self.drop(x)\n        x = self.fc2(x)\n        x = self.drop(x)\n        return x\n\n\ndef window_partition(x, window_size):\n    \"\"\"\n    Args:\n        x: (B, H, W, C)\n        window_size (int): window size\n\n    Returns:\n        windows: (num_windows*B, window_size, window_size, C)\n    \"\"\"\n    B, H, W, C = x.shape\n    x = x.view(B, H // window_size, window_size, W // window_size, window_size, C)\n    windows = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(-1, window_size, window_size, C)\n    return windows\n\n\ndef window_reverse(windows, window_size, H, W):\n    \"\"\"\n    Args:\n        windows: (num_windows*B, window_size, window_size, C)\n        window_size (int): Window size\n        H (int): Height of image\n        W (int): Width of image\n\n    Returns:\n        x: (B, H, W, C)\n    \"\"\"\n    B = int(windows.shape[0] / (H * W / window_size / window_size))\n    x = windows.view(B, H // window_size, W // window_size, window_size, window_size, -1)\n    x = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(B, H, W, -1)\n    return x\n\n\nclass WindowAttention(nn.Module):\n    r\"\"\" Window based multi-head self attention (W-MSA) module with relative position bias.\n    It supports both of shifted and non-shifted window.\n\n    Args:\n        dim (int): Number of input channels.\n        window_size (tuple[int]): The height and width of the window.\n        num_heads (int): Number of attention heads.\n        qkv_bias (bool, optional):  If True, add a learnable bias to query, key, value. Default: True\n        attn_drop (float, optional): Dropout ratio of attention weight. Default: 0.0\n        proj_drop (float, optional): Dropout ratio of output. Default: 0.0\n        pretrained_window_size (tuple[int]): The height and width of the window in pre-training.\n    \"\"\"\n\n    def __init__(self, dim, window_size, num_heads, qkv_bias=True, attn_drop=0., proj_drop=0.,\n                 pretrained_window_size=[0, 0]):\n\n        super().__init__()\n        self.dim = dim\n        self.window_size = window_size  # Wh, Ww\n        self.pretrained_window_size = pretrained_window_size\n        self.num_heads = num_heads\n\n        self.logit_scale = nn.Parameter(torch.log(10 * torch.ones((num_heads, 1, 1))), requires_grad=True)\n\n        # mlp to generate continuous relative position bias\n        self.cpb_mlp = nn.Sequential(nn.Linear(2, 512, bias=True),\n                                     nn.ReLU(inplace=True),\n                                     nn.Linear(512, num_heads, bias=False))\n\n        # get relative_coords_table\n        relative_coords_h = torch.arange(-(self.window_size[0] - 1), self.window_size[0], dtype=torch.float32)\n        relative_coords_w = torch.arange(-(self.window_size[1] - 1), self.window_size[1], dtype=torch.float32)\n        relative_coords_table = torch.stack(\n            torch.meshgrid([relative_coords_h,\n                            relative_coords_w])).permute(1, 2, 0).contiguous().unsqueeze(0)  # 1, 2*Wh-1, 2*Ww-1, 2\n        if pretrained_window_size[0] > 0:\n            relative_coords_table[:, :, :, 0] /= (pretrained_window_size[0] - 1)\n            relative_coords_table[:, :, :, 1] /= (pretrained_window_size[1] - 1)\n        else:\n            relative_coords_table[:, :, :, 0] /= (self.window_size[0] - 1)\n            relative_coords_table[:, :, :, 1] /= (self.window_size[1] - 1)\n        relative_coords_table *= 8  # normalize to -8, 8\n        relative_coords_table = torch.sign(relative_coords_table) * torch.log2(\n            torch.abs(relative_coords_table) + 1.0) / np.log2(8)\n\n        self.register_buffer(\"relative_coords_table\", relative_coords_table)\n\n        # get pair-wise relative position index for each token inside the window\n        coords_h = torch.arange(self.window_size[0])\n        coords_w = torch.arange(self.window_size[1])\n        coords = torch.stack(torch.meshgrid([coords_h, coords_w]))  # 2, Wh, Ww\n        coords_flatten = torch.flatten(coords, 1)  # 2, Wh*Ww\n        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]  # 2, Wh*Ww, Wh*Ww\n        relative_coords = relative_coords.permute(1, 2, 0).contiguous()  # Wh*Ww, Wh*Ww, 2\n        relative_coords[:, :, 0] += self.window_size[0] - 1  # shift to start from 0\n        relative_coords[:, :, 1] += self.window_size[1] - 1\n        relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1\n        relative_position_index = relative_coords.sum(-1)  # Wh*Ww, Wh*Ww\n        self.register_buffer(\"relative_position_index\", relative_position_index)\n\n        self.qkv = nn.Linear(dim, dim * 3, bias=False)\n        if qkv_bias:\n            self.q_bias = nn.Parameter(torch.zeros(dim))\n            self.v_bias = nn.Parameter(torch.zeros(dim))\n        else:\n            self.q_bias = None\n            self.v_bias = None\n        self.attn_drop = nn.Dropout(attn_drop)\n        self.proj = nn.Linear(dim, dim)\n        self.proj_drop = nn.Dropout(proj_drop)\n        self.softmax = nn.Softmax(dim=-1)\n\n    def forward(self, x, mask=None):\n        \"\"\"\n        Args:\n            x: input features with shape of (num_windows*B, N, C)\n            mask: (0/-inf) mask with shape of (num_windows, Wh*Ww, Wh*Ww) or None\n        \"\"\"\n        B_, N, C = x.shape\n        qkv_bias = None\n        if self.q_bias is not None:\n            qkv_bias = torch.cat((self.q_bias, torch.zeros_like(self.v_bias, requires_grad=False), self.v_bias))\n        qkv = F.linear(input=x, weight=self.qkv.weight, bias=qkv_bias)\n        qkv = qkv.reshape(B_, N, 3, self.num_heads, -1).permute(2, 0, 3, 1, 4)\n        q, k, v = qkv[0], qkv[1], qkv[2]  # make torchscript happy (cannot use tensor as tuple)\n\n        # cosine attention\n        attn = (F.normalize(q, dim=-1) @ F.normalize(k, dim=-1).transpose(-2, -1))\n        logit_scale = torch.clamp(self.logit_scale.to(x.device), max=torch.log(torch.tensor(1. / 0.01, device=x.device))).exp()\n        attn = attn * logit_scale\n\n        relative_position_bias_table = self.cpb_mlp(self.relative_coords_table).view(-1, self.num_heads)\n        relative_position_bias = relative_position_bias_table[self.relative_position_index.view(-1)].view(\n            self.window_size[0] * self.window_size[1], self.window_size[0] * self.window_size[1], -1)  # Wh*Ww,Wh*Ww,nH\n        relative_position_bias = relative_position_bias.permute(2, 0, 1).contiguous()  # nH, Wh*Ww, Wh*Ww\n        relative_position_bias = 16 * torch.sigmoid(relative_position_bias)\n        attn = attn + relative_position_bias.unsqueeze(0)\n\n        if mask is not None:\n            nW = mask.shape[0]\n            attn = attn.view(B_ // nW, nW, self.num_heads, N, N) + mask.unsqueeze(1).unsqueeze(0)\n            attn = attn.view(-1, self.num_heads, N, N)\n            attn = self.softmax(attn)\n        else:\n            attn = self.softmax(attn)\n\n        attn = self.attn_drop(attn)\n\n        x = (attn @ v).transpose(1, 2).reshape(B_, N, C)\n        x = self.proj(x)\n        x = self.proj_drop(x)\n        return x\n\nclass SwinTransformerBlock(nn.Module):\n    r\"\"\" Swin Transformer Block.\n\n    Args:\n        dim (int): Number of input channels.\n        input_resolution (tuple[int]): Input resulotion.\n        num_heads (int): Number of attention heads.\n        window_size (int): Window size.\n        shift_size (int): Shift size for SW-MSA.\n        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.\n        qkv_bias (bool, optional): If True, add a learnable bias to query, key, value. Default: True\n        drop (float, optional): Dropout rate. Default: 0.0\n        attn_drop (float, optional): Attention dropout rate. Default: 0.0\n        drop_path (float, optional): Stochastic depth rate. Default: 0.0\n        act_layer (nn.Module, optional): Activation layer. Default: nn.GELU\n        norm_layer (nn.Module, optional): Normalization layer.  Default: nn.LayerNorm\n        pretrained_window_size (int): Window size in pre-training.\n    \"\"\"\n\n    def __init__(self, dim, input_resolution, num_heads, window_size=7, shift_size=0,\n                 mlp_ratio=4., qkv_bias=True, drop=0., attn_drop=0., drop_path=0.,\n                 act_layer=nn.GELU, norm_layer=nn.LayerNorm, pretrained_window_size=0):\n        super().__init__()\n        self.dim = dim\n        self.input_resolution = input_resolution\n        self.num_heads = num_heads\n        self.window_size = window_size\n        self.shift_size = shift_size\n        self.mlp_ratio = mlp_ratio\n        if min(self.input_resolution) <= self.window_size:\n            # if window size is larger than input resolution, we don't partition windows\n            self.shift_size = 0\n            self.window_size = min(self.input_resolution)\n        assert 0 <= self.shift_size < self.window_size, \"shift_size must in 0-window_size\"\n\n        self.norm1 = norm_layer(dim)\n        self.attn = WindowAttention(\n            dim, window_size=to_2tuple(self.window_size), num_heads=num_heads,\n            qkv_bias=qkv_bias, attn_drop=attn_drop, proj_drop=drop,\n            pretrained_window_size=to_2tuple(pretrained_window_size))\n\n        self.drop_path = nn.Identity()\n        self.norm2 = norm_layer(dim)\n        mlp_hidden_dim = int(dim * mlp_ratio)\n        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n\n        if self.shift_size > 0:\n            # calculate attention mask for SW-MSA\n            H, W = self.input_resolution\n            img_mask = torch.zeros((1, H, W, 1))  # 1 H W 1\n            h_slices = (slice(0, -self.window_size),\n                        slice(-self.window_size, -self.shift_size),\n                        slice(-self.shift_size, None))\n            w_slices = (slice(0, -self.window_size),\n                        slice(-self.window_size, -self.shift_size),\n                        slice(-self.shift_size, None))\n            cnt = 0\n            for h in h_slices:\n                for w in w_slices:\n                    img_mask[:, h, w, :] = cnt\n                    cnt += 1\n\n            mask_windows = window_partition(img_mask, self.window_size)  # nW, window_size, window_size, 1\n            mask_windows = mask_windows.view(-1, self.window_size * self.window_size)\n            attn_mask = mask_windows.unsqueeze(1) - mask_windows.unsqueeze(2)\n            attn_mask = attn_mask.masked_fill(attn_mask != 0, float(-100.0)).masked_fill(attn_mask == 0, float(0.0))\n        else:\n            attn_mask = None\n\n        self.register_buffer(\"attn_mask\", attn_mask)\n\n    def forward(self, x):\n        H, W = self.input_resolution\n        B, L, C = x.shape\n        assert L == H * W, \"input feature has wrong size\"\n\n        shortcut = x\n        x = x.view(B, H, W, C)\n\n        # cyclic shift\n        if self.shift_size > 0:\n            shifted_x = torch.roll(x, shifts=(-self.shift_size, -self.shift_size), dims=(1, 2))\n        else:\n            shifted_x = x\n\n        # partition windows\n        x_windows = window_partition(shifted_x, self.window_size)  # nW*B, window_size, window_size, C\n        x_windows = x_windows.view(-1, self.window_size * self.window_size, C)  # nW*B, window_size*window_size, C\n\n        # W-MSA/SW-MSA\n        attn_windows = self.attn(x_windows, mask=self.attn_mask)  # nW*B, window_size*window_size, C\n\n        # merge windows\n        attn_windows = attn_windows.view(-1, self.window_size, self.window_size, C)\n        shifted_x = window_reverse(attn_windows, self.window_size, H, W)  # B H' W' C\n\n        # reverse cyclic shift\n        if self.shift_size > 0:\n            x = torch.roll(shifted_x, shifts=(self.shift_size, self.shift_size), dims=(1, 2))\n        else:\n            x = shifted_x\n        x = x.view(B, H * W, C)\n        x = shortcut + self.drop_path(self.norm1(x))\n\n        # FFN\n        x = x + self.drop_path(self.norm2(self.mlp(x)))\n\n        return x\n\n\nclass PatchMerging(nn.Module):\n    r\"\"\" Patch Merging Layer.\n\n    Args:\n        input_resolution (tuple[int]): Resolution of input feature.\n        dim (int): Number of input channels.\n        norm_layer (nn.Module, optional): Normalization layer.  Default: nn.LayerNorm\n    \"\"\"\n\n    def __init__(self, input_resolution, dim, norm_layer=nn.LayerNorm):\n        super().__init__()\n        self.input_resolution = input_resolution\n        self.dim = dim\n        self.reduction = nn.Linear(4 * dim, 2 * dim, bias=False)\n        self.norm = norm_layer(2 * dim)\n\n    def forward(self, x):\n        \"\"\"\n        x: B, H*W, C\n        \"\"\"\n        H, W = self.input_resolution\n        B, L, C = x.shape\n        assert L == H * W, \"input feature has wrong size\"\n        assert H % 2 == 0 and W % 2 == 0, f\"x size ({H}*{W}) are not even.\"\n\n        x = x.view(B, H, W, C)\n\n        x0 = x[:, 0::2, 0::2, :]  # B H/2 W/2 C\n        x1 = x[:, 1::2, 0::2, :]  # B H/2 W/2 C\n        x2 = x[:, 0::2, 1::2, :]  # B H/2 W/2 C\n        x3 = x[:, 1::2, 1::2, :]  # B H/2 W/2 C\n        x = torch.cat([x0, x1, x2, x3], -1)  # B H/2 W/2 4*C\n        x = x.view(B, -1, 4 * C)  # B H/2*W/2 4*C\n\n        x = self.reduction(x)\n        x = self.norm(x)\n\n        return x\n\nclass BasicLayer(nn.Module):\n    \"\"\" A basic Swin Transformer layer for one stage.\n\n    Args:\n        dim (int): Number of input channels.\n        input_resolution (tuple[int]): Input resolution.\n        depth (int): Number of blocks.\n        num_heads (int): Number of attention heads.\n        window_size (int): Local window size.\n        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.\n        qkv_bias (bool, optional): If True, add a learnable bias to query, key, value. Default: True\n        drop (float, optional): Dropout rate. Default: 0.0\n        attn_drop (float, optional): Attention dropout rate. Default: 0.0\n        drop_path (float | tuple[float], optional): Stochastic depth rate. Default: 0.0\n        norm_layer (nn.Module, optional): Normalization layer. Default: nn.LayerNorm\n        downsample (nn.Module | None, optional): Downsample layer at the end of the layer. Default: None\n        use_checkpoint (bool): Whether to use checkpointing to save memory. Default: False.\n        pretrained_window_size (int): Local window size in pre-training.\n    \"\"\"\n\n    def __init__(self, dim, input_resolution, depth, num_heads, window_size,\n                 mlp_ratio=4., qkv_bias=True, drop=0., attn_drop=0.,\n                 drop_path=0., norm_layer=nn.LayerNorm, downsample=None, use_checkpoint=False,\n                 pretrained_window_size=0):\n\n        super().__init__()\n        self.dim = dim\n        self.input_resolution = input_resolution\n        self.depth = depth\n        self.use_checkpoint = use_checkpoint\n\n        # build blocks\n        self.blocks = nn.ModuleList([\n            SwinTransformerBlock(dim=dim, input_resolution=input_resolution,\n                                 num_heads=num_heads, window_size=window_size,\n                                 shift_size=0 if (i % 2 == 0) else window_size // 2,\n                                 mlp_ratio=mlp_ratio,\n                                 qkv_bias=qkv_bias,\n                                 drop=drop, attn_drop=attn_drop,\n                                 drop_path=drop_path[i] if isinstance(drop_path, list) else drop_path,\n                                 norm_layer=norm_layer,\n                                 pretrained_window_size=pretrained_window_size)\n            for i in range(depth)])\n\n        # patch merging layer\n        if downsample is not None:\n            self.downsample = downsample(input_resolution, dim=dim, norm_layer=norm_layer)\n        else:\n            self.downsample = None\n\n    def forward(self, x):\n        for blk in self.blocks:\n            if self.use_checkpoint:\n                x = checkpoint.checkpoint(blk, x)\n            else:\n                x = blk(x)\n        if self.downsample is not None:\n            x = self.downsample(x)\n        return x\n    \n\nclass PatchEmbed(nn.Module):\n    r\"\"\" Image to Patch Embedding\n\n    Args:\n        img_size (int): Image size.  Default: 224.\n        patch_size (int): Patch token size. Default: 4.\n        in_chans (int): Number of input image channels. Default: 3.\n        embed_dim (int): Number of linear projection output channels. Default: 96.\n        norm_layer (nn.Module, optional): Normalization layer. Default: None\n    \"\"\"\n\n    def __init__(self, img_size=224, patch_size=4, in_chans=3, embed_dim=96, norm_layer=None):\n        super().__init__()\n        img_size = to_2tuple(img_size)\n        patch_size = to_2tuple(patch_size)\n        patches_resolution = [img_size[0] // patch_size[0], img_size[1] // patch_size[1]]\n        self.img_size = img_size\n        self.patch_size = patch_size\n        self.patches_resolution = patches_resolution\n        self.num_patches = patches_resolution[0] * patches_resolution[1]\n\n        self.in_chans = in_chans\n        self.embed_dim = embed_dim\n\n        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n        if norm_layer is not None:\n            self.norm = norm_layer(embed_dim)\n        else:\n            self.norm = None\n\n    def forward(self, x):\n        B, C, H, W = x.shape\n        # FIXME look at relaxing size constraints\n        assert H == self.img_size[0] and W == self.img_size[1], \\\n            f\"Input image size ({H}*{W}) doesn't match model ({self.img_size[0]}*{self.img_size[1]}).\"\n        x = self.proj(x).flatten(2).transpose(1, 2)  # B Ph*Pw C\n        if self.norm is not None:\n            x = self.norm(x)\n        return x\n\n\nclass Model(nn.Module):\n    r\"\"\" Swin Transformer\n        A PyTorch impl of : `Swin Transformer: Hierarchical Vision Transformer using Shifted Windows`  -\n          https://arxiv.org/pdf/2103.14030\n\n    Args:\n        img_size (int | tuple(int)): Input image size. Default 224\n        patch_size (int | tuple(int)): Patch size. Default: 4\n        in_chans (int): Number of input image channels. Default: 3\n        num_classes (int): Number of classes for classification head. Default: 1000\n        embed_dim (int): Patch embedding dimension. Default: 96\n        depths (tuple(int)): Depth of each Swin Transformer layer.\n        num_heads (tuple(int)): Number of attention heads in different layers.\n        window_size (int): Window size. Default: 7\n        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim. Default: 4\n        qkv_bias (bool): If True, add a learnable bias to query, key, value. Default: True\n        drop_rate (float): Dropout rate. Default: 0\n        attn_drop_rate (float): Attention dropout rate. Default: 0\n        drop_path_rate (float): Stochastic depth rate. Default: 0.1\n        norm_layer (nn.Module): Normalization layer. Default: nn.LayerNorm.\n        patch_norm (bool): If True, add normalization after patch embedding. Default: True\n        use_checkpoint (bool): Whether to use checkpointing to save memory. Default: False\n        pretrained_window_sizes (tuple(int)): Pretrained window sizes of each layer.\n    \"\"\"\n\n    def __init__(self, img_size=224, patch_size=4, in_chans=3, num_classes=1000,\n                 embed_dim=96, depths=[2, 2, 6, 2], num_heads=[3, 6, 12, 24],\n                 window_size=7, mlp_ratio=4., qkv_bias=True,\n                 drop_rate=0., attn_drop_rate=0., drop_path_rate=0.1,\n                 norm_layer=nn.LayerNorm, patch_norm=True,\n                 use_checkpoint=False, pretrained_window_sizes=[0, 0, 0, 0], **kwargs):\n        super().__init__()\n\n        self.num_classes = num_classes\n        self.num_layers = len(depths)\n        self.embed_dim = embed_dim\n        self.patch_norm = patch_norm\n        self.num_features = int(embed_dim * 2 ** (self.num_layers - 1))\n        self.mlp_ratio = mlp_ratio\n\n        # split image into non-overlapping patches\n        self.patch_embed = PatchEmbed(\n            img_size=img_size, patch_size=patch_size, in_chans=in_chans, embed_dim=embed_dim,\n            norm_layer=norm_layer if self.patch_norm else None)\n        num_patches = self.patch_embed.num_patches\n        patches_resolution = self.patch_embed.patches_resolution\n        self.patches_resolution = patches_resolution\n\n        self.pos_drop = nn.Dropout(p=drop_rate)\n\n        # stochastic depth\n        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))]  # stochastic depth decay rule\n\n        # build layers\n        self.layers = nn.ModuleList()\n        for i_layer in range(self.num_layers):\n            layer = BasicLayer(dim=int(embed_dim * 2 ** i_layer),\n                               input_resolution=(patches_resolution[0] // (2 ** i_layer),\n                                                 patches_resolution[1] // (2 ** i_layer)),\n                               depth=depths[i_layer],\n                               num_heads=num_heads[i_layer],\n                               window_size=window_size,\n                               mlp_ratio=self.mlp_ratio,\n                               qkv_bias=qkv_bias,\n                               drop=drop_rate, attn_drop=attn_drop_rate,\n                               drop_path=dpr[sum(depths[:i_layer]):sum(depths[:i_layer + 1])],\n                               norm_layer=norm_layer,\n                               downsample=PatchMerging if (i_layer < self.num_layers - 1) else None,\n                               use_checkpoint=use_checkpoint,\n                               pretrained_window_size=pretrained_window_sizes[i_layer])\n            self.layers.append(layer)\n\n        self.norm = norm_layer(self.num_features)\n        self.avgpool = nn.AdaptiveAvgPool1d(1)\n        self.head = nn.Linear(self.num_features, num_classes) if num_classes > 0 else nn.Identity()\n\n    def forward_features(self, x):\n        x = self.patch_embed(x)\n        x = self.pos_drop(x)\n\n        for layer in self.layers:\n            x = layer(x)\n\n        x = self.norm(x)  # B L C\n        x = self.avgpool(x.transpose(1, 2))  # B C 1\n        x = torch.flatten(x, 1)\n        return x\n\n    def forward(self, x):\n        x = self.forward_features(x)\n        x = self.head(x)\n        return x\n\nbatch_size = 10\nimage_size = 224\n\ndef get_inputs():\n    return [torch.rand(batch_size, 3, image_size, image_size)]\n\ndef get_init_inputs():\n    return []", "jax_code": "import jax\nimport jax.numpy as jnp\nimport numpy as np\nfrom flax import linen as nn\nfrom typing import Any, Callable, Sequence, Optional, Tuple\nimport functools\n\ndef _ntuple(n):\n    def parse(x):\n        if isinstance(x, (tuple, list)):\n            return tuple(x)\n        return tuple([x] * n)\n    return parse\nto_2tuple = _ntuple(2)\n\nclass Mlp(nn.Module):\n    in_features: int\n    hidden_features: Optional[int] = None\n    out_features: Optional[int] = None\n    act_layer: Callable = nn.gelu\n    drop: float = 0.\n\n    @nn.compact\n    def __call__(self, x, deterministic=True):\n        out_features = self.out_features or self.in_features\n        hidden_features = self.hidden_features or self.in_features\n        x = nn.Dense(hidden_features)(x)\n        x = self.act_layer(x)\n        x = nn.Dropout(self.drop)(x, deterministic=deterministic)\n        x = nn.Dense(out_features)(x)\n        x = nn.Dropout(self.drop)(x, deterministic=deterministic)\n        return x\n\ndef window_partition(x, window_size):\n    \"\"\"\n    Args:\n        x: (B, H, W, C)\n        window_size (int): window size\n\n    Returns:\n        windows: (num_windows*B, window_size, window_size, C)\n    \"\"\"\n    B, H, W, C = x.shape\n    x = x.reshape(B, H // window_size, window_size, W // window_size, window_size, C)\n    x = jnp.transpose(x, (0, 1, 3, 2, 4, 5))\n    windows = x.reshape(-1, window_size, window_size, C)\n    return windows\n\ndef window_reverse(windows, window_size, H, W):\n    \"\"\"\n    Args:\n        windows: (num_windows*B, window_size, window_size, C)\n        window_size (int): Window size\n        H (int): Height of image\n        W (int): Width of image\n\n    Returns:\n        x: (B, H, W, C)\n    \"\"\"\n    B = int(windows.shape[0] // (H * W // window_size // window_size))\n    x = windows.reshape(B, H // window_size, W // window_size, window_size, window_size, -1)\n    x = jnp.transpose(x, (0, 1, 3, 2, 4, 5))\n    x = x.reshape(B, H, W, -1)\n    return x\n\nclass WindowAttention(nn.Module):\n    dim: int\n    window_size: Tuple[int, int]\n    num_heads: int\n    qkv_bias: bool = True\n    attn_drop: float = 0.\n    proj_drop: float = 0.\n    pretrained_window_size: Tuple[int, int] = (0, 0)\n\n    def setup(self):\n        self.logit_scale = self.param(\n            \"logit_scale\",\n            lambda rng, shape: jnp.log(10 * jnp.ones(shape, dtype=jnp.float32)),\n            (self.num_heads, 1, 1)\n        )\n\n        self.cpb_mlp_dense1 = nn.Dense(512, use_bias=True)\n        self.cpb_mlp_dense2 = nn.Dense(self.num_heads, use_bias=False)\n\n        Wh, Ww = self.window_size\n        ph, pw = self.pretrained_window_size\n        relative_coords_h = jnp.arange(-(Wh - 1), Wh, dtype=jnp.float32)\n        relative_coords_w = jnp.arange(-(Ww - 1), Ww, dtype=jnp.float32)\n        mesh = jnp.meshgrid(relative_coords_h, relative_coords_w, indexing='ij')\n        relative_coords_table = jnp.stack(mesh, axis=-1)[None, ...]  # 1, 2*Wh-1, 2*Ww-1, 2\n\n        if ph > 0:\n            relative_coords_table = relative_coords_table.at[..., 0].divide(ph - 1)\n            relative_coords_table = relative_coords_table.at[..., 1].divide(pw - 1)\n        else:\n            relative_coords_table = relative_coords_table.at[..., 0].divide(Wh - 1)\n            relative_coords_table = relative_coords_table.at[..., 1].divide(Ww - 1)\n        relative_coords_table = relative_coords_table * 8\n        relative_coords_table = jnp.sign(relative_coords_table) * jnp.log2(jnp.abs(relative_coords_table) + 1.0) / np.log2(8)\n        self.relative_coords_table = self.variable(\"constants\", \"relative_coords_table\", lambda: relative_coords_table)\n\n        coords_h = jnp.arange(Wh)\n        coords_w = jnp.arange(Ww)\n        mesh2 = jnp.meshgrid(coords_h, coords_w, indexing='ij')\n        coords = jnp.stack(mesh2)  # 2, Wh, Ww\n        coords_flatten = coords.reshape(2, -1)\n        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]  # 2, Wh*Ww, Wh*Ww\n        relative_coords = jnp.transpose(relative_coords, (1, 2, 0))  # Wh*Ww, Wh*Ww, 2\n        relative_coords = relative_coords.at[:, :, 0].add(Wh - 1)\n        relative_coords = relative_coords.at[:, :, 1].add(Ww - 1)\n        relative_coords = relative_coords.at[:, :, 0].multiply(2 * Ww - 1)\n        relative_position_index = relative_coords.sum(-1)  # Wh*Ww, Wh*Ww\n        self.relative_position_index = self.variable(\"constants\", \"relative_position_index\", lambda: relative_position_index)\n\n        self.qkv = nn.Dense(self.dim * 3, use_bias=False)\n        if self.qkv_bias:\n            self.q_bias = self.param(\"q_bias\", nn.initializers.zeros, (self.dim,))\n            self.v_bias = self.param(\"v_bias\", nn.initializers.zeros, (self.dim,))\n        else:\n            self.q_bias = None\n            self.v_bias = None\n        self.attn_drop_layer = nn.Dropout(self.attn_drop)\n        self.proj = nn.Dense(self.dim)\n        self.proj_drop_layer = nn.Dropout(self.proj_drop)\n\n    def __call__(self, x, mask=None, deterministic=True):\n        B_, N, C = x.shape\n        if self.qkv_bias:\n            qkv_bias = jnp.concatenate([\n                self.q_bias,\n                jnp.zeros_like(self.v_bias),\n                self.v_bias\n            ])\n        else:\n            qkv_bias = None\n        qkv = self.qkv(x)\n        if qkv_bias is not None:\n            qkv = qkv + qkv_bias\n        qkv = qkv.reshape(B_, N, 3, self.num_heads, C // self.num_heads)\n        qkv = jnp.transpose(qkv, (2, 0, 3, 1, 4))\n        q, k, v = qkv[0], qkv[1], qkv[2]\n\n        q = q / (jnp.linalg.norm(q, axis=-1, keepdims=True) + 1e-6)\n        k = k / (jnp.linalg.norm(k, axis=-1, keepdims=True) + 1e-6)\n        attn = jnp.einsum('bnqd,bnkd->bnqk', q, k)\n        attn = jnp.matmul(q, jnp.swapaxes(k, -2, -1))\n\n        logit_scale = jnp.clip(self.logit_scale, a_max=jnp.log(1. / 0.01)).exp()\n        attn = attn * logit_scale\n\n        relative_coords_table = self.relative_coords_table.value\n        rel_coords_flat = relative_coords_table.reshape(-1, 2)\n        rel_bias = self.cpb_mlp_dense1(rel_coords_flat)\n        rel_bias = nn.relu(rel_bias)\n        rel_bias = self.cpb_mlp_dense2(rel_bias)\n        rel_bias = rel_bias.reshape(-1, self.num_heads)\n        relative_position_index = self.relative_position_index.value\n        rel_bias = rel_bias[relative_position_index.reshape(-1)]\n        rel_bias = rel_bias.reshape(self.window_size[0] * self.window_size[1],\n                                   self.window_size[0] * self.window_size[1], self.num_heads)\n        rel_bias = jnp.transpose(rel_bias, (2, 0, 1))\n        rel_bias = 16 * nn.sigmoid(rel_bias)\n        attn = attn + rel_bias[None, ...]\n\n        if mask is not None:\n            nW = mask.shape[0]\n            attn = attn.reshape(B_ // nW, nW, self.num_heads, N, N) + mask[None, :, None, :, :]\n            attn = attn.reshape(-1, self.num_heads, N, N)\n            attn = nn.softmax(attn, axis=-1)\n        else:\n            attn = nn.softmax(attn, axis=-1)\n\n        attn = self.attn_drop_layer(attn, deterministic=deterministic)\n        x = jnp.matmul(attn, v)\n        x = jnp.transpose(x, (0, 2, 1, 3)).reshape(B_, N, C)\n        x = self.proj(x)\n        x = self.proj_drop_layer(x, deterministic=deterministic)\n        return x\n\nclass SwinTransformerBlock(nn.Module):\n    dim: int\n    input_resolution: Tuple[int, int]\n    num_heads: int\n    window_size: int = 7\n    shift_size: int = 0\n    mlp_ratio: float = 4.\n    qkv_bias: bool = True\n    drop: float = 0.\n    attn_drop: float = 0.\n    drop_path: float = 0.\n    act_layer: Callable = nn.gelu\n    norm_layer: Callable = nn.LayerNorm\n    pretrained_window_size: int = 0\n\n    def setup(self):\n        H, W = self.input_resolution\n        window_size = self.window_size\n        shift_size = self.shift_size\n        if min(self.input_resolution) <= self.window_size:\n            shift_size = 0\n            window_size = min(self.input_resolution)\n        self.window_size_ = window_size\n        self.shift_size_ = shift_size\n\n        self.norm1 = self.norm_layer()\n        self.attn = WindowAttention(\n            dim=self.dim,\n            window_size=to_2tuple(window_size),\n            num_heads=self.num_heads,\n            qkv_bias=self.qkv_bias,\n            attn_drop=self.attn_drop,\n            proj_drop=self.drop,\n            pretrained_window_size=to_2tuple(self.pretrained_window_size)\n        )\n        self.norm2 = self.norm_layer()\n        mlp_hidden_dim = int(self.dim * self.mlp_ratio)\n        self.mlp = Mlp(in_features=self.dim, hidden_features=mlp_hidden_dim, act_layer=self.act_layer, drop=self.drop)\n\n        if self.shift_size_ > 0:\n            img_mask = jnp.zeros((1, H, W, 1))\n            h_slices = (slice(0, -window_size), slice(-window_size, -shift_size), slice(-shift_size, None))\n            w_slices = (slice(0, -window_size), slice(-window_size, -shift_size), slice(-shift_size, None))\n            cnt = 0\n            mask = np.zeros((1, H, W, 1), dtype=np.float32)\n            for h in h_slices:\n                for w in w_slices:\n                    mask[(slice(None), h, w, slice(None))] = cnt\n                    cnt += 1\n            mask_windows = window_partition(mask, window_size)\n            mask_windows = mask_windows.reshape(-1, window_size * window_size)\n            attn_mask = mask_windows[:, None, :] - mask_windows[:, :, None]\n            attn_mask = np.where(attn_mask != 0, -100.0, 0.0)\n            self.attn_mask = self.variable(\"constants\", \"attn_mask\", lambda: jnp.array(attn_mask))\n        else:\n            self.attn_mask = None\n\n    def __call__(self, x, deterministic=True):\n        H, W = self.input_resolution\n        B, L, C = x.shape\n        assert L == H * W\n        shortcut = x\n        x = x.reshape(B, H, W, C)\n\n        if self.shift_size_ > 0:\n            shifted_x = jnp.roll(x, shift=(-self.shift_size_, -self.shift_size_), axis=(1, 2))\n        else:\n            shifted_x = x\n\n        x_windows = window_partition(shifted_x, self.window_size_)\n        x_windows = x_windows.reshape(-1, self.window_size_ * self.window_size_, C)\n\n        attn_mask = self.attn_mask.value if self.attn_mask is not None else None\n        attn_windows = self.attn(x_windows, mask=attn_mask, deterministic=deterministic)\n\n        attn_windows = attn_windows.reshape(-1, self.window_size_, self.window_size_, C)\n        shifted_x = window_reverse(attn_windows, self.window_size_, H, W)\n\n        if self.shift_size_ > 0:\n            x = jnp.roll(shifted_x, shift=(self.shift_size_, self.shift_size_), axis=(1, 2))\n        else:\n            x = shifted_x\n        x = x.reshape(B, H * W, C)\n        x = shortcut + self.norm1(x)\n        x = x + self.norm2(self.mlp(x, deterministic=deterministic))\n        return x\n\nclass PatchMerging(nn.Module):\n    input_resolution: Tuple[int, int]\n    dim: int\n    norm_layer: Callable = nn.LayerNorm\n\n    def setup(self):\n        self.reduction = nn.Dense(2 * self.dim, use_bias=False)\n        self.norm = self.norm_layer()\n\n    def __call__(self, x):\n        H, W = self.input_resolution\n        B, L, C = x.shape\n        assert L == H * W\n        assert H % 2 == 0 and W % 2 == 0\n        x = x.reshape(B, H, W, C)\n        x0 = x[:, 0::2, 0::2, :]\n        x1 = x[:, 1::2, 0::2, :]\n        x2 = x[:, 0::2, 1::2, :]\n        x3 = x[:, 1::2, 1::2, :]\n        x = jnp.concatenate([x0, x1, x2, x3], axis=-1)\n        x = x.reshape(B, -1, 4 * C)\n        x = self.reduction(x)\n        x = self.norm(x)\n        return x\n\nclass BasicLayer(nn.Module):\n    dim: int\n    input_resolution: Tuple[int, int]\n    depth: int\n    num_heads: int\n    window_size: int\n    mlp_ratio: float = 4.\n    qkv_bias: bool = True\n    drop: float = 0.\n    attn_drop: float = 0.\n    drop_path: float = 0.\n    norm_layer: Callable = nn.LayerNorm\n    downsample: Optional[Any] = None\n    use_checkpoint: bool = False\n    pretrained_window_size: int = 0\n\n    def setup(self):\n        self.blocks = [\n            SwinTransformerBlock(\n                dim=self.dim,\n                input_resolution=self.input_resolution,\n                num_heads=self.num_heads,\n                window_size=self.window_size,\n                shift_size=0 if (i % 2 == 0) else self.window_size // 2,\n                mlp_ratio=self.mlp_ratio,\n                qkv_bias=self.qkv_bias,\n                drop=self.drop,\n                attn_drop=self.attn_drop,\n                drop_path=self.drop_path if not isinstance(self.drop_path, (list, tuple)) else self.drop_path[i],\n                norm_layer=self.norm_layer,\n                pretrained_window_size=self.pretrained_window_size\n            ) for i in range(self.depth)\n        ]\n        if self.downsample is not None:\n            self.downsample_layer = self.downsample(self.input_resolution, dim=self.dim, norm_layer=self.norm_layer)\n        else:\n            self.downsample_layer = None\n\n    def __call__(self, x, deterministic=True):\n        for blk in self.blocks:\n            x = blk(x, deterministic=deterministic)\n        if self.downsample_layer is not None:\n            x = self.downsample_layer(x)\n        return x\n\nclass PatchEmbed(nn.Module):\n    img_size: int = 224\n    patch_size: int = 4\n    in_chans: int = 3\n    embed_dim: int = 96\n    norm_layer: Optional[Callable] = None\n\n    def setup(self):\n        img_size = to_2tuple(self.img_size)\n        patch_size = to_2tuple(self.patch_size)\n        patches_resolution = [img_size[0] // patch_size[0], img_size[1] // patch_size[1]]\n        self.img_size_ = img_size\n        self.patch_size_ = patch_size\n        self.patches_resolution = patches_resolution\n        self.num_patches = patches_resolution[0] * patches_resolution[1]\n        self.proj = nn.Conv(self.embed_dim, kernel_size=patch_size, strides=patch_size, use_bias=True)\n        if self.norm_layer is not None:\n            self.norm = self.norm_layer()\n        else:\n            self.norm = None\n\n    def __call__(self, x):\n        B, C, H, W = x.shape\n        assert H == self.img_size_[0] and W == self.img_size_[1]\n        x = jnp.transpose(x, (0, 2, 3, 1))  # B, H, W, C\n        x = self.proj(x)\n        x = x.reshape(B, -1, self.embed_dim)\n        if self.norm is not None:\n            x = self.norm(x)\n        return x\n\nclass Model(nn.Module):\n    img_size: int = 224\n    patch_size: int = 4\n    in_chans: int = 3\n    num_classes: int = 1000\n    embed_dim: int = 96\n    depths: Sequence[int] = (2, 2, 6, 2)\n    num_heads: Sequence[int] = (3, 6, 12, 24)\n    window_size: int = 7\n    mlp_ratio: float = 4.\n    qkv_bias: bool = True\n    drop_rate: float = 0.\n    attn_drop_rate: float = 0.\n    drop_path_rate: float = 0.1\n    norm_layer: Callable = nn.LayerNorm\n    patch_norm: bool = True\n    use_checkpoint: bool = False\n    pretrained_window_sizes: Sequence[int] = (0, 0, 0, 0)\n\n    def setup(self):\n        self.num_layers = len(self.depths)\n        self.num_features = int(self.embed_dim * 2 ** (self.num_layers - 1))\n        self.patch_embed = PatchEmbed(\n            img_size=self.img_size,\n            patch_size=self.patch_size,\n            in_chans=self.in_chans,\n            embed_dim=self.embed_dim,\n            norm_layer=self.norm_layer if self.patch_norm else None\n        )\n        self.patches_resolution = self.patch_embed.patches_resolution\n        self.pos_drop = nn.Dropout(self.drop_rate)\n        dpr = np.linspace(0, self.drop_path_rate, sum(self.depths)).tolist()\n        self.layers = []\n        for i_layer in range(self.num_layers):\n            layer = BasicLayer(\n                dim=int(self.embed_dim * 2 ** i_layer),\n                input_resolution=(self.patches_resolution[0] // (2 ** i_layer),\n                                  self.patches_resolution[1] // (2 ** i_layer)),\n                depth=self.depths[i_layer],\n                num_heads=self.num_heads[i_layer],\n                window_size=self.window_size,\n                mlp_ratio=self.mlp_ratio,\n                qkv_bias=self.qkv_bias,\n                drop=self.drop_rate,\n                attn_drop=self.attn_drop_rate,\n                drop_path=dpr[sum(self.depths[:i_layer]):sum(self.depths[:i_layer + 1])],\n                norm_layer=self.norm_layer,\n                downsample=PatchMerging if (i_layer < self.num_layers - 1) else None,\n                use_checkpoint=self.use_checkpoint,\n                pretrained_window_size=self.pretrained_window_sizes[i_layer]\n            )\n            self.layers.append(layer)\n        self.norm = self.norm_layer()\n        self.head = nn.Dense(self.num_features if self.num_classes <= 0 else self.num_classes)\n        self.avgpool = lambda x: jnp.mean(x, axis=1, keepdims=True)\n\n    def forward_features(self, x, deterministic=True):\n        x = self.patch_embed(x)\n        x = self.pos_drop(x, deterministic=deterministic)\n        for layer in self.layers:\n            x = layer(x, deterministic=deterministic)\n        x = self.norm(x)\n        x = self.avgpool(x)\n        x = x.reshape(x.shape[0], -1)\n        return x\n\n    def __call__(self, x, deterministic=True):\n        x = self.forward_features(x, deterministic=deterministic)\n        x = self.head(x)\n        return x\n\nbatch_size = 10\nimage_size = 224\n\ndef get_inputs():\n    return [jnp.array(np.random.rand(batch_size, 3, image_size, image_size), dtype=jnp.float32)]\n\ndef get_init_inputs():\n    return []"}
{"kb_id": "kb_level_3_0023", "level": "level_3", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/pytorch_samples/kb_level_3_0023.py", "jax_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/jax_outputs/kb_level_3_0023_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, embed_dim, num_heads):\n        \"\"\"\n        Attention Block using Multihead Self-Attention.\n        :param embed_dim: Embedding dimension (the number of channels)\n        :param num_heads: Number of attention heads\n        \"\"\"\n        super(Model, self).__init__()\n        self.attn = nn.MultiheadAttention(embed_dim, num_heads)\n        self.norm = nn.LayerNorm(embed_dim)\n\n    def forward(self, x):\n        \"\"\"\n        Forward pass of the AttentionBlock.\n        :param x: Input tensor of shape (B, C, H, W)\n        :return: Output tensor of the same shape (B, C, H, W)\n        \"\"\"\n        B, C, H, W = x.shape\n        x = x.view(B, C, H * W).permute(2, 0, 1)  # (seq_len, batch_size, embed_dim)\n        attn_output, _ = self.attn(x, x, x)\n        x = self.norm(attn_output + x)  # (seq_len, batch_size, embed_dim)\n        x = x.permute(1, 2, 0).view(B, C, H, W)\n        return x\n\nembed_dim = 128\nnum_heads = 4\nbatch_size = 2\nnum_channels = embed_dim\nimage_height = 128\nimage_width = 128\n\ndef get_inputs():\n    return [torch.rand(batch_size, num_channels, image_height, image_width)]\n\ndef get_init_inputs():\n    return [embed_dim, num_heads]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass MultiheadSelfAttention(nn.Module):\n    embed_dim: int\n    num_heads: int\n\n    @nn.compact\n    def __call__(self, x):\n        # x: (seq_len, batch_size, embed_dim)\n        seq_len, batch_size, embed_dim = x.shape\n        head_dim = self.embed_dim // self.num_heads\n        assert self.embed_dim % self.num_heads == 0, \"embed_dim must be divisible by num_heads\"\n\n        # Project inputs to Q, K, V\n        qkv = nn.Dense(3 * self.embed_dim, use_bias=True)(x)  # (seq_len, batch_size, 3*embed_dim)\n        qkv = qkv.reshape(seq_len, batch_size, 3, self.num_heads, head_dim)\n        qkv = qkv.transpose(2, 3, 1, 0, 4)  # (3, num_heads, batch_size, seq_len, head_dim)\n        q, k, v = qkv[0], qkv[1], qkv[2]  # each: (num_heads, batch_size, seq_len, head_dim)\n\n        # Compute attention scores\n        attn_scores = jnp.einsum('hbqd,hbkd->hbqk', q, k)  # (num_heads, batch_size, seq_len, seq_len)\n        attn_scores = attn_scores / jnp.sqrt(head_dim)\n        attn_weights = nn.softmax(attn_scores, axis=-1)  # (num_heads, batch_size, seq_len, seq_len)\n\n        # Weighted sum of values\n        attn_output = jnp.einsum('hbqk,hbkd->hbqd', attn_weights, v)  # (num_heads, batch_size, seq_len, head_dim)\n        attn_output = attn_output.transpose(2, 1, 0, 3)  # (seq_len, batch_size, num_heads, head_dim)\n        attn_output = attn_output.reshape(seq_len, batch_size, self.embed_dim)  # (seq_len, batch_size, embed_dim)\n\n        # Final output projection\n        out = nn.Dense(self.embed_dim, use_bias=True)(attn_output)  # (seq_len, batch_size, embed_dim)\n        return out\n\nclass Model(nn.Module):\n    embed_dim: int\n    num_heads: int\n\n    def setup(self):\n        self.attn = MultiheadSelfAttention(self.embed_dim, self.num_heads)\n        self.norm = nn.LayerNorm()\n\n    def __call__(self, x):\n        # x: (B, C, H, W)\n        B, C, H, W = x.shape\n        x_reshaped = x.reshape(B, C, H * W).transpose(2, 0, 1)  # (seq_len, batch_size, embed_dim)\n        attn_output = self.attn(x_reshaped)\n        x_out = self.norm(attn_output + x_reshaped)\n        x_out = x_out.transpose(1, 2, 0).reshape(B, C, H, W)\n        return x_out\n\nembed_dim = 128\nnum_heads = 4\nbatch_size = 2\nnum_channels = embed_dim\nimage_height = 128\nimage_width = 128\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, num_channels, image_height, image_width).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [embed_dim, num_heads]"}
{"kb_id": "kb_level_3_0024", "level": "level_3", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/pytorch_samples/kb_level_3_0024.py", "jax_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/jax_outputs/kb_level_3_0024_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    def __init__(self, num_classes, embed_dim=512, num_heads=8, num_layers=6, \n                 mlp_ratio=4.0, patch_size=4, in_channels=3, image_size=32):\n        \"\"\"\n        Convolutional Vision Transformer (CViT) implementation.\n        :param num_classes: Number of output classes for classification.\n        :param embed_dim: Dimensionality of the embedding space.\n        :param num_heads: Number of attention heads.\n        :param num_layers: Number of transformer layers.\n        :param mlp_ratio: Ratio of the MLP hidden dimension to the embedding dimension.\n        :param patch_size: Size of the convolutional patches.\n        :param in_channels: Number of input channels (e.g., 3 for RGB images).\n        :param image_size: Height/width of the square input image.\n        \"\"\"\n        super(Model, self).__init__()\n\n        self.patch_size = patch_size\n        self.image_size = image_size\n        self.embed_dim = embed_dim\n\n        self.conv1 = nn.Conv2d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size)\n        num_patches = (image_size // patch_size) ** 2  # Total number of patches after conv\n        self.linear_proj = nn.Linear(embed_dim * num_patches, embed_dim)\n\n        self.transformer_layers = nn.ModuleList([\n            nn.TransformerEncoderLayer(\n                d_model=embed_dim,\n                nhead=num_heads,\n                dim_feedforward=int(embed_dim * mlp_ratio),\n                dropout=0.0,\n                batch_first=True\n            ) for _ in range(num_layers)\n        ])\n\n        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n        self.fc_out = nn.Linear(embed_dim, num_classes)\n\n    def forward(self, x):\n        \"\"\"\n        Forward pass of the CViT model.\n        :param x: Input tensor of shape (B, C, H, W)\n        :return: Output tensor of shape (B, num_classes)\n        \"\"\"\n        B = x.size(0)\n        x = self.conv1(x)                  # (B, embed_dim, H/patch_size, W/patch_size)\n        x = x.flatten(start_dim=1)         # (B, embed_dim * num_patches)\n        x = self.linear_proj(x)            # (B, embed_dim)\n\n        cls_tokens = self.cls_token.expand(B, -1, -1)  # (B, 1, embed_dim)\n        x = torch.cat((cls_tokens, x.unsqueeze(1)), dim=1)  # (B, 2, embed_dim)\n\n        for layer in self.transformer_layers:\n            x = layer(x)\n\n        return self.fc_out(x[:, 0])        # Use [CLS] token for classification\n\n# === Test config ===\nbatch_size = 10\nimage_size = 32\nembed_dim = 128\nin_channels = 3\nnum_heads = 4\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, image_size, image_size)]\n\ndef get_init_inputs():\n    return [num_classes, embed_dim, num_heads]\n", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Conv2d(nn.Module):\n    in_channels: int\n    out_channels: int\n    kernel_size: int\n    stride: int\n\n    @nn.compact\n    def __call__(self, x):\n        # x: (B, C, H, W) -> (B, H, W, C)\n        x = jnp.transpose(x, (0, 2, 3, 1))\n        conv = nn.Conv(\n            features=self.out_channels,\n            kernel_size=(self.kernel_size, self.kernel_size),\n            strides=(self.stride, self.stride),\n            use_bias=True,\n            kernel_init=nn.initializers.lecun_normal()\n        )\n        x = conv(x)\n        # (B, H', W', out_channels) -> (B, out_channels, H', W')\n        x = jnp.transpose(x, (0, 3, 1, 2))\n        return x\n\nclass Linear(nn.Module):\n    in_features: int\n    out_features: int\n\n    @nn.compact\n    def __call__(self, x):\n        dense = nn.Dense(features=self.out_features, use_bias=True)\n        return dense(x)\n\nclass MLP(nn.Module):\n    embed_dim: int\n    mlp_dim: int\n\n    @nn.compact\n    def __call__(self, x):\n        x = nn.Dense(self.mlp_dim)(x)\n        x = nn.gelu(x)\n        x = nn.Dense(self.embed_dim)(x)\n        return x\n\nclass TransformerEncoderLayer(nn.Module):\n    embed_dim: int\n    num_heads: int\n    mlp_dim: int\n\n    @nn.compact\n    def __call__(self, x):\n        # x: (B, N, D)\n        # LayerNorm + MultiHead Self-Attention\n        y = nn.LayerNorm()(x)\n        y = nn.SelfAttention(\n            num_heads=self.num_heads,\n            qkv_features=self.embed_dim,\n            out_features=self.embed_dim,\n            use_bias=True,\n            broadcast_dropout=False,\n            dropout_rate=0.0\n        )(y)\n        x = x + y\n        # LayerNorm + MLP\n        y = nn.LayerNorm()(x)\n        y = MLP(self.embed_dim, self.mlp_dim)(y)\n        x = x + y\n        return x\n\nclass Model(nn.Module):\n    num_classes: int\n    embed_dim: int = 512\n    num_heads: int = 8\n    num_layers: int = 6\n    mlp_ratio: float = 4.0\n    patch_size: int = 4\n    in_channels: int = 3\n    image_size: int = 32\n\n    def setup(self):\n        self.conv1 = Conv2d(\n            in_channels=self.in_channels,\n            out_channels=self.embed_dim,\n            kernel_size=self.patch_size,\n            stride=self.patch_size\n        )\n        num_patches = (self.image_size // self.patch_size) ** 2\n        self.num_patches = num_patches\n        self.linear_proj = Linear(\n            in_features=self.embed_dim * num_patches,\n            out_features=self.embed_dim\n        )\n        self.transformer_layers = [\n            TransformerEncoderLayer(\n                embed_dim=self.embed_dim,\n                num_heads=self.num_heads,\n                mlp_dim=int(self.embed_dim * self.mlp_ratio)\n            ) for _ in range(self.num_layers)\n        ]\n        self.cls_token = self.param(\n            'cls_token',\n            nn.initializers.zeros,\n            (1, 1, self.embed_dim)\n        )\n        self.fc_out = Linear(\n            in_features=self.embed_dim,\n            out_features=self.num_classes\n        )\n\n    def __call__(self, x):\n        # x: (B, C, H, W)\n        B = x.shape[0]\n        x = self.conv1(x)  # (B, embed_dim, H/patch, W/patch)\n        x = x.reshape((B, -1))  # (B, embed_dim * num_patches)\n        x = self.linear_proj(x)  # (B, embed_dim)\n        cls_tokens = jnp.tile(self.cls_token, (B, 1, 1))  # (B, 1, embed_dim)\n        x = jnp.expand_dims(x, axis=1)  # (B, 1, embed_dim)\n        x = jnp.concatenate([cls_tokens, x], axis=1)  # (B, 2, embed_dim)\n        for layer in self.transformer_layers:\n            x = layer(x)\n        logits = self.fc_out(x[:, 0])  # (B, num_classes)\n        return logits\n\n# === Test config ===\nbatch_size = 10\nimage_size = 32\nembed_dim = 128\nin_channels = 3\nnum_heads = 4\nnum_classes = 1000\n\ndef get_inputs():\n    key = jax.random.PRNGKey(0)\n    x = jax.random.uniform(\n        key,\n        (batch_size, in_channels, image_size, image_size),\n        minval=0.0,\n        maxval=1.0\n    )\n    return [x]\n\ndef get_init_inputs():\n    return [num_classes, embed_dim, num_heads]"}
{"kb_id": "kb_level_3_0026", "level": "level_3", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/pytorch_samples/kb_level_3_0026.py", "jax_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/jax_outputs/kb_level_3_0026_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    def __init__(self, input_size: int, hidden_size: int, output_size: int):\n        \"\"\"\n        Initialize the Vanilla RNN model.\n\n        :param input_size: The number of input features (int).\n        :param hidden_size: The size of the hidden state (int).\n        :param output_size: The number of output features (int).\n        \"\"\"\n        super(Model, self).__init__()\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.output_size = output_size\n\n        # Define the RNN cell components (input to hidden, hidden to hidden, and hidden to output)\n        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)  # Input to hidden\n        self.h2o = nn.Linear(hidden_size, output_size)  # Hidden to output\n        self.tanh = nn.Tanh()  # Activation function for hidden state\n\n    def forward(self, x: torch.Tensor, h0: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Forward pass of the Vanilla RNN.\n\n        :param x: Input tensor of shape (seq_len, batch_size, input_size)\n        :param h0: Initial hidden state tensor of shape (batch_size, hidden_size)\n        :return: Output tensor of shape (seq_len, batch_size, output_size)\n        \"\"\"\n        seq_len, batch_size, _ = x.size()\n        hidden = h0.to(x.device)\n        outputs = []\n\n        for t in range(seq_len):\n            combined = torch.cat((x[t], hidden), dim=1)  # Concatenate input and hidden state\n            hidden = self.tanh(self.i2h(combined))  # Update hidden state\n            output = self.h2o(hidden)  # Compute output\n            outputs.append(output)\n\n        return torch.stack(outputs, dim=0)  # (seq_len, batch_size, output_size)\n\n# === Test configuration ===\nbatch_size = 8\ninput_size = 1024\nhidden_size = 256\noutput_size = 128\nsequence_length = 256\n\ndef get_inputs():\n    return [\n        torch.rand(sequence_length, batch_size, input_size),\n        torch.rand(batch_size, hidden_size)\n    ]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, output_size]\n", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    input_size: int\n    hidden_size: int\n    output_size: int\n\n    @nn.compact\n    def __call__(self, x, h0):\n        \"\"\"\n        x: (seq_len, batch_size, input_size)\n        h0: (batch_size, hidden_size)\n        Returns: (seq_len, batch_size, output_size)\n        \"\"\"\n        i2h = nn.Dense(self.hidden_size)\n        h2o = nn.Dense(self.output_size)\n        seq_len, batch_size, _ = x.shape\n        hidden = h0\n\n        def step_fn(carry, x_t):\n            hidden = carry\n            combined = jnp.concatenate([x_t, hidden], axis=1)\n            hidden_new = jnp.tanh(i2h(combined))\n            output = h2o(hidden_new)\n            return hidden_new, output\n\n        # Scan over time dimension (axis=0)\n        _, outputs = jax.lax.scan(step_fn, hidden, x)\n        return outputs  # (seq_len, batch_size, output_size)\n\n# === Test configuration ===\nbatch_size = 8\ninput_size = 1024\nhidden_size = 256\noutput_size = 128\nsequence_length = 256\n\ndef get_inputs(key=None):\n    if key is None:\n        key = jax.random.PRNGKey(0)\n    k1, k2 = jax.random.split(key)\n    x = jax.random.uniform(k1, (sequence_length, batch_size, input_size))\n    h0 = jax.random.uniform(k2, (batch_size, hidden_size))\n    return [x, h0]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, output_size]"}
{"kb_id": "kb_level_3_0027", "level": "level_3", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/pytorch_samples/kb_level_3_0027.py", "jax_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/jax_outputs/kb_level_3_0027_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.0):\n        \"\"\"\n        Initialize the LSTM model.\n\n        :param input_size: The number of expected features in the input `x`\n        :param hidden_size: The number of features in the hidden state `h`\n        :param num_layers: Number of recurrent layers\n        :param output_size: The number of output features\n        :param dropout: If non-zero, introduces a Dropout layer on the outputs of each LSTM layer except the last layer\n        \"\"\"\n        super(Model, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.lstm = nn.LSTM(input_size, hidden_size, num_layers,\n                            batch_first=True, dropout=dropout, bidirectional=False)\n        self.fc = nn.Linear(hidden_size, output_size)\n\n    def forward(self, x, h0=None, c0=None):\n        \"\"\"\n        Forward pass through the LSTM model.\n\n        :param x: The input tensor, shape (batch_size, sequence_length, input_size)\n        :param h0: Optional initial hidden state (num_layers, batch_size, hidden_size)\n        :param c0: Optional initial cell state (num_layers, batch_size, hidden_size)\n        :return: The output tensor, shape (batch_size, output_size)\n        \"\"\"\n        batch_size = x.size(0)\n\n        if h0 is None:\n            h0 = torch.randn(self.num_layers, batch_size, self.hidden_size, device=x.device)\n        if c0 is None:\n            c0 = torch.randn(self.num_layers, batch_size, self.hidden_size, device=x.device)\n\n        out, _ = self.lstm(x, (h0, c0))  # out: (batch_size, seq_length, hidden_size)\n        out = self.fc(out[:, -1, :])     # out: (batch_size, output_size)\n\n        return out\n\n# === Test configuration ===\nbatch_size = 10\nsequence_length = 512\ninput_size = 128\nhidden_size = 256\nnum_layers = 6\noutput_size = 10\ndropout = 0.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, sequence_length, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, num_layers, output_size, dropout]\n", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass LSTMCell(nn.Module):\n    hidden_size: int\n\n    @nn.compact\n    def __call__(self, carry, x):\n        h, c = carry\n        input_size = x.shape[-1]\n        # Concatenate input and hidden state\n        concat = jnp.concatenate([x, h], axis=-1)\n        # Linear for all gates at once\n        gates = nn.Dense(4 * self.hidden_size)(concat)\n        i, f, g, o = jnp.split(gates, 4, axis=-1)\n        i = jax.nn.sigmoid(i)\n        f = jax.nn.sigmoid(f)\n        o = jax.nn.sigmoid(o)\n        g = jnp.tanh(g)\n        new_c = f * c + i * g\n        new_h = o * jnp.tanh(new_c)\n        return (new_h, new_c), new_h\n\nclass LSTMStack(nn.Module):\n    input_size: int\n    hidden_size: int\n    num_layers: int\n    dropout: float = 0.0\n\n    @nn.compact\n    def __call__(self, x, h0=None, c0=None, train: bool = False):\n        # x: (batch, seq, input_size)\n        batch_size = x.shape[0]\n        seq_len = x.shape[1]\n        hs = []\n        cs = []\n        outs = x\n        new_hs = []\n        new_cs = []\n        for layer in range(self.num_layers):\n            cell = LSTMCell(self.hidden_size)\n            # Initial hidden/cell state\n            if h0 is not None:\n                h = h0[layer]\n            else:\n                h = jnp.zeros((batch_size, self.hidden_size), dtype=outs.dtype)\n            if c0 is not None:\n                c = c0[layer]\n            else:\n                c = jnp.zeros((batch_size, self.hidden_size), dtype=outs.dtype)\n            carry = (h, c)\n            # Scan over sequence\n            carry, y = nn.scan(\n                cell,\n                variable_broadcast=\"params\",\n                split_rngs={\"params\": False},\n                in_axes=1,\n                out_axes=1,\n                name=f\"lstm_layer_{layer}\"\n            )(carry, outs)\n            outs = y\n            if self.dropout > 0.0 and layer < self.num_layers - 1:\n                outs = nn.Dropout(rate=self.dropout, deterministic=not train)(outs)\n            new_hs.append(carry[0])\n            new_cs.append(carry[1])\n        # outs: (batch, seq, hidden_size)\n        h_n = jnp.stack(new_hs, axis=0)  # (num_layers, batch, hidden_size)\n        c_n = jnp.stack(new_cs, axis=0)  # (num_layers, batch, hidden_size)\n        return outs, (h_n, c_n)\n\nclass Model(nn.Module):\n    input_size: int\n    hidden_size: int\n    num_layers: int\n    output_size: int\n    dropout: float = 0.0\n\n    @nn.compact\n    def __call__(self, x, h0=None, c0=None, train: bool = False):\n        # x: (batch, seq, input_size)\n        lstm = LSTMStack(\n            input_size=self.input_size,\n            hidden_size=self.hidden_size,\n            num_layers=self.num_layers,\n            dropout=self.dropout\n        )\n        out, (h_n, c_n) = lstm(x, h0, c0, train=train)\n        # Take last time step\n        out_last = out[:, -1, :]  # (batch, hidden_size)\n        out_proj = nn.Dense(self.output_size)(out_last)\n        return out_proj\n\n# === Test configuration ===\nbatch_size = 10\nsequence_length = 512\ninput_size = 128\nhidden_size = 256\nnum_layers = 6\noutput_size = 10\ndropout = 0.0\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, sequence_length, input_size).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, num_layers, output_size, dropout]"}
{"kb_id": "kb_level_3_0028", "level": "level_3", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.62230215827337, "success": true, "pytorch_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/pytorch_samples/kb_level_3_0028.py", "jax_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/jax_outputs/kb_level_3_0028_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.0):\n        \"\"\"\n        Initialize the LSTM model.\n\n        :param input_size: The number of expected features in the input `x`\n        :param hidden_size: The number of features in the hidden state `h`\n        :param num_layers: Number of recurrent layers\n        :param output_size: The number of output features\n        :param dropout: If non-zero, introduces a Dropout layer on the outputs of each LSTM layer except the last layer, with dropout probability equal to `dropout`\n        \"\"\"\n        super(Model, self).__init__()\n        # Initialize hidden state with random values\n        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout, bidirectional=False)\n        self.fc = nn.Linear(hidden_size, output_size)\n    \n    def forward(self, x,h0,c0):\n        \"\"\"\n        Forward pass through the LSTM model.\n\n        :param x: The input tensor, shape (batch_size, sequence_length, input_size)\n        :return: The output tensor, shape (batch_size, sequence_length, output_size)\n        \"\"\"\n        \n        # Forward propagate LSTM\n        out, state = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n        \n        # Decode the hidden state of the last time step\n        out = self.fc(out[:, -1, :])  # out: tensor of shape (batch_size, output_size)\n        \n        return state[0]\n\n# Test code\nbatch_size = 10\nsequence_length = 512\ninput_size = 128\nhidden_size = 256\nnum_layers = 6\noutput_size = 10\ndropout = 0.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, sequence_length, input_size),torch.rand((num_layers, batch_size, hidden_size)),torch.rand((num_layers, batch_size, hidden_size))]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, num_layers, output_size, dropout]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    input_size: int\n    hidden_size: int\n    num_layers: int\n    output_size: int\n    dropout: float = 0.0\n\n    @nn.compact\n    def __call__(self, x, h0, c0):\n        \"\"\"\n        Forward pass through the LSTM model.\n\n        :param x: The input tensor, shape (batch_size, sequence_length, input_size)\n        :param h0: Initial hidden state, shape (num_layers, batch_size, hidden_size)\n        :param c0: Initial cell state, shape (num_layers, batch_size, hidden_size)\n        :return: The output hidden state, shape (num_layers, batch_size, hidden_size)\n        \"\"\"\n        batch_size, seq_len, _ = x.shape\n\n        # Flax's LSTMCell is single-layer, so we stack them manually\n        class StackedLSTM(nn.Module):\n            hidden_size: int\n            num_layers: int\n            dropout: float\n\n            @nn.compact\n            def __call__(self, x, h0, c0, train=False):\n                outputs = []\n                h_n = []\n                c_n = []\n                seq_len = x.shape[1]\n                input_ = x\n                for layer in range(self.num_layers):\n                    lstm_cell = nn.scan(\n                        nn.LSTMCell,\n                        variable_broadcast=\"params\",\n                        split_rngs={\"params\": False},\n                        in_axes=1,\n                        out_axes=1,\n                        name=f\"lstm_layer_{layer}\"\n                    )(name=f\"cell_{layer}\", features=self.hidden_size)\n                    h, c = h0[layer], c0[layer]\n                    out, (h_last, c_last) = lstm_cell(input_, (h, c))\n                    if self.dropout > 0.0 and layer < self.num_layers - 1:\n                        out = nn.Dropout(rate=self.dropout, deterministic=not train)(out)\n                    input_ = out\n                    h_n.append(h_last)\n                    c_n.append(c_last)\n                return input_, (jnp.stack(h_n, axis=0), jnp.stack(c_n, axis=0))\n\n        lstm = StackedLSTM(self.hidden_size, self.num_layers, self.dropout)\n        out, (hn, cn) = lstm(x, h0, c0, train=False)\n        # out: (batch, seq, hidden)\n        out_last = out[:, -1, :]  # (batch, hidden)\n        fc = nn.Dense(self.output_size)\n        out_fc = fc(out_last)  # (batch, output_size)\n        return hn\n\n# Test code\nbatch_size = 10\nsequence_length = 512\ninput_size = 128\nhidden_size = 256\nnum_layers = 6\noutput_size = 10\ndropout = 0.0\n\ndef get_inputs():\n    key = jax.random.PRNGKey(0)\n    x = jax.random.uniform(key, (batch_size, sequence_length, input_size))\n    h0 = jax.random.uniform(key, (num_layers, batch_size, hidden_size))\n    c0 = jax.random.uniform(key, (num_layers, batch_size, hidden_size))\n    return [x, h0, c0]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, num_layers, output_size, dropout]"}
{"kb_id": "kb_level_3_0029", "level": "level_3", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/pytorch_samples/kb_level_3_0029.py", "jax_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/jax_outputs/kb_level_3_0029_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.0):\n        \"\"\"\n        Initialize the LSTM model.\n\n        :param input_size: The number of expected features in the input `x`\n        :param hidden_size: The number of features in the hidden state `h`\n        :param num_layers: Number of recurrent layers\n        :param output_size: The number of output features\n        :param dropout: If non-zero, introduces a Dropout layer on the outputs of each LSTM layer except the last layer, with dropout probability equal to `dropout`\n        \"\"\"\n        super(Model, self).__init__()\n        # Initialize hidden state with random values\n        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout, bidirectional=False)\n        self.fc = nn.Linear(hidden_size, output_size)\n    \n    def forward(self, x, h0, c0):\n        \"\"\"\n        Forward pass through the LSTM model.\n\n        :param x: The input tensor, shape (batch_size, sequence_length, input_size)\n        :return: The output tensor, shape (batch_size, sequence_length, output_size)\n        \"\"\"\n        \n        # Forward propagate LSTM\n        out, state = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n        \n        # Decode the hidden state of the last time step\n        out = self.fc(out[:, -1, :])  # out: tensor of shape (batch_size, output_size)\n        \n        return state[1]\n\n# Test code\nbatch_size = 10\nsequence_length = 512\ninput_size = 128\nhidden_size = 256\nnum_layers = 6\noutput_size = 10\ndropout = 0.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, sequence_length, input_size),torch.rand((num_layers, batch_size, hidden_size)),torch.rand((num_layers, batch_size, hidden_size))]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, num_layers, output_size, dropout]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    input_size: int\n    hidden_size: int\n    num_layers: int\n    output_size: int\n    dropout: float = 0.0\n\n    @nn.compact\n    def __call__(self, x, h0, c0):\n        \"\"\"\n        Forward pass through the LSTM model.\n\n        :param x: The input tensor, shape (batch_size, sequence_length, input_size)\n        :param h0: Initial hidden state, shape (num_layers, batch_size, hidden_size)\n        :param c0: Initial cell state, shape (num_layers, batch_size, hidden_size)\n        :return: The cell state after processing, shape (num_layers, batch_size, hidden_size)\n        \"\"\"\n        batch_size, seq_len, _ = x.shape\n\n        def lstm_cell():\n            return nn.OptimizedLSTMCell()\n\n        # Stack LSTM layers\n        cells = [lstm_cell() for _ in range(self.num_layers)]\n\n        # Prepare initial states\n        h = [h0[i] for i in range(self.num_layers)]\n        c = [c0[i] for i in range(self.num_layers)]\n\n        def step_fn(carry, x_t):\n            h_list, c_list = carry\n            new_h_list = []\n            new_c_list = []\n            input_t = x_t\n            for i, cell in enumerate(cells):\n                h_i, c_i = h_list[i], c_list[i]\n                (new_c_i, new_h_i) = cell((c_i, h_i), input_t)\n                input_t = new_h_i\n                if self.dropout > 0.0 and i < self.num_layers - 1:\n                    input_t = nn.Dropout(rate=self.dropout, deterministic=False)(input_t)\n                new_h_list.append(new_h_i)\n                new_c_list.append(new_c_i)\n            return (new_h_list, new_c_list), input_t\n\n        # Scan over sequence\n        (final_h, final_c), outputs = jax.lax.scan(\n            step_fn,\n            (h, c),\n            jnp.swapaxes(x, 0, 1)  # (seq_len, batch, input_size)\n        )\n        # outputs: (seq_len, batch, hidden_size)\n        outputs = jnp.swapaxes(outputs, 0, 1)  # (batch, seq_len, hidden_size)\n\n        # Decode the hidden state of the last time step\n        out = outputs[:, -1, :]  # (batch, hidden_size)\n        out = nn.Dense(self.output_size)(out)  # (batch, output_size)\n\n        # Return the final cell state (as in the PyTorch code)\n        final_c = jnp.stack(final_c, axis=0)  # (num_layers, batch, hidden_size)\n        return final_c\n\n# Test code\nbatch_size = 10\nsequence_length = 512\ninput_size = 128\nhidden_size = 256\nnum_layers = 6\noutput_size = 10\ndropout = 0.0\n\ndef get_inputs():\n    key = jax.random.PRNGKey(0)\n    x = jax.random.uniform(key, (batch_size, sequence_length, input_size))\n    h0 = jax.random.uniform(key, (num_layers, batch_size, hidden_size))\n    c0 = jax.random.uniform(key, (num_layers, batch_size, hidden_size))\n    return [x, h0, c0]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, num_layers, output_size, dropout]"}
{"kb_id": "kb_level_3_0030", "level": "level_3", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.74774774774775, "success": true, "pytorch_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/pytorch_samples/kb_level_3_0030.py", "jax_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/jax_outputs/kb_level_3_0030_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.0):\n        \"\"\"\n        Initialize the LSTM model.\n\n        :param input_size: The number of expected features in the input `x`\n        :param hidden_size: The number of features in the hidden state `h`\n        :param num_layers: Number of recurrent layers\n        :param output_size: The number of output features\n        :param dropout: If non-zero, introduces a Dropout layer on the outputs of each LSTM layer except the last layer, with dropout probability equal to `dropout`\n        \"\"\"\n        super(Model, self).__init__()\n        # Initialize hidden state with random values\n        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout, bidirectional=True)\n        self.fc = nn.Linear(hidden_size * 2, output_size)\n    \n    def forward(self, x,h0,c0):\n        \"\"\"\n        Forward pass through the LSTM model.\n\n        :param x: The input tensor, shape (batch_size, sequence_length, input_size)\n        :return: The output tensor, shape (batch_size, sequence_length, output_size)\n        \"\"\"\n        # Forward propagate LSTM\n        out, hn = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n        \n        # Decode the hidden state of the last time step\n        out = self.fc(out[:, -1, :])  # out: tensor of shape (batch_size, output_size)\n        \n        return out\n\n# Test code\nbatch_size = 10\nsequence_length = 512\ninput_size = 128\nhidden_size = 256\nnum_layers = 6\noutput_size = 10\ndropout = 0.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, sequence_length, input_size),torch.rand((num_layers*2, batch_size, hidden_size)),torch.rand((num_layers*2, batch_size, hidden_size))]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, num_layers, output_size, dropout]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    input_size: int\n    hidden_size: int\n    num_layers: int\n    output_size: int\n    dropout: float = 0.0\n\n    @nn.compact\n    def __call__(self, x, h0, c0):\n        \"\"\"\n        Forward pass through the LSTM model.\n\n        :param x: The input tensor, shape (batch_size, sequence_length, input_size)\n        :param h0: Initial hidden state, shape (num_layers*2, batch_size, hidden_size)\n        :param c0: Initial cell state, shape (num_layers*2, batch_size, hidden_size)\n        :return: The output tensor, shape (batch_size, output_size)\n        \"\"\"\n        batch_size, seq_len, _ = x.shape\n        num_directions = 2  # bidirectional\n\n        # Flax's LSTMCell is unidirectional; we implement multi-layer, bidirectional LSTM manually\n        def lstm_layer(inputs, carry, cell_fw, cell_bw, dropout_rate, train):\n            # Forward direction\n            def scan_fw(carry, x):\n                carry, y = cell_fw(carry, x)\n                if dropout_rate > 0.0 and train:\n                    y = nn.Dropout(rate=dropout_rate)(y, deterministic=not train)\n                return carry, y\n            _, ys_fw = nn.scan(scan_fw, variable_broadcast=\"params\", split_rngs={\"params\": False, \"dropout\": True}, in_axes=1, out_axes=1, length=seq_len)(carry[0], inputs)\n            # Backward direction\n            def scan_bw(carry, x):\n                carry, y = cell_bw(carry, x)\n                if dropout_rate > 0.0 and train:\n                    y = nn.Dropout(rate=dropout_rate)(y, deterministic=not train)\n                return carry, y\n            _, ys_bw = nn.scan(scan_bw, variable_broadcast=\"params\", split_rngs={\"params\": False, \"dropout\": True}, in_axes=1, out_axes=1, length=seq_len)(carry[1], jnp.flip(inputs, axis=1))\n            ys_bw = jnp.flip(ys_bw, axis=1)\n            # Concatenate outputs\n            ys = jnp.concatenate([ys_fw, ys_bw], axis=-1)\n            return ys, (carry[0], carry[1])\n\n        # Prepare initial states for all layers and directions\n        h = h0\n        c = c0\n        out = x\n        for layer in range(self.num_layers):\n            # Each layer has forward and backward LSTMCell\n            cell_fw = nn.LSTMCell(name=f\"lstm_fw_{layer}\", hidden_size=self.hidden_size)\n            cell_bw = nn.LSTMCell(name=f\"lstm_bw_{layer}\", hidden_size=self.hidden_size)\n            # Get initial state for this layer and direction\n            h_fw = (h[layer * num_directions + 0], c[layer * num_directions + 0])\n            h_bw = (h[layer * num_directions + 1], c[layer * num_directions + 1])\n            # Dropout only on all but last layer\n            dropout_rate = self.dropout if (layer < self.num_layers - 1) else 0.0\n            out, (h_fw_last, h_bw_last) = lstm_layer(out, (h_fw, h_bw), cell_fw, cell_bw, dropout_rate, self.is_mutable_collection('dropout'))\n            # For next layer, out is (batch, seq, hidden*2)\n        # out: (batch, seq, hidden*2)\n        # Take last time step\n        out_last = out[:, -1, :]\n        out = nn.Dense(self.output_size)(out_last)\n        return out\n\n# Test code\nbatch_size = 10\nsequence_length = 512\ninput_size = 128\nhidden_size = 256\nnum_layers = 6\noutput_size = 10\ndropout = 0.0\n\ndef get_inputs():\n    key = jax.random.PRNGKey(0)\n    x = jax.random.uniform(key, (batch_size, sequence_length, input_size))\n    h0 = jax.random.uniform(key, (num_layers*2, batch_size, hidden_size))\n    c0 = jax.random.uniform(key, (num_layers*2, batch_size, hidden_size))\n    return [x, h0, c0]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, num_layers, output_size, dropout]"}
{"kb_id": "kb_level_3_0031", "level": "level_3", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/pytorch_samples/kb_level_3_0031.py", "jax_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/jax_outputs/kb_level_3_0031_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers=3, bias=True, batch_first=False):\n        \"\"\"\n        :param input_size: The number of expected features in the input x\n        :param hidden_size: The number of features in the hidden state h\n        :param num_layers: Number of recurrent layers (default: 1)\n        :param bias: If False, then the layer does not use bias weights b_ih and b_hh (default: True)\n        :param batch_first: If True, then the input and output tensors are provided as (batch, seq, feature) (default: False)\n        \"\"\"\n        super(Model, self).__init__()\n        \n        self.gru = nn.GRU(input_size, hidden_size, num_layers, bias, batch_first, dropout=0, bidirectional=False)\n    \n    def forward(self, x,h0):\n        \"\"\"\n        :param x: The input tensor, shape (seq_len, batch_size, input_size) if batch_first=False, otherwise (batch_size, seq_len, input_size)\n        :param h_0: The initial hidden state for the input sequence, shape (num_layers * num_directions, batch_size, hidden_size) (default: None)\n        :return: output, h_n\n            - output: The output features (h_t) from the last layer of the GRU, for each t, shape (seq_len, batch_size, num_directions * hidden_size) if batch_first=False, otherwise (batch_size, seq_len, num_directions * hidden_size)\n            - h_n: The hidden state for t = seq_len, shape (num_layers * num_directions, batch_size, hidden_size)\n        \"\"\"\n        output, h_n = self.gru(x, h0)\n        return output\n\n# Test code\nbatch_size = 10\nseq_len = 512\ninput_size = 128\nhidden_size = 256\nnum_layers = 6\n\ndef get_inputs():\n    return [torch.rand(seq_len, batch_size, input_size),torch.rand((num_layers, batch_size, hidden_size))]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, num_layers]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    input_size: int\n    hidden_size: int\n    num_layers: int = 3\n    bias: bool = True\n    batch_first: bool = False\n\n    @nn.compact\n    def __call__(self, x, h0):\n        \"\"\"\n        :param x: The input tensor, shape (seq_len, batch_size, input_size) if batch_first=False, otherwise (batch_size, seq_len, input_size)\n        :param h0: The initial hidden state for the input sequence, shape (num_layers, batch_size, hidden_size)\n        :return: output, h_n\n            - output: The output features (h_t) from the last layer of the GRU, for each t, shape (seq_len, batch_size, hidden_size) if batch_first=False, otherwise (batch_size, seq_len, hidden_size)\n            - h_n: The hidden state for t = seq_len, shape (num_layers, batch_size, hidden_size)\n        \"\"\"\n        # If batch_first, swap axes to (seq_len, batch_size, input_size)\n        if self.batch_first:\n            x = jnp.swapaxes(x, 0, 1)  # (seq_len, batch_size, input_size)\n\n        batch_size = x.shape[1]\n        seq_len = x.shape[0]\n\n        # Define GRUCells for each layer\n        cells = [nn.GRUCell(name=f\"gru_cell_{i}\", hidden_size=self.hidden_size, use_bias=self.bias) for i in range(self.num_layers)]\n\n        def step_fn(carry, x_t):\n            h_prev = carry  # (num_layers, batch_size, hidden_size)\n            h_next = []\n            input_t = x_t\n            for i, cell in enumerate(cells):\n                h_i, _ = cell(h_prev[i], input_t)\n                h_next.append(h_i)\n                input_t = h_i\n            h_next = jnp.stack(h_next, axis=0)\n            return h_next, input_t  # carry, output\n\n        # Scan over sequence\n        h_init = h0\n        outputs, final_h = jax.lax.scan(step_fn, h_init, x)\n        # outputs: (seq_len, batch_size, hidden_size)\n        # final_h: (num_layers, batch_size, hidden_size)\n\n        if self.batch_first:\n            outputs = jnp.swapaxes(outputs, 0, 1)  # (batch_size, seq_len, hidden_size)\n\n        return outputs, final_h\n\n# Test code\nbatch_size = 10\nseq_len = 512\ninput_size = 128\nhidden_size = 256\nnum_layers = 6\n\ndef get_inputs():\n    x = jax.random.uniform(jax.random.PRNGKey(0), (seq_len, batch_size, input_size))\n    h0 = jax.random.uniform(jax.random.PRNGKey(1), (num_layers, batch_size, hidden_size))\n    return [x, h0]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, num_layers]"}
{"kb_id": "kb_level_3_0032", "level": "level_3", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/pytorch_samples/kb_level_3_0032.py", "jax_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/jax_outputs/kb_level_3_0032_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, input_size, hidden_layer_sizes, output_size):\n        \"\"\"\n        :param input_size: The number of input features\n        :param hidden_layer_sizes: A list of ints containing the sizes of each hidden layer\n        :param output_size: The number of output features\n        \"\"\"\n        super(Model, self).__init__()\n        \n        layers = []\n        current_input_size = input_size\n        \n        for hidden_size in hidden_layer_sizes:\n            layers.append(nn.Linear(current_input_size, hidden_size))\n            layers.append(nn.ReLU())\n            current_input_size = hidden_size\n        \n        layers.append(nn.Linear(current_input_size, output_size))\n        \n        self.network = nn.Sequential(*layers)\n    \n    def forward(self, x):\n        \"\"\"\n        :param x: The input tensor, shape (batch_size, input_size)\n        :return: The output tensor, shape (batch_size, output_size)\n        \"\"\"\n        return self.network(x)\n\n# Test code\nbatch_size = 1024\ninput_size = 8192\nhidden_layer_sizes = [1024] * 16  # deep network with wider layers\noutput_size = 8192\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_layer_sizes, output_size]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    input_size: int\n    hidden_layer_sizes: list\n    output_size: int\n\n    @nn.compact\n    def __call__(self, x):\n        current_input_size = self.input_size\n        for hidden_size in self.hidden_layer_sizes:\n            x = nn.Dense(hidden_size)(x)\n            x = nn.relu(x)\n            current_input_size = hidden_size\n        x = nn.Dense(self.output_size)(x)\n        return x\n\n# Test code\nbatch_size = 1024\ninput_size = 8192\nhidden_layer_sizes = [1024] * 16  # deep network with wider layers\noutput_size = 8192\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_layer_sizes, output_size]"}
{"kb_id": "kb_level_3_0033", "level": "level_3", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/pytorch_samples/kb_level_3_0033.py", "jax_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/jax_outputs/kb_level_3_0033_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers=3, bias=True, batch_first=False):\n        \"\"\"\n        :param input_size: The number of expected features in the input x\n        :param hidden_size: The number of features in the hidden state h\n        :param num_layers: Number of recurrent layers (default: 1)\n        :param bias: If False, then the layer does not use bias weights b_ih and b_hh (default: True)\n        :param batch_first: If True, then the input and output tensors are provided as (batch, seq, feature) (default: False)\n        \"\"\"\n        super(Model, self).__init__()\n        \n        self.gru = nn.GRU(input_size, hidden_size, num_layers, bias, batch_first, dropout=0, bidirectional=False)\n    \n    def forward(self, x,h0):\n        \"\"\"\n        :param x: The input tensor, shape (seq_len, batch_size, input_size) if batch_first=False, otherwise (batch_size, seq_len, input_size)\n        :param h_0: The initial hidden state for the input sequence, shape (num_layers * num_directions, batch_size, hidden_size) (default: None)\n        :return: output, h_n\n            - output: The output features (h_t) from the last layer of the GRU, for each t, shape (seq_len, batch_size, num_directions * hidden_size) if batch_first=False, otherwise (batch_size, seq_len, num_directions * hidden_size)\n            - h_n: The hidden state for t = seq_len, shape (num_layers * num_directions, batch_size, hidden_size)\n        \"\"\"\n        output, h_n = self.gru(x, h0)\n        return h_n\n\n# Test code\nbatch_size = 10\nseq_len = 512\ninput_size = 128\nhidden_size = 256\nnum_layers = 6\n\ndef get_inputs():\n    return [torch.rand(seq_len, batch_size, input_size),torch.rand((num_layers, batch_size, hidden_size))]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, num_layers]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    input_size: int\n    hidden_size: int\n    num_layers: int = 3\n    bias: bool = True\n    batch_first: bool = False\n\n    @nn.compact\n    def __call__(self, x, h0):\n        \"\"\"\n        :param x: The input tensor, shape (seq_len, batch_size, input_size) if batch_first=False, otherwise (batch_size, seq_len, input_size)\n        :param h0: The initial hidden state for the input sequence, shape (num_layers, batch_size, hidden_size)\n        :return: h_n: The hidden state for t = seq_len, shape (num_layers, batch_size, hidden_size)\n        \"\"\"\n        # Flax's nn.GRUCell is a cell, not a full GRU layer, so we need to unroll manually\n        # We'll implement a multi-layer GRU stack\n\n        def gru_step(carry, x_t):\n            h_prev = carry  # (num_layers, batch_size, hidden_size)\n            h_next = []\n            input_t = x_t\n            for layer in range(self.num_layers):\n                gru_cell = nn.GRUCell(\n                    name=f\"gru_cell_{layer}\",\n                    use_bias=self.bias,\n                )\n                h, new_state = gru_cell(input_t, h_prev[layer])\n                h_next.append(new_state)\n                input_t = h  # output of this layer is input to next\n            h_next = jnp.stack(h_next, axis=0)\n            return h_next, input_t  # carry, y_t\n\n        # Prepare input shape\n        if self.batch_first:\n            # (batch, seq, feature) -> (seq, batch, feature)\n            x = jnp.transpose(x, (1, 0, 2))\n        seq_len, batch_size, _ = x.shape\n\n        # h0: (num_layers, batch_size, hidden_size)\n        carry = h0\n\n        outputs = []\n        for t in range(seq_len):\n            carry, y_t = gru_step(carry, x[t])\n            outputs.append(y_t)\n        outputs = jnp.stack(outputs, axis=0)  # (seq_len, batch_size, hidden_size)\n\n        # For compatibility, output shape should match PyTorch's GRU output\n        # output: (seq_len, batch_size, hidden_size)\n        # h_n: (num_layers, batch_size, hidden_size)\n        if self.batch_first:\n            outputs = jnp.transpose(outputs, (1, 0, 2))  # (batch, seq, hidden)\n\n        h_n = carry\n        return h_n\n\n# Test code\nbatch_size = 10\nseq_len = 512\ninput_size = 128\nhidden_size = 256\nnum_layers = 6\n\ndef get_inputs():\n    x = jax.random.uniform(jax.random.PRNGKey(0), (seq_len, batch_size, input_size))\n    h0 = jax.random.uniform(jax.random.PRNGKey(1), (num_layers, batch_size, hidden_size))\n    return [x, h0]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, num_layers]"}
{"kb_id": "kb_level_3_0034", "level": "level_3", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/pytorch_samples/kb_level_3_0034.py", "jax_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/jax_outputs/kb_level_3_0034_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers=3, bias=True, batch_first=False):\n        \"\"\"\n        :param input_size: The number of expected features in the input x\n        :param hidden_size: The number of features in the hidden state h\n        :param num_layers: Number of recurrent layers (default: 1)\n        :param bias: If False, then the layer does not use bias weights b_ih and b_hh (default: True)\n        :param batch_first: If True, then the input and output tensors are provided as (batch, seq, feature) (default: False)\n        \"\"\"\n        super(Model, self).__init__()\n        \n        self.gru = nn.GRU(input_size, hidden_size, num_layers, bias, batch_first, dropout=0, bidirectional=True)\n        self.h0 = torch.randn((num_layers * 2, batch_size, hidden_size))\n    \n    def forward(self, x,h0):\n        \"\"\"\n        :param x: The input tensor, shape (seq_len, batch_size, input_size) if batch_first=False, otherwise (batch_size, seq_len, input_size)\n        :param h_0: The initial hidden state for the input sequence, shape (num_layers * num_directions, batch_size, hidden_size) (default: None)\n        :return: output, h_n\n            - output: The output features (h_t) from the last layer of the GRU, for each t, shape (seq_len, batch_size, num_directions * hidden_size) if batch_first=False, otherwise (batch_size, seq_len, num_directions * hidden_size)\n            - h_n: The hidden state for t = seq_len, shape (num_layers * num_directions, batch_size, hidden_size)\n        \"\"\"\n        output, h_n = self.gru(x, h0)\n        return output\n\n# Test code\nbatch_size = 10\nseq_len = 512\ninput_size = 128\nhidden_size = 256\nnum_layers = 6\n\ndef get_inputs():\n    return [torch.rand(seq_len, batch_size, input_size),torch.rand((num_layers*2, batch_size, hidden_size))]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, num_layers]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass GRUStack(nn.Module):\n    input_size: int\n    hidden_size: int\n    num_layers: int = 3\n    bias: bool = True\n    batch_first: bool = False\n\n    @nn.compact\n    def __call__(self, x, h0):\n        # x: (seq_len, batch_size, input_size) or (batch_size, seq_len, input_size)\n        # h0: (num_layers * 2, batch_size, hidden_size)\n        num_directions = 2  # bidirectional\n        batch_dim = 0 if not self.batch_first else 1\n\n        # Prepare input shape\n        if self.batch_first:\n            batch_size, seq_len, _ = x.shape\n            x = jnp.transpose(x, (1, 0, 2))  # (seq_len, batch_size, input_size)\n        else:\n            seq_len, batch_size, _ = x.shape\n\n        # Split h0 for each direction and layer\n        h0 = h0.reshape(self.num_layers, num_directions, batch_size, self.hidden_size)\n\n        outputs = []\n        h_n = []\n\n        for layer in range(self.num_layers):\n            layer_outs = []\n            for direction in range(num_directions):\n                # Each direction has its own GRUCell\n                cell = nn.GRUCell(name=f\"gru_cell_l{layer}_d{direction}\")\n                hx = h0[layer, direction]\n                if direction == 0:\n                    # forward\n                    seq = x\n                else:\n                    # backward\n                    seq = jnp.flip(x, axis=0)\n                outs = []\n                for t in range(seq_len):\n                    hx, _ = cell(hx, seq[t])\n                    outs.append(hx)\n                outs = jnp.stack(outs, axis=0)  # (seq_len, batch_size, hidden_size)\n                if direction == 1:\n                    outs = jnp.flip(outs, axis=0)\n                layer_outs.append(outs)\n                h_n.append(hx)\n            # Concatenate directions\n            x = jnp.concatenate(layer_outs, axis=-1)  # (seq_len, batch_size, hidden_size*2)\n            outputs.append(x)\n        output = x  # output from last layer\n        h_n = jnp.stack(h_n, axis=0)  # (num_layers*2, batch_size, hidden_size)\n        if self.batch_first:\n            output = jnp.transpose(output, (1, 0, 2))  # (batch_size, seq_len, hidden_size*2)\n        return output, h_n\n\nclass Model(nn.Module):\n    input_size: int\n    hidden_size: int\n    num_layers: int = 3\n    bias: bool = True\n    batch_first: bool = False\n\n    @nn.compact\n    def __call__(self, x, h0):\n        gru = GRUStack(\n            input_size=self.input_size,\n            hidden_size=self.hidden_size,\n            num_layers=self.num_layers,\n            bias=self.bias,\n            batch_first=self.batch_first,\n        )\n        output, h_n = gru(x, h0)\n        return output\n\n# Test code\nbatch_size = 10\nseq_len = 512\ninput_size = 128\nhidden_size = 256\nnum_layers = 6\n\ndef get_inputs():\n    # (seq_len, batch_size, input_size), (num_layers*2, batch_size, hidden_size)\n    x = jax.random.uniform(jax.random.PRNGKey(0), (seq_len, batch_size, input_size))\n    h0 = jax.random.uniform(jax.random.PRNGKey(1), (num_layers*2, batch_size, hidden_size))\n    return [x, h0]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, num_layers]"}
{"kb_id": "kb_level_3_0035", "level": "level_3", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/pytorch_samples/kb_level_3_0035.py", "jax_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/jax_outputs/kb_level_3_0035_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers=3, bias=True, batch_first=False):\n        \"\"\"\n        :param input_size: The number of expected features in the input x\n        :param hidden_size: The number of features in the hidden state h\n        :param num_layers: Number of recurrent layers (default: 1)\n        :param bias: If False, then the layer does not use bias weights b_ih and b_hh (default: True)\n        :param batch_first: If True, then the input and output tensors are provided as (batch, seq, feature) (default: False)\n        \"\"\"\n        super(Model, self).__init__()\n        \n        self.gru = nn.GRU(input_size, hidden_size, num_layers, bias, batch_first, dropout=0, bidirectional=True)\n    \n    def forward(self, x,h0):\n        \"\"\"\n        :param x: The input tensor, shape (seq_len, batch_size, input_size) if batch_first=False, otherwise (batch_size, seq_len, input_size)\n        :param h_0: The initial hidden state for the input sequence, shape (num_layers * num_directions, batch_size, hidden_size) (default: None)\n        :return: output, h_n\n            - output: The output features (h_t) from the last layer of the GRU, for each t, shape (seq_len, batch_size, num_directions * hidden_size) if batch_first=False, otherwise (batch_size, seq_len, num_directions * hidden_size)\n            - h_n: The hidden state for t = seq_len, shape (num_layers * num_directions, batch_size, hidden_size)\n        \"\"\"\n        output, h_n = self.gru(x, h0)\n        return h_n\n\n# Test code\nbatch_size = 10\nseq_len = 512\ninput_size = 128\nhidden_size = 256\nnum_layers = 6\n\ndef get_inputs():\n    return [torch.rand(seq_len, batch_size, input_size),torch.rand((num_layers*2, batch_size, hidden_size))]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, num_layers]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    input_size: int\n    hidden_size: int\n    num_layers: int = 3\n    bias: bool = True\n    batch_first: bool = False\n\n    @nn.compact\n    def __call__(self, x, h0):\n        \"\"\"\n        :param x: The input tensor, shape (seq_len, batch_size, input_size) if batch_first=False, otherwise (batch_size, seq_len, input_size)\n        :param h0: The initial hidden state for the input sequence, shape (num_layers * num_directions, batch_size, hidden_size)\n        :return: h_n\n        \"\"\"\n        # Bidirectional GRU: num_directions = 2\n        num_directions = 2\n        # Flax's nn.GRUCell is unidirectional, so we need to implement bidirectional stacking manually\n        def gru_layer(inputs, h, fw_cell, bw_cell):\n            # inputs: (seq_len, batch_size, input_size)\n            # h: (num_directions, batch_size, hidden_size)\n            # Forward\n            def fw_scan(carry, x):\n                h = fw_cell(carry, x)\n                return h, h\n            fw_init = h[0]\n            fw_outputs, fw_states = jax.lax.scan(fw_scan, fw_init, inputs)\n            # Backward\n            def bw_scan(carry, x):\n                h = bw_cell(carry, x)\n                return h, h\n            bw_init = h[1]\n            bw_inputs = jnp.flip(inputs, axis=0)\n            bw_outputs, bw_states = jax.lax.scan(bw_scan, bw_init, bw_inputs)\n            bw_outputs = jnp.flip(bw_outputs, axis=0)\n            # Concatenate outputs\n            outputs = jnp.concatenate([fw_outputs, bw_outputs], axis=-1)\n            hn = jnp.stack([fw_outputs[-1], bw_outputs[0]], axis=0)\n            return outputs, hn\n\n        # Prepare input\n        if self.batch_first:\n            # (batch, seq, feat) -> (seq, batch, feat)\n            x = jnp.transpose(x, (1, 0, 2))\n\n        seq_len, batch_size, _ = x.shape\n\n        # h0: (num_layers * num_directions, batch_size, hidden_size)\n        h0 = h0.reshape((self.num_layers, num_directions, batch_size, self.hidden_size))\n\n        outputs = x\n        hn_list = []\n        for layer in range(self.num_layers):\n            fw_cell = nn.GRUCell(name=f'fw_gru_{layer}', use_bias=self.bias)\n            bw_cell = nn.GRUCell(name=f'bw_gru_{layer}', use_bias=self.bias)\n            h_layer = h0[layer]  # (2, batch, hidden_size)\n            outputs, hn = gru_layer(outputs, h_layer, fw_cell, bw_cell)\n            # For next layer, outputs shape: (seq_len, batch_size, hidden_size*2)\n            # For next layer, split outputs for each direction\n            # We'll split outputs for each direction for the next layer\n            # But GRU expects input_size, so we keep outputs as is\n            hn_list.append(hn)\n        # hn_list: list of (2, batch, hidden_size), len=num_layers\n        h_n = jnp.concatenate(hn_list, axis=0)  # (num_layers*2, batch, hidden_size)\n\n        if self.batch_first:\n            # outputs: (seq, batch, hidden*2) -> (batch, seq, hidden*2)\n            outputs = jnp.transpose(outputs, (1, 0, 2))\n\n        return h_n\n\n# Test code\nbatch_size = 10\nseq_len = 512\ninput_size = 128\nhidden_size = 256\nnum_layers = 6\n\ndef get_inputs():\n    x = jax.random.uniform(jax.random.PRNGKey(0), (seq_len, batch_size, input_size))\n    h0 = jax.random.uniform(jax.random.PRNGKey(1), (num_layers*2, batch_size, hidden_size))\n    return [x, h0]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, num_layers]"}
{"kb_id": "kb_level_3_0036", "level": "level_3", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/pytorch_samples/kb_level_3_0036.py", "jax_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/jax_outputs/kb_level_3_0036_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\n\n# From https://github.com/karpathy/minGPT/blob/master/mingpt/model.py\n\nclass Model(nn.Module):\n    \"\"\"\n    A vanilla multi-head masked self-attention layer with a projection at the end.\n    It is possible to use torch.nn.MultiheadAttention here but I am including an\n    explicit implementation here to show that there is nothing too scary here.\n    \"\"\"\n\n    def __init__(self, n_embd, n_head, attn_pdrop, resid_pdrop, max_seqlen):\n        super().__init__()\n        assert n_embd % n_head == 0\n        # key, query, value projections for all heads, but in a batch\n        self.c_attn = nn.Linear(n_embd, 3 * n_embd)\n        # output projection\n        self.c_proj = nn.Linear(n_embd, n_embd)\n        # regularization\n        self.attn_dropout = nn.Dropout(attn_pdrop)\n        self.resid_dropout = nn.Dropout(resid_pdrop)\n        # causal mask to ensure that attention is only applied to the left in the input sequence\n        self.register_buffer(\"bias\", torch.tril(torch.ones(max_seqlen, max_seqlen))\n                                     .view(1, 1, max_seqlen, max_seqlen))\n        self.n_head = n_head\n        self.n_embd = n_embd\n\n    def forward(self, x):\n        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n\n        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n        q, k ,v  = self.c_attn(x).split(self.n_embd, dim=2)\n        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n\n        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n        att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n        att = F.softmax(att, dim=-1)\n        att = self.attn_dropout(att)\n        y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n\n        # output projection\n        y = self.resid_dropout(self.c_proj(y))\n        return y\n\nbatch_size = 128\nmax_seqlen = 1024\nseq_len = 512\nn_embd = 768\nn_head = 8\nattn_pdrop = 0.0\nresid_pdrop = 0.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, seq_len, n_embd)]\n\ndef get_init_inputs():\n    return [n_embd, n_head, attn_pdrop, resid_pdrop, max_seqlen]", "jax_code": "import math\nimport jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    n_embd: int\n    n_head: int\n    attn_pdrop: float\n    resid_pdrop: float\n    max_seqlen: int\n\n    def setup(self):\n        assert self.n_embd % self.n_head == 0\n        self.c_attn = nn.Dense(3 * self.n_embd)\n        self.c_proj = nn.Dense(self.n_embd)\n        self.attn_dropout = nn.Dropout(self.attn_pdrop)\n        self.resid_dropout = nn.Dropout(self.resid_pdrop)\n        # Causal mask: shape (1, 1, max_seqlen, max_seqlen)\n        bias = jnp.tril(jnp.ones((self.max_seqlen, self.max_seqlen), dtype=jnp.float32))\n        self.bias = bias[None, None, :, :]\n\n    @nn.compact\n    def __call__(self, x, *, deterministic: bool = True):\n        B, T, C = x.shape\n        n_head = self.n_head\n        n_embd = self.n_embd\n        head_dim = C // n_head\n\n        # Linear projection for q, k, v\n        qkv = self.c_attn(x)\n        q, k, v = jnp.split(qkv, 3, axis=2)\n        # Reshape and transpose to (B, n_head, T, head_dim)\n        def split_heads(t):\n            t = t.reshape(B, T, n_head, head_dim)\n            return jnp.transpose(t, (0, 2, 1, 3))\n        q = split_heads(q)\n        k = split_heads(k)\n        v = split_heads(v)\n\n        # Attention scores\n        att = jnp.einsum('bnth,bnsh->bnts', q, k) * (1.0 / math.sqrt(head_dim))\n        # Causal mask\n        mask = self.bias[:, :, :T, :T]\n        att = jnp.where(mask == 0, -1e10, att)\n        att = nn.softmax(att, axis=-1)\n        att = self.attn_dropout(att, deterministic=deterministic)\n        y = jnp.einsum('bnts,bnsh->bnth', att, v)\n        # Re-assemble heads: (B, T, C)\n        y = jnp.transpose(y, (0, 2, 1, 3)).reshape(B, T, C)\n        y = self.c_proj(y)\n        y = self.resid_dropout(y, deterministic=deterministic)\n        return y\n\nbatch_size = 128\nmax_seqlen = 1024\nseq_len = 512\nn_embd = 768\nn_head = 8\nattn_pdrop = 0.0\nresid_pdrop = 0.0\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, seq_len, n_embd).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [n_embd, n_head, attn_pdrop, resid_pdrop, max_seqlen]"}
{"kb_id": "kb_level_3_0037", "level": "level_3", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.37275985663082, "success": true, "pytorch_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/pytorch_samples/kb_level_3_0037.py", "jax_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/jax_outputs/kb_level_3_0037_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\n\n# From https://github.com/karpathy/minGPT/blob/master/mingpt/model.py\n\nclass NewGELU(nn.Module):\n    \"\"\"\n    Implementation of the GELU activation function currently in Google BERT repo (identical to OpenAI GPT).\n    Reference: Gaussian Error Linear Units (GELU) paper: https://arxiv.org/abs/1606.08415\n    \"\"\"\n    def __init__(self):\n        super(NewGELU, self).__init__()\n    \n    def forward(self, x):\n        return 0.5 * x * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (x + 0.044715 * torch.pow(x, 3.0))))\n\nclass CausalSelfAttention(nn.Module):\n    \"\"\"\n    A vanilla multi-head masked self-attention layer with a projection at the end.\n    It is possible to use torch.nn.MultiheadAttention here but I am including an\n    explicit implementation here to show that there is nothing too scary here.\n    \"\"\"\n\n    def __init__(self, n_embd, n_head, attn_pdrop, resid_pdrop, max_seqlen):\n        super().__init__()\n        assert n_embd % n_head == 0\n        # key, query, value projections for all heads, but in a batch\n        self.c_attn = nn.Linear(n_embd, 3 * n_embd)\n        # output projection\n        self.c_proj = nn.Linear(n_embd, n_embd)\n        # regularization\n        self.attn_dropout = nn.Dropout(attn_pdrop)\n        self.resid_dropout = nn.Dropout(resid_pdrop)\n        # causal mask to ensure that attention is only applied to the left in the input sequence\n        self.register_buffer(\"bias\", torch.tril(torch.ones(max_seqlen, max_seqlen))\n                                     .view(1, 1, max_seqlen, max_seqlen))\n        self.n_head = n_head\n        self.n_embd = n_embd\n\n    def forward(self, x):\n        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n\n        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n        q, k ,v  = self.c_attn(x).split(self.n_embd, dim=2)\n        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n\n        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n        att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n        att = F.softmax(att, dim=-1)\n        att = self.attn_dropout(att)\n        y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n\n        # output projection\n        y = self.resid_dropout(self.c_proj(y))\n        return y\n    \nclass Model(nn.Module):\n    \"\"\" an unassuming Transformer block \"\"\"\n\n    def __init__(self, n_embd, n_head, attn_pdrop, resid_pdrop, max_seqlen):\n        super().__init__()\n        self.ln_1 = nn.LayerNorm(n_embd)\n        self.attn = CausalSelfAttention(n_embd, n_head, attn_pdrop, resid_pdrop, max_seqlen)\n        self.ln_2 = nn.LayerNorm(n_embd)\n        self.mlp = nn.ModuleDict(dict(\n            c_fc    = nn.Linear(n_embd, 4 * n_embd),\n            c_proj  = nn.Linear(4 * n_embd, n_embd),\n            act     = NewGELU(),\n            dropout = nn.Dropout(resid_pdrop),\n        ))\n        m = self.mlp\n        self.mlpf = lambda x: m.dropout(m.c_proj(m.act(m.c_fc(x)))) # MLP forward\n\n    def forward(self, x):\n        x = x + self.attn(self.ln_1(x))\n        x = x + self.mlpf(self.ln_2(x))\n        return x\n\nbatch_size = 128\nmax_seqlen = 1024\nseq_len = 512\nn_embd = 768\nn_head = 8\nattn_pdrop = 0.0\nresid_pdrop = 0.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, seq_len, n_embd)]\n\ndef get_init_inputs():\n    return [n_embd, n_head, attn_pdrop, resid_pdrop, max_seqlen]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\nimport math\n\nclass NewGELU(nn.Module):\n    \"\"\"\n    Implementation of the GELU activation function currently in Google BERT repo (identical to OpenAI GPT).\n    Reference: Gaussian Error Linear Units (GELU) paper: https://arxiv.org/abs/1606.08415\n    \"\"\"\n    @nn.compact\n    def __call__(self, x):\n        return 0.5 * x * (1.0 + jnp.tanh(jnp.sqrt(2.0 / jnp.pi) * (x + 0.044715 * jnp.power(x, 3.0))))\n\nclass CausalSelfAttention(nn.Module):\n    n_embd: int\n    n_head: int\n    attn_pdrop: float\n    resid_pdrop: float\n    max_seqlen: int\n\n    def setup(self):\n        assert self.n_embd % self.n_head == 0\n        self.c_attn = nn.Dense(3 * self.n_embd)\n        self.c_proj = nn.Dense(self.n_embd)\n        self.attn_dropout = nn.Dropout(self.attn_pdrop)\n        self.resid_dropout = nn.Dropout(self.resid_pdrop)\n        # Causal mask: (1, 1, max_seqlen, max_seqlen)\n        bias = jnp.tril(jnp.ones((self.max_seqlen, self.max_seqlen), dtype=jnp.float32))\n        self.bias = bias[None, None, :, :]\n\n    def __call__(self, x, *, deterministic):\n        B, T, C = x.shape\n\n        # Linear projection and split into q, k, v\n        qkv = self.c_attn(x)  # (B, T, 3 * n_embd)\n        q, k, v = jnp.split(qkv, 3, axis=2)\n        # Reshape for multi-head: (B, nh, T, hs)\n        nh = self.n_head\n        hs = C // nh\n        k = k.reshape(B, T, nh, hs).transpose(0, 2, 1, 3)\n        q = q.reshape(B, T, nh, hs).transpose(0, 2, 1, 3)\n        v = v.reshape(B, T, nh, hs).transpose(0, 2, 1, 3)\n\n        # Attention scores\n        att = jnp.einsum('bnth,bnsh->bnts', q, k) * (1.0 / math.sqrt(hs))\n        # Causal mask\n        mask = self.bias[:, :, :T, :T]\n        att = jnp.where(mask == 0, -1e10, att)\n        att = nn.softmax(att, axis=-1)\n        att = self.attn_dropout(att, deterministic=deterministic)\n        y = jnp.einsum('bnts,bnsh->bnth', att, v)\n        y = y.transpose(0, 2, 1, 3).reshape(B, T, C)\n\n        y = self.c_proj(y)\n        y = self.resid_dropout(y, deterministic=deterministic)\n        return y\n\nclass Model(nn.Module):\n    n_embd: int\n    n_head: int\n    attn_pdrop: float\n    resid_pdrop: float\n    max_seqlen: int\n\n    def setup(self):\n        self.ln_1 = nn.LayerNorm()\n        self.attn = CausalSelfAttention(\n            n_embd=self.n_embd,\n            n_head=self.n_head,\n            attn_pdrop=self.attn_pdrop,\n            resid_pdrop=self.resid_pdrop,\n            max_seqlen=self.max_seqlen,\n        )\n        self.ln_2 = nn.LayerNorm()\n        self.c_fc = nn.Dense(4 * self.n_embd)\n        self.act = NewGELU()\n        self.c_proj = nn.Dense(self.n_embd)\n        self.dropout = nn.Dropout(self.resid_pdrop)\n\n    def mlpf(self, x, *, deterministic):\n        x = self.c_fc(x)\n        x = self.act(x)\n        x = self.c_proj(x)\n        x = self.dropout(x, deterministic=deterministic)\n        return x\n\n    def __call__(self, x, *, deterministic):\n        x = x + self.attn(self.ln_1(x), deterministic=deterministic)\n        x = x + self.mlpf(self.ln_2(x), deterministic=deterministic)\n        return x\n\nbatch_size = 128\nmax_seqlen = 1024\nseq_len = 512\nn_embd = 768\nn_head = 8\nattn_pdrop = 0.0\nresid_pdrop = 0.0\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, seq_len, n_embd).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [n_embd, n_head, attn_pdrop, resid_pdrop, max_seqlen]"}
{"kb_id": "kb_level_3_0038", "level": "level_3", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/pytorch_samples/kb_level_3_0038.py", "jax_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/jax_outputs/kb_level_3_0038_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\n\n# U-Net Implementation\nclass DoubleConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.double_conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.Softmax(dim=-1),\n            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.Softmax(dim=-1)\n        )\n\n    def forward(self, x):\n        return self.double_conv(x)\n\nclass Model(nn.Module):\n    def __init__(self, in_channels, out_channels, features):\n        \"\"\"\n        :param in_channels: Number of input channels\n        :param out_channels: Number of output channels\n        :param features: Number of base features (will be doubled in each layer)\n        \"\"\"\n        super(Model, self).__init__()\n        self.encoder1 = DoubleConv(in_channels, features)\n        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.encoder2 = DoubleConv(features, features * 2)\n        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.encoder3 = DoubleConv(features * 2, features * 4)\n        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.encoder4 = DoubleConv(features * 4, features * 8)\n        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n\n        self.bottleneck = DoubleConv(features * 8, features * 16)\n\n        self.upconv4 = nn.ConvTranspose2d(features * 16, features * 8, kernel_size=2, stride=2)\n        self.decoder4 = DoubleConv(features * 16, features * 8)\n        self.upconv3 = nn.ConvTranspose2d(features * 8, features * 4, kernel_size=2, stride=2)\n        self.decoder3 = DoubleConv(features * 8, features * 4)\n        self.upconv2 = nn.ConvTranspose2d(features * 4, features * 2, kernel_size=2, stride=2)\n        self.decoder2 = DoubleConv(features * 4, features * 2)\n        self.upconv1 = nn.ConvTranspose2d(features * 2, features, kernel_size=2, stride=2)\n        self.decoder1 = DoubleConv(features * 2, features)\n\n        self.final_conv = nn.Conv2d(features, out_channels, kernel_size=1)\n\n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor, shape (batch_size, in_channels, height, width)\n        :return: Output tensor, shape (batch_size, out_channels, height, width)\n        \"\"\"\n        enc1 = self.encoder1(x)\n        enc2 = self.encoder2(self.pool1(enc1))\n        enc3 = self.encoder3(self.pool2(enc2))\n        enc4 = self.encoder4(self.pool3(enc3))\n\n        bottleneck = self.bottleneck(self.pool4(enc4))\n\n        dec4 = self.upconv4(bottleneck)\n        dec4 = torch.cat((dec4, enc4), dim=1)\n        dec4 = self.decoder4(dec4)\n        dec3 = self.upconv3(dec4)\n        dec3 = torch.cat((dec3, enc3), dim=1)\n        dec3 = self.decoder3(dec3)\n        dec2 = self.upconv2(dec3)\n        dec2 = torch.cat((dec2, enc2), dim=1)\n        dec2 = self.decoder2(dec2)\n        dec1 = self.upconv1(dec2)\n        dec1 = torch.cat((dec1, enc1), dim=1)\n        dec1 = self.decoder1(dec1)\n\n        return self.final_conv(dec1)\n    \nbatch_size = 8\nin_channels = 8\nout_channels = 4\nheight = 64\nwidth = 512\nfeatures = 64\n# Test code for UNet\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, features]\n", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass DoubleConv(nn.Module):\n    in_channels: int\n    out_channels: int\n\n    @nn.compact\n    def __call__(self, x):\n        x = nn.Conv(self.out_channels, kernel_size=(3, 3), padding='SAME')(x)\n        x = nn.BatchNorm(use_running_average=False)(x)\n        x = nn.softmax(x, axis=-1)\n        x = nn.Conv(self.out_channels, kernel_size=(3, 3), padding='SAME')(x)\n        x = nn.BatchNorm(use_running_average=False)(x)\n        x = nn.softmax(x, axis=-1)\n        return x\n\nclass Model(nn.Module):\n    in_channels: int\n    out_channels: int\n    features: int\n\n    @nn.compact\n    def __call__(self, x, *, train=True):\n        # Encoder\n        enc1 = DoubleConv(self.in_channels, self.features)(x)\n        enc1_pooled = nn.max_pool(enc1, window_shape=(2, 2), strides=(2, 2), padding='VALID')\n        enc2 = DoubleConv(self.features, self.features * 2)(enc1_pooled)\n        enc2_pooled = nn.max_pool(enc2, window_shape=(2, 2), strides=(2, 2), padding='VALID')\n        enc3 = DoubleConv(self.features * 2, self.features * 4)(enc2_pooled)\n        enc3_pooled = nn.max_pool(enc3, window_shape=(2, 2), strides=(2, 2), padding='VALID')\n        enc4 = DoubleConv(self.features * 4, self.features * 8)(enc3_pooled)\n        enc4_pooled = nn.max_pool(enc4, window_shape=(2, 2), strides=(2, 2), padding='VALID')\n\n        # Bottleneck\n        bottleneck = DoubleConv(self.features * 8, self.features * 16)(enc4_pooled)\n\n        # Decoder\n        def upconv(x, features):\n            # ConvTranspose2d with kernel_size=2, stride=2\n            # Use nn.ConvTranspose\n            return nn.ConvTranspose(features, kernel_size=(2, 2), strides=(2, 2), padding='SAME')(x)\n\n        dec4 = upconv(bottleneck, self.features * 8)\n        # Crop enc4 if needed to match dec4 spatial dims\n        dec4 = jnp.concatenate([dec4, crop_to(enc4, dec4)], axis=1)\n        dec4 = DoubleConv(self.features * 16, self.features * 8)(dec4)\n\n        dec3 = upconv(dec4, self.features * 4)\n        dec3 = jnp.concatenate([dec3, crop_to(enc3, dec3)], axis=1)\n        dec3 = DoubleConv(self.features * 8, self.features * 4)(dec3)\n\n        dec2 = upconv(dec3, self.features * 2)\n        dec2 = jnp.concatenate([dec2, crop_to(enc2, dec2)], axis=1)\n        dec2 = DoubleConv(self.features * 4, self.features * 2)(dec2)\n\n        dec1 = upconv(dec2, self.features)\n        dec1 = jnp.concatenate([dec1, crop_to(enc1, dec1)], axis=1)\n        dec1 = DoubleConv(self.features * 2, self.features)(dec1)\n\n        out = nn.Conv(self.out_channels, kernel_size=(1, 1))(dec1)\n        return out\n\ndef crop_to(enc, dec):\n    # enc, dec: (batch, channels, h, w)\n    # Crop enc spatial dims to match dec\n    h_enc, w_enc = enc.shape[2], enc.shape[3]\n    h_dec, w_dec = dec.shape[2], dec.shape[3]\n    dh = h_enc - h_dec\n    dw = w_enc - w_dec\n    h_start = dh // 2\n    w_start = dw // 2\n    return enc[:, :, h_start:h_start + h_dec, w_start:w_start + w_dec]\n\nbatch_size = 8\nin_channels = 8\nout_channels = 4\nheight = 64\nwidth = 512\nfeatures = 64\n\ndef get_inputs():\n    # Return a list with a single input array\n    key = jax.random.PRNGKey(0)\n    x = jax.random.uniform(key, (batch_size, in_channels, height, width))\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, features]"}
{"kb_id": "kb_level_3_0041", "level": "level_3", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/pytorch_samples/kb_level_3_0041.py", "jax_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/jax_outputs/kb_level_3_0041_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom einops import rearrange\n\nclass Model(nn.Module):\n    def __init__(self, batch_size, seq_length, n_heads, d_head, d_state, block_len=64):\n        \"\"\"\n        Mamba Structured State Space model implementation for benchmarking.\n        \n        :param batch_size: Size of the batch\n        :param seq_length: Length of the input sequence\n        :param n_heads: Number of attention heads\n        :param d_head: Dimension of each head\n        :param d_state: Dimension of the state space\n        :param block_len: Length of each block for chunked computation\n        \"\"\"\n        super(Model, self).__init__()\n        \n        assert seq_length % block_len == 0, \"Sequence length must be divisible by block length\"\n        \n        self.batch_size = batch_size\n        self.seq_length = seq_length\n        self.n_heads = n_heads\n        self.d_head = d_head\n        self.d_state = d_state\n        self.block_len = block_len\n        \n        # Initialize parameters\n        self.A = nn.Parameter(torch.randn(batch_size, seq_length, n_heads))\n        self.B = nn.Parameter(torch.randn(batch_size, seq_length, n_heads, d_state))\n        self.C = nn.Parameter(torch.randn(batch_size, seq_length, n_heads, d_state))\n        \n    def segsum(self, x):\n        \"\"\"Naive segment sum calculation.\"\"\"\n        T = x.size(-1)\n        x_cumsum = torch.cumsum(x, dim=-1)\n        x_segsum = x_cumsum[..., :, None] - x_cumsum[..., None, :]\n        mask = torch.tril(torch.ones(T, T, device=x.device, dtype=bool), diagonal=0)\n        x_segsum = x_segsum.masked_fill(~mask, -torch.inf)\n        return x_segsum\n    \n    def forward(self, X, initial_states=None):\n        \"\"\"\n        Forward pass implementing the SSD operation.\n        \n        :param X: Input tensor of shape (batch, length, n_heads, d_head)\n        :param initial_states: Optional initial states\n        :return: Output tensor Y and final state\n        \"\"\"\n        # Rearrange into blocks/chunks\n        X_blocks, A_blocks, B_blocks, C_blocks = [\n            rearrange(x, \"b (c l) ... -> b c l ...\", l=self.block_len)\n            for x in (X, self.A, self.B, self.C)\n        ]\n        \n        A_blocks = rearrange(A_blocks, \"b c l h -> b h c l\")\n        A_cumsum = torch.cumsum(A_blocks, dim=-1)\n        \n        # 1. Compute diagonal block outputs\n        L = torch.exp(self.segsum(A_blocks))\n        Y_diag = torch.einsum(\"bclhn,bcshn,bhcls,bcshp->bclhp\", \n                             C_blocks, B_blocks, L, X_blocks)\n        \n        # 2. Compute intra-chunk states\n        decay_states = torch.exp((A_cumsum[:, :, :, -1:] - A_cumsum))\n        states = torch.einsum(\"bclhn,bhcl,bclhp->bchpn\", \n                            B_blocks, decay_states, X_blocks)\n        \n        # 3. Compute inter-chunk recurrence\n        if initial_states is None:\n            initial_states = torch.zeros_like(states[:, :1])\n        states = torch.cat([initial_states, states], dim=1)\n        \n        decay_chunk = torch.exp(self.segsum(F.pad(A_cumsum[:, :, :, -1], (1, 0))))\n        new_states = torch.einsum(\"bhzc,bchpn->bzhpn\", decay_chunk, states)\n        states = new_states[:, :-1]\n        \n        # 4. Compute state-to-output conversion\n        state_decay_out = torch.exp(A_cumsum)\n        Y_off = torch.einsum('bclhn,bchpn,bhcl->bclhp', \n                           C_blocks, states, state_decay_out)\n        \n        # Combine diagonal and off-diagonal terms\n        Y = rearrange(Y_diag + Y_off, \"b c l h p -> b (c l) h p\")\n        \n        \n        return Y\n\n# Test parameters\nbatch_size = 2048\nseq_length = 128\nn_heads = 8\nd_head = 64\nd_state = 16\nblock_len = 64\n\ndef get_inputs():\n    return [torch.rand(batch_size, seq_length, n_heads, d_head)]\n\ndef get_init_inputs():\n    return [batch_size, seq_length, n_heads, d_head, d_state, block_len]\n", "jax_code": "import jax\nimport jax.numpy as jnp\n\ndef rearrange_blocks(x, block_len):\n    # x: (b, seq, ...)\n    b, seq = x.shape[:2]\n    c = seq // block_len\n    new_shape = (b, c, block_len) + x.shape[2:]\n    return x.reshape(new_shape)\n\ndef reverse_rearrange_blocks(x):\n    # x: (b, c, l, ...)\n    b, c, l = x.shape[:3]\n    new_shape = (b, c * l) + x.shape[3:]\n    return x.reshape(new_shape)\n\nclass Model:\n    def __init__(self, batch_size, seq_length, n_heads, d_head, d_state, block_len=64, key=None):\n        assert seq_length % block_len == 0, \"Sequence length must be divisible by block length\"\n        self.batch_size = batch_size\n        self.seq_length = seq_length\n        self.n_heads = n_heads\n        self.d_head = d_head\n        self.d_state = d_state\n        self.block_len = block_len\n\n        if key is None:\n            key = jax.random.PRNGKey(0)\n        k1, k2, k3 = jax.random.split(key, 3)\n        self.A = jax.random.normal(k1, (batch_size, seq_length, n_heads))\n        self.B = jax.random.normal(k2, (batch_size, seq_length, n_heads, d_state))\n        self.C = jax.random.normal(k3, (batch_size, seq_length, n_heads, d_state))\n\n    def segsum(self, x):\n        # x: (..., T)\n        T = x.shape[-1]\n        x_cumsum = jnp.cumsum(x, axis=-1)\n        x_cumsum_exp = x_cumsum[..., :, None] - x_cumsum[..., None, :]\n        mask = jnp.tril(jnp.ones((T, T), dtype=bool))\n        x_segsum = jnp.where(mask, x_cumsum_exp, -jnp.inf)\n        return x_segsum\n\n    def forward(self, X, initial_states=None):\n        # X: (batch, length, n_heads, d_head)\n        block_len = self.block_len\n\n        # Rearrange into blocks/chunks\n        X_blocks = rearrange_blocks(X, block_len)\n        A_blocks = rearrange_blocks(self.A, block_len)\n        B_blocks = rearrange_blocks(self.B, block_len)\n        C_blocks = rearrange_blocks(self.C, block_len)\n\n        # A_blocks: (b, c, l, h) -> (b, h, c, l)\n        A_blocks = jnp.transpose(A_blocks, (0, 3, 1, 2))\n        A_cumsum = jnp.cumsum(A_blocks, axis=-1)  # (b, h, c, l)\n\n        # 1. Compute diagonal block outputs\n        # L = exp(segsum(A_blocks)) -> (b, h, l, l)\n        L = jnp.exp(self.segsum(A_blocks))  # (b, h, l, l)\n        # C_blocks: (b, c, l, h, d_state)\n        # B_blocks: (b, c, l, h, d_state)\n        # X_blocks: (b, c, l, h, d_head)\n        # L: (b, h, l, l)\n        # We need to align dims for einsum\n        # Let's expand L to (b, 1, l, l, h, 1)\n        L_exp = L[:, None, :, :, :, None]  # (b, 1, h, l, l, 1)\n        # C_blocks: (b, c, l, h, d_state)\n        # B_blocks: (b, c, l, h, d_state)\n        # X_blocks: (b, c, l, h, d_head)\n        # We'll use einsum to match PyTorch's:\n        # \"bclhn,bcshn,bhcls,bcshp->bclhp\"\n        # But in JAX, let's do:\n        # C_blocks: (b, c, l, h, d_state)\n        # B_blocks: (b, c, l, h, d_state)\n        # L: (b, h, l, l)\n        # X_blocks: (b, c, l, h, d_head)\n        # We'll need to sum over s and n (l and d_state)\n        # Let's expand dims to align\n        # We'll use a for loop for clarity and correctness\n\n        b, c, l, h, p = C_blocks.shape[0], C_blocks.shape[1], C_blocks.shape[2], C_blocks.shape[3], X_blocks.shape[-1]\n        d_state = C_blocks.shape[-1]\n\n        # Y_diag: (b, c, l, h, p)\n        def compute_Y_diag(bi, ci):\n            # C: (l, h, d_state)\n            # B: (l, h, d_state)\n            # X: (l, h, p)\n            # L: (h, l, l)\n            C = C_blocks[bi, ci]  # (l, h, d_state)\n            B = B_blocks[bi, ci]  # (l, h, d_state)\n            X = X_blocks[bi, ci]  # (l, h, p)\n            Lh = L[bi]  # (h, l, l)\n            # We'll compute for each h\n            def compute_h(h_idx):\n                # C: (l, d_state)\n                # B: (l, d_state)\n                # X: (l, p)\n                # L: (l, l)\n                Ch = C[:, h_idx, :]  # (l, d_state)\n                Bh = B[:, h_idx, :]  # (l, d_state)\n                Xh = X[:, h_idx, :]  # (l, p)\n                Lhh = Lh[h_idx]      # (l, l)\n                # einsum over s, n: sum_s sum_n C[l, n] * B[s, n] * L[l, s] * X[s, p]\n                # -> for each l, p\n                # We'll do:\n                # Y[l, p] = sum_{s, n} C[l, n] * B[s, n] * L[l, s] * X[s, p]\n                # Let's expand dims:\n                # C[l, n] -> (l, 1, n, 1)\n                # B[s, n] -> (1, s, n, 1)\n                # L[l, s] -> (l, s, 1, 1)\n                # X[s, p] -> (1, s, 1, p)\n                C_exp = Ch[:, None, :, None]\n                B_exp = Bh[None, :, :, None]\n                L_exp = Lhh[:, :, None, None]\n                X_exp = Xh[None, :, None, :]\n                prod = C_exp * B_exp * L_exp * X_exp  # (l, s, n, p)\n                Y = jnp.sum(prod, axis=(1,2))  # sum over s, n -> (l, p)\n                return Y\n            Yh = jax.vmap(compute_h)(jnp.arange(h))\n            # Yh: (h, l, p) -> (l, h, p)\n            return jnp.transpose(Yh, (1,0,2))\n        Y_diag = jax.vmap(lambda bi: jax.vmap(lambda ci: compute_Y_diag(bi, ci))(jnp.arange(c)))(jnp.arange(b))\n        # Y_diag: (b, c, l, h, p)\n\n        # 2. Compute intra-chunk states\n        # decay_states = exp(A_cumsum[:, :, :, -1:] - A_cumsum)\n        # A_cumsum: (b, h, c, l)\n        decay_states = jnp.exp(A_cumsum[:, :, :, -1:] - A_cumsum)  # (b, h, c, l)\n        # B_blocks: (b, c, l, h, d_state)\n        # X_blocks: (b, c, l, h, d_head)\n        # We'll sum over l\n        # states: (b, c, h, d_head, d_state)\n        def compute_states(bi, ci):\n            # B: (l, h, d_state)\n            # decay: (h, l)\n            # X: (l, h, d_head)\n            B = B_blocks[bi, ci]  # (l, h, d_state)\n            decay = decay_states[bi, :, ci]  # (h, l)\n            X = X_blocks[bi, ci]  # (l, h, d_head)\n            # For each h, p, n: sum over l: B[l, h, n] * decay[h, l] * X[l, h, p]\n            def compute_h(h_idx):\n                B_h = B[:, h_idx, :]  # (l, d_state)\n                decay_h = decay[h_idx]  # (l,)\n                X_h = X[:, h_idx, :]    # (l, d_head)\n                # (l, d_state) * (l, 1) * (l, d_head)\n                # We'll do outer product over l, then sum over l\n                # For each n, p: sum_l B[l, n] * decay[l] * X[l, p]\n                prod = B_h * decay_h[:, None]  # (l, d_state)\n                # Now, for each p, n: sum_l prod[l, n] * X[l, p]\n                # We'll do: (l, d_state)T @ (l, d_head) -> (d_state, d_head)\n                # But we want (d_head, d_state)\n                res = jnp.dot(X_h.T, prod)  # (d_head, d_state)\n                return res\n            states_h = jax.vmap(compute_h)(jnp.arange(h))  # (h, d_head, d_state)\n            # (h, d_head, d_state) -> (h, d_head, d_state)\n            return states_h\n        states = jax.vmap(lambda bi: jax.vmap(lambda ci: compute_states(bi, ci))(jnp.arange(c)))(jnp.arange(b))\n        # states: (b, c, h, d_head, d_state)\n\n        # 3. Compute inter-chunk recurrence\n        if initial_states is None:\n            initial_states = jnp.zeros_like(states[:, :1])  # (b, 1, h, d_head, d_state)\n        states_cat = jnp.concatenate([initial_states, states], axis=1)  # (b, c+1, h, d_head, d_state)\n\n        # decay_chunk = exp(segsum(F.pad(A_cumsum[:, :, :, -1], (1, 0))))\n        # A_cumsum[:, :, :, -1]: (b, h, c)\n        A_last = A_cumsum[:, :, :, -1]  # (b, h, c)\n        # Pad (1, 0) on last axis\n        A_last_padded = jnp.pad(A_last, ((0,0),(0,0),(1,0)), mode='constant')\n        decay_chunk = jnp.exp(self.segsum(A_last_padded))  # (b, h, c+1, c+1)\n\n        # new_states = einsum(\"bhzc,bchpn->bzhpn\", decay_chunk, states_cat)\n        # decay_chunk: (b, h, z, c+1)\n        # states_cat: (b, c+1, h, d_head, d_state)\n        # We'll do: for z in c+1, sum over c+1: decay_chunk[b, h, z, s] * states_cat[b, s, h, d_head, d_state]\n        def compute_new_states(bi):\n            # decay_chunk: (h, c+1, c+1)\n            # states_cat: (c+1, h, d_head, d_state)\n            dc = decay_chunk[bi]  # (h, c+1, c+1)\n            sc = states_cat[bi]   # (c+1, h, d_head, d_state)\n            def compute_z(z_idx):\n                # For each h, sum over s\n                def compute_h(h_idx):\n                    # dc: (c+1,)\n                    # sc: (c+1, d_head, d_state)\n                    weights = dc[h_idx, z_idx]  # (c+1,)\n                    # weighted sum over s\n                    weighted = weights[:, None, None] * sc[:, h_idx]\n                    return jnp.sum(weighted, axis=0)  # (d_head, d_state)\n                return jax.vmap(compute_h)(jnp.arange(h))  # (h, d_head, d_state)\n            return jax.vmap(compute_z)(jnp.arange(c+1))  # (c+1, h, d_head, d_state)\n        new_states = jax.vmap(compute_new_states)(jnp.arange(b))  # (b, c+1, h, d_head, d_state)\n        # states = new_states[:, :-1]\n        states = new_states[:, :-1]  # (b, c, h, d_head, d_state)\n\n        # 4. Compute state-to-output conversion\n        # state_decay_out = exp(A_cumsum)\n        state_decay_out = jnp.exp(A_cumsum)  # (b, h, c, l)\n        # C_blocks: (b, c, l, h, d_state)\n        # states: (b, c, h, d_head, d_state)\n        # state_decay_out: (b, h, c, l)\n        # We'll do: einsum('bclhn,bchpn,bhcl->bclhp', C_blocks, states, state_decay_out)\n        # C_blocks: (b, c, l, h, d_state)\n        # states: (b, c, h, d_head, d_state)\n        # state_decay_out: (b, h, c, l)\n        def compute_Y_off(bi, ci):\n            # C: (l, h, d_state)\n            # states: (h, d_head, d_state)\n            # decay: (h, l)\n            C = C_blocks[bi, ci]  # (l, h, d_state)\n            S = states[bi, ci]    # (h, d_head, d_state)\n            decay = state_decay_out[bi, :, ci]  # (h, l)\n            # For each l, h, p: sum_n C[l, h, n] * S[h, p, n] * decay[h, l]\n            # We'll do: for l in block, h in n_heads, p in d_head\n            def compute_l(l_idx):\n                def compute_h(h_idx):\n                    C_lh = C[l_idx, h_idx]  # (d_state,)\n                    S_hp = S[h_idx]         # (d_head, d_state)\n                    d = decay[h_idx, l_idx]\n                    # sum_n C_lh[n] * S_hp[p, n] * d\n                    # For each p: sum_n C_lh[n] * S_hp[p, n]\n                    prod = jnp.dot(S_hp, C_lh) * d  # (d_head,)\n                    return prod\n                return jax.vmap(compute_h)(jnp.arange(h))  # (h, d_head)\n            Y = jax.vmap(compute_l)(jnp.arange(l))  # (l, h, d_head)\n            # (l, h, d_head) -> (l, h, d_head)\n            return Y\n        Y_off = jax.vmap(lambda bi: jax.vmap(lambda ci: compute_Y_off(bi, ci))(jnp.arange(c)))(jnp.arange(b))\n        # Y_off: (b, c, l, h, d_head)\n        # Transpose to (b, c, l, h, d_head)\n        # Combine diagonal and off-diagonal terms\n        Y = Y_diag + Y_off\n        Y = reverse_rearrange_blocks(Y)  # (b, seq_length, h, d_head)\n        return Y\n\n# Test parameters\nbatch_size = 2048\nseq_length = 128\nn_heads = 8\nd_head = 64\nd_state = 16\nblock_len = 64\n\ndef get_inputs():\n    key = jax.random.PRNGKey(42)\n    X = jax.random.uniform(key, (batch_size, seq_length, n_heads, d_head))\n    return [X]\n\ndef get_init_inputs():\n    return [batch_size, seq_length, n_heads, d_head, d_state, block_len]"}
{"kb_id": "kb_level_3_0042", "level": "level_3", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/pytorch_samples/kb_level_3_0042.py", "jax_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/jax_outputs/kb_level_3_0042_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom einops import rearrange\n\nclass Model(nn.Module):\n    def __init__(self, batch_size, seq_length, n_heads, d_head, d_state, block_len=64):\n        \"\"\"\n        Mamba Structured State Space model implementation for benchmarking.\n        \n        :param batch_size: Size of the batch\n        :param seq_length: Length of the input sequence\n        :param n_heads: Number of attention heads\n        :param d_head: Dimension of each head\n        :param d_state: Dimension of the state space\n        :param block_len: Length of each block for chunked computation\n        \"\"\"\n        super(Model, self).__init__()\n        \n        assert seq_length % block_len == 0, \"Sequence length must be divisible by block length\"\n        \n        self.batch_size = batch_size\n        self.seq_length = seq_length\n        self.n_heads = n_heads\n        self.d_head = d_head\n        self.d_state = d_state\n        self.block_len = block_len\n        \n        # Initialize parameters\n        self.A = nn.Parameter(torch.randn(batch_size, seq_length, n_heads))\n        self.B = nn.Parameter(torch.randn(batch_size, seq_length, n_heads, d_state))\n        self.C = nn.Parameter(torch.randn(batch_size, seq_length, n_heads, d_state))\n        \n    def segsum(self, x):\n        \"\"\"Naive segment sum calculation.\"\"\"\n        T = x.size(-1)\n        x_cumsum = torch.cumsum(x, dim=-1)\n        x_segsum = x_cumsum[..., :, None] - x_cumsum[..., None, :]\n        mask = torch.tril(torch.ones(T, T, device=x.device, dtype=bool), diagonal=0)\n        x_segsum = x_segsum.masked_fill(~mask, -torch.inf)\n        return x_segsum\n    \n    def forward(self, X, initial_states=None):\n        \"\"\"\n        Forward pass implementing the SSD operation.\n        \n        :param X: Input tensor of shape (batch, length, n_heads, d_head)\n        :param initial_states: Optional initial states\n        :return: Output tensor Y and final state\n        \"\"\"\n        # Rearrange into blocks/chunks\n        X_blocks, A_blocks, B_blocks, C_blocks = [\n            rearrange(x, \"b (c l) ... -> b c l ...\", l=self.block_len)\n            for x in (X, self.A, self.B, self.C)\n        ]\n        \n        A_blocks = rearrange(A_blocks, \"b c l h -> b h c l\")\n        A_cumsum = torch.cumsum(A_blocks, dim=-1)\n        \n        # 1. Compute diagonal block outputs\n        L = torch.exp(self.segsum(A_blocks))\n        Y_diag = torch.einsum(\"bclhn,bcshn,bhcls,bcshp->bclhp\", \n                             C_blocks, B_blocks, L, X_blocks)\n        \n        # 2. Compute intra-chunk states\n        decay_states = torch.exp((A_cumsum[:, :, :, -1:] - A_cumsum))\n        states = torch.einsum(\"bclhn,bhcl,bclhp->bchpn\", \n                            B_blocks, decay_states, X_blocks)\n        \n        # 3. Compute inter-chunk recurrence\n        if initial_states is None:\n            initial_states = torch.zeros_like(states[:, :1])\n        states = torch.cat([initial_states, states], dim=1)\n        \n        decay_chunk = torch.exp(self.segsum(F.pad(A_cumsum[:, :, :, -1], (1, 0))))\n        new_states = torch.einsum(\"bhzc,bchpn->bzhpn\", decay_chunk, states)\n        return new_states[:, -1]\n\n# Test parameters\nbatch_size = 2048\nseq_length = 128\nn_heads = 8\nd_head = 64\nd_state = 16\nblock_len = 64\n\ndef get_inputs():\n    return [torch.rand(batch_size, seq_length, n_heads, d_head)]\n\ndef get_init_inputs():\n    return [batch_size, seq_length, n_heads, d_head, d_state, block_len]\n", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    def __init__(self, batch_size, seq_length, n_heads, d_head, d_state, block_len=64, key=None):\n        assert seq_length % block_len == 0, \"Sequence length must be divisible by block length\"\n        self.batch_size = batch_size\n        self.seq_length = seq_length\n        self.n_heads = n_heads\n        self.d_head = d_head\n        self.d_state = d_state\n        self.block_len = block_len\n\n        if key is None:\n            key = jax.random.PRNGKey(0)\n        kA, kB, kC = jax.random.split(key, 3)\n        self.A = jax.random.normal(kA, (batch_size, seq_length, n_heads))\n        self.B = jax.random.normal(kB, (batch_size, seq_length, n_heads, d_state))\n        self.C = jax.random.normal(kC, (batch_size, seq_length, n_heads, d_state))\n\n    def rearrange_blocks(self, x, l):\n        # x: (b, seq, ...)\n        b = x.shape[0]\n        seq = x.shape[1]\n        c = seq // l\n        new_shape = (b, c, l) + x.shape[2:]\n        return x.reshape(new_shape)\n\n    def segsum(self, x):\n        # x: (..., T)\n        T = x.shape[-1]\n        x_cumsum = jnp.cumsum(x, axis=-1)\n        x_cumsum_exp = jnp.expand_dims(x_cumsum, axis=-2)  # (..., 1, T)\n        x_cumsum_exp2 = jnp.expand_dims(x_cumsum, axis=-1) # (..., T, 1)\n        x_segsum = x_cumsum_exp - x_cumsum_exp2  # (..., T, T)\n        mask = jnp.tril(jnp.ones((T, T), dtype=bool), k=0)\n        # Broadcast mask to x_segsum shape\n        mask = jnp.broadcast_to(mask, x_segsum.shape)\n        x_segsum = jnp.where(mask, x_segsum, -jnp.inf)\n        return x_segsum\n\n    def forward(self, X, initial_states=None):\n        # X: (batch, length, n_heads, d_head)\n        # Rearrange into blocks/chunks\n        X_blocks = self.rearrange_blocks(X, self.block_len)\n        A_blocks = self.rearrange_blocks(self.A, self.block_len)\n        B_blocks = self.rearrange_blocks(self.B, self.block_len)\n        C_blocks = self.rearrange_blocks(self.C, self.block_len)\n\n        # A_blocks: (b, c, l, h) -> (b, h, c, l)\n        A_blocks = jnp.transpose(A_blocks, (0, 3, 1, 2))\n        A_cumsum = jnp.cumsum(A_blocks, axis=-1)  # (b, h, c, l)\n\n        # 1. Compute diagonal block outputs\n        L = jnp.exp(self.segsum(A_blocks))  # (b, h, c, l, l)\n        # C_blocks: (b, c, l, h, d_state)\n        # B_blocks: (b, c, l, h, d_state)\n        # X_blocks: (b, c, l, n_heads, d_head)\n        # We'll need to align axes for einsum\n        # Let's expand dims to match\n        # C_blocks: (b, c, l, h, d_state)\n        # B_blocks: (b, c, l, h, d_state)\n        # L: (b, h, c, l, l)\n        # X_blocks: (b, c, l, h, d_head)\n        # We'll use: \"b c l h n, b c l h p, b h c l s, b c s h p -> b c l h p\"\n        # But PyTorch code uses: \"bclhn,bcshn,bhcls,bcshp->bclhp\"\n        # Let's transpose X_blocks to (b, c, l, h, d_head)\n        # We'll need to align axes for einsum\n        # Let's use the same notation as PyTorch\n        # C_blocks: (b, c, l, h, d_state) -> b c l h n\n        # B_blocks: (b, c, s, h, d_state) -> b c s h n\n        # L: (b, h, c, l, s) -> b h c l s\n        # X_blocks: (b, c, s, h, p) -> b c s h p\n        # Output: b c l h p\n        Y_diag = jnp.einsum(\n            \"bclhn,bcshn,bhcls,bcshp->bclhp\",\n            C_blocks, B_blocks, L, X_blocks\n        )\n\n        # 2. Compute intra-chunk states\n        # decay_states = exp(A_cumsum[:, :, :, -1:] - A_cumsum)\n        # A_cumsum: (b, h, c, l)\n        last_A = A_cumsum[..., -1:]  # (b, h, c, 1)\n        decay_states = jnp.exp(last_A - A_cumsum)  # (b, h, c, l)\n        # B_blocks: (b, c, l, h, d_state) -> (b, c, l, h, d_state)\n        # decay_states: (b, h, c, l) -> (b, c, l, h)\n        decay_states_t = jnp.transpose(decay_states, (0, 2, 3, 1))  # (b, c, l, h)\n        # X_blocks: (b, c, l, h, d_head)\n        # We'll need to sum over l\n        # \"bclhn,bclh,bclhp->bchpn\"\n        states = jnp.einsum(\n            \"bclhn,bclh,bclhp->bchpn\",\n            B_blocks, decay_states_t, X_blocks\n        )\n\n        # 3. Compute inter-chunk recurrence\n        if initial_states is None:\n            initial_states = jnp.zeros_like(states[:, :1])\n        states = jnp.concatenate([initial_states, states], axis=1)  # (b, c+1, h, p, n)\n\n        # decay_chunk = exp(self.segsum(F.pad(A_cumsum[:, :, :, -1], (1, 0))))\n        # A_cumsum: (b, h, c, l)\n        # A_cumsum[:, :, :, -1]: (b, h, c)\n        last_A_cumsum = A_cumsum[..., -1]  # (b, h, c)\n        # Pad (1, 0) on last axis\n        last_A_cumsum_padded = jnp.pad(last_A_cumsum, ((0,0),(0,0),(1,0)), mode='constant')\n        # self.segsum: (..., T)\n        decay_chunk = jnp.exp(self.segsum(last_A_cumsum_padded))  # (b, h, c+1, c+1)\n        # states: (b, c+1, h, p, n)\n        # decay_chunk: (b, h, c+1, c+1)\n        # \"bhzc,bchpn->bzhpn\"\n        new_states = jnp.einsum(\"bhzc,bchpn->bzhpn\", decay_chunk, states)\n        return new_states[:, -1]  # (b, h, p, n)\n\n# Test parameters\nbatch_size = 2048\nseq_length = 128\nn_heads = 8\nd_head = 64\nd_state = 16\nblock_len = 64\n\ndef get_inputs():\n    key = jax.random.PRNGKey(42)\n    X = jax.random.uniform(key, (batch_size, seq_length, n_heads, d_head))\n    return [X]\n\ndef get_init_inputs():\n    return [batch_size, seq_length, n_heads, d_head, d_state, block_len]"}
{"kb_id": "kb_level_3_0043", "level": "level_3", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/pytorch_samples/kb_level_3_0043.py", "jax_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/jax_outputs/kb_level_3_0043_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, num_classes):\n        \"\"\"\n        LeNet-5 architecture implementation in PyTorch.\n\n        :param num_classes: The number of output classes.\n        \"\"\"\n        super(Model, self).__init__()\n        \n        # Convolutional layers\n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1)\n        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1)\n        \n        # Fully connected layers\n        self.fc1 = nn.Linear(in_features=16*5*5, out_features=120)\n        self.fc2 = nn.Linear(in_features=120, out_features=84)\n        self.fc3 = nn.Linear(in_features=84, out_features=num_classes)\n    \n    def forward(self, x):\n        \"\"\"\n        Forward pass of the LeNet-5 model.\n\n        :param x: The input tensor, shape (batch_size, 1, 32, 32)\n        :return: The output tensor, shape (batch_size, num_classes)\n        \"\"\"\n        # First convolutional layer with ReLU activation and max pooling\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, kernel_size=2, stride=2)\n        \n        # Second convolutional layer with ReLU activation and max pooling\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, kernel_size=2, stride=2)\n        \n        # Flatten the output for the fully connected layers\n        x = x.view(-1, 16*5*5)\n        \n        # First fully connected layer with ReLU activation\n        x = F.relu(self.fc1(x))\n        \n        # Second fully connected layer with ReLU activation\n        x = F.relu(self.fc2(x))\n        \n        # Final fully connected layer\n        x = self.fc3(x)\n        \n        return x\n\n# Test code for the LeNet-5 model (larger batch & image)\nbatch_size = 4096\nnum_classes = 20\n\ndef get_inputs():\n    return [torch.rand(batch_size, 1, 32, 32)]\n\ndef get_init_inputs():\n    return [num_classes]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    num_classes: int\n\n    @nn.compact\n    def __call__(self, x):\n        # First convolutional layer with ReLU activation and max pooling\n        x = nn.Conv(features=6, kernel_size=(5, 5), strides=(1, 1), use_bias=True)(x)\n        x = nn.relu(x)\n        x = nn.max_pool(x, window_shape=(2, 2), strides=(2, 2), padding='VALID')\n\n        # Second convolutional layer with ReLU activation and max pooling\n        x = nn.Conv(features=16, kernel_size=(5, 5), strides=(1, 1), use_bias=True)(x)\n        x = nn.relu(x)\n        x = nn.max_pool(x, window_shape=(2, 2), strides=(2, 2), padding='VALID')\n\n        # Flatten the output for the fully connected layers\n        x = x.reshape((x.shape[0], -1))\n\n        # First fully connected layer with ReLU activation\n        x = nn.Dense(features=120)(x)\n        x = nn.relu(x)\n\n        # Second fully connected layer with ReLU activation\n        x = nn.Dense(features=84)(x)\n        x = nn.relu(x)\n\n        # Final fully connected layer\n        x = nn.Dense(features=self.num_classes)(x)\n        return x\n\n# Test code for the LeNet-5 model (larger batch & image)\nbatch_size = 4096\nnum_classes = 20\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, 1, 32, 32).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [num_classes]"}
{"kb_id": "kb_level_3_0044", "level": "level_3", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.62230215827337, "success": true, "pytorch_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/pytorch_samples/kb_level_3_0044.py", "jax_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/jax_outputs/kb_level_3_0044_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\n\n# From https://github.com/karpathy/minGPT/blob/master/mingpt/model.py\n\nclass NewGELU(nn.Module):\n    \"\"\"\n    Implementation of the GELU activation function currently in Google BERT repo (identical to OpenAI GPT).\n    Reference: Gaussian Error Linear Units (GELU) paper: https://arxiv.org/abs/1606.08415\n    \"\"\"\n    def __init__(self):\n        super(NewGELU, self).__init__()\n    \n    def forward(self, x):\n        return 0.5 * x * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (x + 0.044715 * torch.pow(x, 3.0))))\n\nclass Model(nn.Module):\n    \"\"\"\n    A multi-head masked self-attention layer with a projection at the end that uses ReLU instead of Softmax.\n    It is possible to use torch.nn.MultiheadAttention here but I am including an\n    explicit implementation here to show that there is nothing too scary here.\n    \"\"\"\n\n    def __init__(self, n_embd, n_head, max_seqlen):\n        super().__init__()\n        assert n_embd % n_head == 0\n        # key, query, value projections for all heads, but in a batch\n        self.c_attn = nn.Linear(n_embd, 3 * n_embd)\n        # output projection\n        self.c_proj = nn.Linear(n_embd, n_embd)\n        # causal mask to ensure that attention is only applied to the left in the input sequence\n        self.register_buffer(\"bias\", torch.tril(torch.ones(max_seqlen, max_seqlen))\n                                     .view(1, 1, max_seqlen, max_seqlen))\n        self.n_head = n_head\n        self.n_embd = n_embd\n\n    def forward(self, x):\n        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n\n        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n        q, k ,v  = self.c_attn(x).split(self.n_embd, dim=2)\n        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n\n        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n        att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n        att = F.relu(att)\n\n        y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n\n        return y\n\nbatch_size = 16\nmax_seqlen = 1024\nn_embd = 768  # Hidden dimension, typical for BERT-base size\nn_head = 12   # Number of attention heads, typical for BERT-base size\n\ndef get_inputs():\n    return [torch.rand(batch_size, max_seqlen, n_embd)]\n\ndef get_init_inputs():\n    return [n_embd, n_head, max_seqlen]", "jax_code": "import math\nimport jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass NewGELU(nn.Module):\n    \"\"\"\n    Implementation of the GELU activation function currently in Google BERT repo (identical to OpenAI GPT).\n    Reference: Gaussian Error Linear Units (GELU) paper: https://arxiv.org/abs/1606.08415\n    \"\"\"\n    @nn.compact\n    def __call__(self, x):\n        return 0.5 * x * (1.0 + jnp.tanh(math.sqrt(2.0 / math.pi) * (x + 0.044715 * jnp.power(x, 3.0))))\n\nclass Model(nn.Module):\n    n_embd: int\n    n_head: int\n    max_seqlen: int\n\n    def setup(self):\n        assert self.n_embd % self.n_head == 0\n        self.c_attn = nn.Dense(3 * self.n_embd)\n        self.c_proj = nn.Dense(self.n_embd)\n        # Causal mask: shape (1, 1, max_seqlen, max_seqlen)\n        bias = jnp.tril(jnp.ones((self.max_seqlen, self.max_seqlen), dtype=jnp.float32))\n        self.bias = bias[None, None, :, :]\n\n    def __call__(self, x):\n        # x: (B, T, C)\n        B, T, C = x.shape\n\n        # Linear projection and split into q, k, v\n        qkv = self.c_attn(x)  # (B, T, 3 * n_embd)\n        q, k, v = jnp.split(qkv, 3, axis=2)  # Each (B, T, n_embd)\n\n        # Reshape for multi-head: (B, T, n_head, head_dim) -> (B, n_head, T, head_dim)\n        head_dim = C // self.n_head\n        k = k.reshape(B, T, self.n_head, head_dim).transpose(0, 2, 1, 3)\n        q = q.reshape(B, T, self.n_head, head_dim).transpose(0, 2, 1, 3)\n        v = v.reshape(B, T, self.n_head, head_dim).transpose(0, 2, 1, 3)\n\n        # Attention scores: (B, n_head, T, head_dim) x (B, n_head, head_dim, T) -> (B, n_head, T, T)\n        att = jnp.einsum('bnth,bnhd->bntd', q, k.transpose(0,1,3,2))\n        att = att / math.sqrt(head_dim)\n\n        # Causal mask\n        mask = self.bias[:, :, :T, :T]\n        att = jnp.where(mask == 0, -jnp.inf, att)\n\n        # ReLU instead of softmax\n        att = jnp.maximum(att, 0.0)\n\n        # Weighted sum: (B, n_head, T, T) x (B, n_head, T, head_dim) -> (B, n_head, T, head_dim)\n        y = jnp.einsum('bnij,bnjh->bnih', att, v)\n\n        # Re-assemble all head outputs side by side: (B, n_head, T, head_dim) -> (B, T, C)\n        y = y.transpose(0, 2, 1, 3).reshape(B, T, C)\n\n        return y\n\nbatch_size = 16\nmax_seqlen = 1024\nn_embd = 768\nn_head = 12\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, max_seqlen, n_embd).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [n_embd, n_head, max_seqlen]"}
{"kb_id": "kb_level_3_0045", "level": "level_3", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.74774774774775, "success": true, "pytorch_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/pytorch_samples/kb_level_3_0045.py", "jax_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/jax_outputs/kb_level_3_0045_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, num_classes=1000):\n        \"\"\"\n        :param num_classes: The number of output classes (default is 1000 for ImageNet)\n        \"\"\"\n        super(Model, self).__init__()\n        \n        # First convolutional layer\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4, padding=2)\n        self.relu1 = nn.ReLU(inplace=True)\n        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2)\n        \n        # Second convolutional layer\n        self.conv2 = nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, padding=2)\n        self.relu2 = nn.ReLU(inplace=True)\n        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2)\n        \n        # Third convolutional layer\n        self.conv3 = nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, padding=1)\n        self.relu3 = nn.ReLU(inplace=True)\n        \n        # Fourth convolutional layer\n        self.conv4 = nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, padding=1)\n        self.relu4 = nn.ReLU(inplace=True)\n        \n        # Fifth convolutional layer\n        self.conv5 = nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, padding=1)\n        self.relu5 = nn.ReLU(inplace=True)\n        self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=2)\n        \n        # Fully connected layers\n        self.fc1 = nn.Linear(in_features=256 * 6 * 6, out_features=4096)\n        self.relu6 = nn.ReLU(inplace=True)\n        self.dropout1 = nn.Dropout(p=0.0)\n        \n        self.fc2 = nn.Linear(in_features=4096, out_features=4096)\n        self.relu7 = nn.ReLU(inplace=True)\n        self.dropout2 = nn.Dropout(p=0.0)\n        \n        self.fc3 = nn.Linear(in_features=4096, out_features=num_classes)\n    \n    def forward(self, x):\n        \"\"\"\n        :param x: The input tensor, shape (batch_size, 3, 224, 224)\n        :return: The output tensor, shape (batch_size, num_classes)\n        \"\"\"\n        x = self.conv1(x)\n        x = self.relu1(x)\n        x = self.maxpool1(x)\n        \n        x = self.conv2(x)\n        x = self.relu2(x)\n        x = self.maxpool2(x)\n        \n        x = self.conv3(x)\n        x = self.relu3(x)\n        \n        x = self.conv4(x)\n        x = self.relu4(x)\n        \n        x = self.conv5(x)\n        x = self.relu5(x)\n        x = self.maxpool3(x)\n        \n        x = torch.flatten(x, 1)\n        \n        x = self.fc1(x)\n        x = self.relu6(x)\n        x = self.dropout1(x)\n        \n        x = self.fc2(x)\n        x = self.relu7(x)\n        x = self.dropout2(x)\n        \n        x = self.fc3(x)\n        \n        return x\n\n# Test code\nbatch_size = 1024\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.rand(batch_size, 3, 224, 224)]\n\ndef get_init_inputs():\n    return [num_classes]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    num_classes: int = 1000\n\n    @nn.compact\n    def __call__(self, x, *, train: bool = False):\n        # First convolutional layer\n        x = nn.Conv(features=96, kernel_size=(11, 11), strides=(4, 4), padding='SAME', use_bias=True)(x)\n        x = nn.relu(x)\n        x = nn.max_pool(x, window_shape=(3, 3), strides=(2, 2), padding='VALID')\n\n        # Second convolutional layer\n        x = nn.Conv(features=256, kernel_size=(5, 5), strides=(1, 1), padding='SAME', use_bias=True)(x)\n        x = nn.relu(x)\n        x = nn.max_pool(x, window_shape=(3, 3), strides=(2, 2), padding='VALID')\n\n        # Third convolutional layer\n        x = nn.Conv(features=384, kernel_size=(3, 3), strides=(1, 1), padding='SAME', use_bias=True)(x)\n        x = nn.relu(x)\n\n        # Fourth convolutional layer\n        x = nn.Conv(features=384, kernel_size=(3, 3), strides=(1, 1), padding='SAME', use_bias=True)(x)\n        x = nn.relu(x)\n\n        # Fifth convolutional layer\n        x = nn.Conv(features=256, kernel_size=(3, 3), strides=(1, 1), padding='SAME', use_bias=True)(x)\n        x = nn.relu(x)\n        x = nn.max_pool(x, window_shape=(3, 3), strides=(2, 2), padding='VALID')\n\n        # Flatten\n        x = x.reshape((x.shape[0], -1))\n\n        # Fully connected layers\n        x = nn.Dense(features=4096)(x)\n        x = nn.relu(x)\n        x = nn.Dropout(rate=0.0)(x, deterministic=not train)\n\n        x = nn.Dense(features=4096)(x)\n        x = nn.relu(x)\n        x = nn.Dropout(rate=0.0)(x, deterministic=not train)\n\n        x = nn.Dense(features=self.num_classes)(x)\n        return x\n\n# Test code\nbatch_size = 1024\nnum_classes = 1000\n\ndef get_inputs():\n    # JAX expects NHWC by default, but Flax Conv2D supports NCHW if input is NCHW.\n    # We'll keep NCHW to match PyTorch.\n    key = jax.random.PRNGKey(0)\n    x = jax.random.uniform(key, (batch_size, 3, 224, 224), dtype=jnp.float32)\n    return [x]\n\ndef get_init_inputs():\n    return [num_classes]"}
{"kb_id": "kb_level_3_0047", "level": "level_3", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.0017825311943, "success": true, "pytorch_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/pytorch_samples/kb_level_3_0047.py", "jax_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/jax_outputs/kb_level_3_0047_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass InceptionModule(nn.Module):\n    def __init__(self, in_channels, out_1x1, reduce_3x3, out_3x3, reduce_5x5, out_5x5, pool_proj):\n        \"\"\"\n        :param in_channels: Number of input channels\n        :param out_1x1: Number of output channels for the 1x1 convolution\n        :param reduce_3x3: Number of output channels for the 1x1 reduction before 3x3 convolution\n        :param out_3x3: Number of output channels for the 3x3 convolution\n        :param reduce_5x5: Number of output channels for the 1x1 reduction before 5x5 convolution\n        :param out_5x5: Number of output channels for the 5x5 convolution\n        :param pool_proj: Number of output channels for the pooling projection\n        \"\"\"\n        super(InceptionModule, self).__init__()\n        \n        # 1x1 convolution branch\n        self.branch1x1 = nn.Conv2d(in_channels, out_1x1, kernel_size=1)\n        \n        # 3x3 convolution branch\n        self.branch3x3 = nn.Sequential(\n            nn.Conv2d(in_channels, reduce_3x3, kernel_size=1),\n            nn.Conv2d(reduce_3x3, out_3x3, kernel_size=3, padding=1)\n        )\n        \n        # 5x5 convolution branch\n        self.branch5x5 = nn.Sequential(\n            nn.Conv2d(in_channels, reduce_5x5, kernel_size=1),\n            nn.Conv2d(reduce_5x5, out_5x5, kernel_size=5, padding=2)\n        )\n        \n        # Max pooling branch\n        self.branch_pool = nn.Sequential(\n            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n            nn.Conv2d(in_channels, pool_proj, kernel_size=1)\n        )\n    \n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor, shape (batch_size, in_channels, height, width)\n        :return: Output tensor, shape (batch_size, out_channels, height, width)\n        \"\"\"\n        branch1x1 = self.branch1x1(x)\n        branch3x3 = self.branch3x3(x)\n        branch5x5 = self.branch5x5(x)\n        branch_pool = self.branch_pool(x)\n        \n        outputs = [branch1x1, branch3x3, branch5x5, branch_pool]\n        return torch.cat(outputs, 1)\n\nclass Model(nn.Module):\n    def __init__(self, num_classes=1000):\n        \"\"\"\n        :param num_classes: Number of output classes\n        \"\"\"\n        super(Model, self).__init__()\n        \n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n        self.maxpool1 = nn.MaxPool2d(3, stride=2, padding=1)\n        self.conv2 = nn.Conv2d(64, 64, kernel_size=1)\n        self.conv3 = nn.Conv2d(64, 192, kernel_size=3, padding=1)\n        self.maxpool2 = nn.MaxPool2d(3, stride=2, padding=1)\n        \n        self.inception3a = InceptionModule(192, 64, 96, 128, 16, 32, 32)\n        self.inception3b = InceptionModule(256, 128, 128, 192, 32, 96, 64)\n        self.maxpool3 = nn.MaxPool2d(3, stride=2, padding=1)\n        \n        self.inception4a = InceptionModule(480, 192, 96, 208, 16, 48, 64)\n        self.inception4b = InceptionModule(512, 160, 112, 224, 24, 64, 64)\n        self.inception4c = InceptionModule(512, 128, 128, 256, 24, 64, 64)\n        self.inception4d = InceptionModule(512, 112, 144, 288, 32, 64, 64)\n        self.inception4e = InceptionModule(528, 256, 160, 320, 32, 128, 128)\n        self.maxpool4 = nn.MaxPool2d(3, stride=2, padding=1)\n        \n        self.inception5a = InceptionModule(832, 256, 160, 320, 32, 128, 128)\n        self.inception5b = InceptionModule(832, 384, 192, 384, 48, 128, 128)\n        \n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.dropout = nn.Dropout(0.0)\n        self.fc = nn.Linear(1024, num_classes)\n    \n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor, shape (batch_size, 3, height, width)\n        :return: Output tensor, shape (batch_size, num_classes)\n        \"\"\"\n        x = self.maxpool1(F.relu(self.conv1(x)))\n        x = F.relu(self.conv2(x))\n        x = self.maxpool2(F.relu(self.conv3(x)))\n        \n        x = self.inception3a(x)\n        x = self.inception3b(x)\n        x = self.maxpool3(x)\n        \n        x = self.inception4a(x)\n        x = self.inception4b(x)\n        x = self.inception4c(x)\n        x = self.inception4d(x)\n        x = self.inception4e(x)\n        x = self.maxpool4(x)\n        \n        x = self.inception5a(x)\n        x = self.inception5b(x)\n        \n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.dropout(x)\n        x = self.fc(x)\n        \n        return x\n\n# Test code\nbatch_size = 10\ninput_channels = 3\nheight = 224\nwidth = 224\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_channels, height, width)]\n\ndef get_init_inputs():\n    return [num_classes]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass InceptionModule(nn.Module):\n    in_channels: int\n    out_1x1: int\n    reduce_3x3: int\n    out_3x3: int\n    reduce_5x5: int\n    out_5x5: int\n    pool_proj: int\n\n    @nn.compact\n    def __call__(self, x):\n        # 1x1 convolution branch\n        branch1x1 = nn.Conv(self.out_1x1, kernel_size=(1,1))(x)\n\n        # 3x3 convolution branch\n        branch3x3 = nn.Conv(self.reduce_3x3, kernel_size=(1,1))(x)\n        branch3x3 = nn.Conv(self.out_3x3, kernel_size=(3,3), padding='SAME')(branch3x3)\n\n        # 5x5 convolution branch\n        branch5x5 = nn.Conv(self.reduce_5x5, kernel_size=(1,1))(x)\n        branch5x5 = nn.Conv(self.out_5x5, kernel_size=(5,5), padding='SAME')(branch5x5)\n\n        # Max pooling branch\n        branch_pool = nn.max_pool(x, window_shape=(3,3), strides=(1,1), padding='SAME')\n        branch_pool = nn.Conv(self.pool_proj, kernel_size=(1,1))(branch_pool)\n\n        outputs = [branch1x1, branch3x3, branch5x5, branch_pool]\n        return jnp.concatenate(outputs, axis=1)\n\nclass Model(nn.Module):\n    num_classes: int = 1000\n\n    @nn.compact\n    def __call__(self, x, train: bool = False):\n        x = nn.Conv(64, kernel_size=(7,7), strides=(2,2), padding='SAME')(x)\n        x = nn.relu(x)\n        x = nn.max_pool(x, window_shape=(3,3), strides=(2,2), padding='SAME')\n\n        x = nn.Conv(64, kernel_size=(1,1))(x)\n        x = nn.relu(x)\n        x = nn.Conv(192, kernel_size=(3,3), padding='SAME')(x)\n        x = nn.relu(x)\n        x = nn.max_pool(x, window_shape=(3,3), strides=(2,2), padding='SAME')\n\n        x = InceptionModule(192, 64, 96, 128, 16, 32, 32)(x)\n        x = InceptionModule(256, 128, 128, 192, 32, 96, 64)(x)\n        x = nn.max_pool(x, window_shape=(3,3), strides=(2,2), padding='SAME')\n\n        x = InceptionModule(480, 192, 96, 208, 16, 48, 64)(x)\n        x = InceptionModule(512, 160, 112, 224, 24, 64, 64)(x)\n        x = InceptionModule(512, 128, 128, 256, 24, 64, 64)(x)\n        x = InceptionModule(512, 112, 144, 288, 32, 64, 64)(x)\n        x = InceptionModule(528, 256, 160, 320, 32, 128, 128)(x)\n        x = nn.max_pool(x, window_shape=(3,3), strides=(2,2), padding='SAME')\n\n        x = InceptionModule(832, 256, 160, 320, 32, 128, 128)(x)\n        x = InceptionModule(832, 384, 192, 384, 48, 128, 128)(x)\n\n        # AdaptiveAvgPool2d((1,1)) equivalent: mean over H,W\n        x = jnp.mean(x, axis=(2,3), keepdims=True)\n        x = x.reshape((x.shape[0], -1))\n        x = nn.Dropout(0.0)(x, deterministic=not train)\n        x = nn.Dense(self.num_classes)(x)\n        return x\n\n# Test code\nbatch_size = 10\ninput_channels = 3\nheight = 224\nwidth = 224\nnum_classes = 1000\n\ndef get_inputs():\n    # JAX expects NHWC by default, but Flax Conv uses NCHW if axis=1 (default)\n    # So we keep NCHW for compatibility with the above model\n    key = jax.random.PRNGKey(0)\n    x = jax.random.uniform(key, (batch_size, input_channels, height, width))\n    return [x]\n\ndef get_init_inputs():\n    return [num_classes]"}
{"kb_id": "kb_level_3_0048", "level": "level_3", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.62230215827337, "success": true, "pytorch_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/pytorch_samples/kb_level_3_0048.py", "jax_path": "results/runs/2025-11-23-18h38_level_3_gpt41_strict_full_v2_n50/jax_outputs/kb_level_3_0048_jax.py", "pytorch_code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_channels, out_channels, stride=1):\n        \"\"\"\n        :param in_channels: Number of input channels\n        :param out_channels: Number of output channels\n        :param stride: Stride for the first convolutional layer\n        :param downsample: Downsample layer for the shortcut connection\n        \"\"\"\n        super(Model, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.downsample = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels * self.expansion, kernel_size=1, stride=stride, bias=False),\n            nn.BatchNorm2d(out_channels * self.expansion),\n        )\n        self.stride = stride\n\n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor, shape (batch_size, in_channels, height, width)\n        :return: Output tensor, shape (batch_size, out_channels, height, width)\n        \"\"\"\n        identity = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            identity = self.downsample(x)\n\n        out += identity\n        out = self.relu(out)\n\n        return out\n    \n# Test code\nin_channels = 3\nout_channels = 64\nstride = 1\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, 224, 224)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, stride]", "jax_code": "import jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\nclass Model(nn.Module):\n    in_channels: int\n    out_channels: int\n    stride: int = 1\n    expansion: int = 1\n\n    @nn.compact\n    def __call__(self, x):\n        # First conv-bn-relu\n        out = nn.Conv(\n            features=self.out_channels,\n            kernel_size=(3, 3),\n            strides=(self.stride, self.stride),\n            padding='SAME',\n            use_bias=False,\n            name='conv1'\n        )(x)\n        out = nn.BatchNorm(use_running_average=False, name='bn1')(out)\n        out = nn.relu(out)\n\n        # Second conv-bn\n        out = nn.Conv(\n            features=self.out_channels,\n            kernel_size=(3, 3),\n            strides=(1, 1),\n            padding='SAME',\n            use_bias=False,\n            name='conv2'\n        )(out)\n        out = nn.BatchNorm(use_running_average=False, name='bn2')(out)\n\n        # Downsample path\n        identity = x\n        identity = nn.Conv(\n            features=self.out_channels * self.expansion,\n            kernel_size=(1, 1),\n            strides=(self.stride, self.stride),\n            padding='SAME',\n            use_bias=False,\n            name='downsample_conv'\n        )(identity)\n        identity = nn.BatchNorm(use_running_average=False, name='downsample_bn')(identity)\n\n        out = out + identity\n        out = nn.relu(out)\n        return out\n\n# Test code\nin_channels = 3\nout_channels = 64\nstride = 1\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [jnp.random.rand(batch_size, in_channels, 224, 224).astype(jnp.float32)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, stride]"}
{"kb_id": "kb_level_4_0000", "level": "level_4", "prompt_tag": "gpt41_strict_full_v2", "aqs": 65.46709129511677, "success": true, "pytorch_path": "results/runs/2025-11-23-18h42_level_4_gpt41_strict_full_v2_n20/pytorch_samples/kb_level_4_0000.py", "jax_path": "results/runs/2025-11-23-18h42_level_4_gpt41_strict_full_v2_n20/jax_outputs/kb_level_4_0000_jax.py", "pytorch_code": "\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoConfig\n\nclass Model(torch.nn.Module):\n    def __init__(self, model_name, config):\n        super().__init__()\n        self.model_name = model_name\n        self.config = config\n        self.model = AutoModelForCausalLM.from_pretrained(self.model_name, config=self.config)\n\n    def forward(self, x):\n        return self.model(x).logits\n\nmodel_name = \"google/bigbird-roberta-base\"\nconfig = AutoConfig.from_pretrained(model_name)\nvocab_size = config.vocab_size\nsequence_length = 32\nbatch_size = 1024\n\ndef get_inputs():\n    inputs = torch.randint(0, vocab_size, (batch_size, sequence_length))\n    return [inputs]\n\ndef get_init_inputs():\n    return [model_name, config]", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    def __init__(self, model_name, config):\n        self.model_name = model_name\n        self.config = config\n        # Placeholder: In JAX/Flax, you would load or define your model here.\n        # For demonstration, we'll just store the config and model_name.\n\n    def __call__(self, x):\n        # Placeholder: Replace with actual model logic.\n        # For demonstration, return a fake logits tensor of shape (batch, seq, vocab)\n        batch_size, seq_len = x.shape\n        vocab_size = self.config.vocab_size\n        return jnp.zeros((batch_size, seq_len, vocab_size))\n\nclass Config:\n    def __init__(self, vocab_size):\n        self.vocab_size = vocab_size\n\nmodel_name = \"google/bigbird-roberta-base\"\n# Placeholder: In practice, load config from a file or dict.\nvocab_size = 50265  # Example vocab size; adjust as needed.\nconfig = Config(vocab_size)\nsequence_length = 32\nbatch_size = 1024\n\ndef get_inputs():\n    inputs = jax.random.randint(\n        jax.random.PRNGKey(0),\n        (batch_size, sequence_length),\n        minval=0,\n        maxval=vocab_size\n    )\n    return [inputs]\n\ndef get_init_inputs():\n    return [model_name, config]"}
{"kb_id": "kb_level_4_0001", "level": "level_4", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h42_level_4_gpt41_strict_full_v2_n20/pytorch_samples/kb_level_4_0001.py", "jax_path": "results/runs/2025-11-23-18h42_level_4_gpt41_strict_full_v2_n20/jax_outputs/kb_level_4_0001_jax.py", "pytorch_code": "\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoConfig\n\nclass Model(torch.nn.Module):\n    def __init__(self, model_name, config):\n        super().__init__()\n        self.model_name = model_name\n        self.config = config\n        self.model = AutoModelForCausalLM.from_pretrained(self.model_name, config=self.config)\n\n    def forward(self, x):\n        return self.model(x).logits\n\nmodel_name = \"google/electra-small-discriminator\"\nconfig = AutoConfig.from_pretrained(model_name)\nvocab_size = config.vocab_size\nsequence_length = 511\nbatch_size = 1\n\ndef get_inputs():\n    inputs = torch.randint(0, vocab_size, (batch_size, sequence_length))\n    return [inputs]\n\ndef get_init_inputs():\n    return [model_name, config]", "jax_code": "import jax\nimport jax.numpy as jnp\n\n# Placeholder for HuggingFace model integration in JAX.\n# In practice, you would use Flax models from transformers (e.g., FlaxAutoModelForCausalLM).\n# Here, we provide a dummy model for demonstration.\n\nclass DummyCausalLM:\n    def __init__(self, vocab_size):\n        self.vocab_size = vocab_size\n\n    def __call__(self, x):\n        # Simulate logits output: shape (batch, seq_len, vocab_size)\n        batch_size, seq_len = x.shape\n        logits = jnp.zeros((batch_size, seq_len, self.vocab_size))\n        return type('Output', (), {'logits': logits})\n\nclass Model:\n    def __init__(self, model_name, config):\n        self.model_name = model_name\n        self.config = config\n        self.model = DummyCausalLM(self.config.vocab_size)\n\n    def __call__(self, x):\n        return self.model(x).logits\n\n# Simulate HuggingFace config\nclass DummyConfig:\n    def __init__(self, vocab_size):\n        self.vocab_size = vocab_size\n\n# Simulate loading config\ndef load_config(model_name):\n    # For demonstration, set vocab_size to a typical value\n    return DummyConfig(vocab_size=30522)\n\nmodel_name = \"google/electra-small-discriminator\"\nconfig = load_config(model_name)\nvocab_size = config.vocab_size\nsequence_length = 511\nbatch_size = 1\n\ndef get_inputs():\n    # Random integer inputs in [0, vocab_size)\n    key = jax.random.PRNGKey(0)\n    inputs = jax.random.randint(key, (batch_size, sequence_length), 0, vocab_size)\n    return [inputs]\n\ndef get_init_inputs():\n    return [model_name, config]"}
{"kb_id": "kb_level_4_0002", "level": "level_4", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h42_level_4_gpt41_strict_full_v2_n20/pytorch_samples/kb_level_4_0002.py", "jax_path": "results/runs/2025-11-23-18h42_level_4_gpt41_strict_full_v2_n20/jax_outputs/kb_level_4_0002_jax.py", "pytorch_code": "\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoConfig\n\nclass Model(torch.nn.Module):\n    def __init__(self, model_name, config):\n        super().__init__()\n        self.model_name = model_name\n        self.config = config\n        self.model = AutoModelForCausalLM.from_pretrained(self.model_name, config=self.config)\n\n    def forward(self, x):\n        return self.model(x).logits\n\nmodel_name = \"google/electra-small-discriminator\"\nconfig = AutoConfig.from_pretrained(model_name)\nvocab_size = config.vocab_size\nsequence_length = 32\nbatch_size = 1024\n\ndef get_inputs():\n    inputs = torch.randint(0, vocab_size, (batch_size, sequence_length))\n    return [inputs]\n\ndef get_init_inputs():\n    return [model_name, config]", "jax_code": "import jax\nimport jax.numpy as jnp\n\nclass Model:\n    def __init__(self, model_name, config):\n        self.model_name = model_name\n        self.config = config\n        # Placeholder: In JAX/Flax, you would load or define your model here.\n        # For demonstration, we'll just store the config and model_name.\n        # Actual model loading (e.g., with HuggingFace Flax models) is omitted.\n\n    def __call__(self, x):\n        # Placeholder: Replace with actual model logic.\n        # For demonstration, we'll just return a dummy logits tensor.\n        # Shape: (batch_size, sequence_length, vocab_size)\n        batch_size, sequence_length = x.shape\n        vocab_size = self.config.vocab_size\n        return jnp.zeros((batch_size, sequence_length, vocab_size))\n\n# Dummy config class to mimic HuggingFace config\nclass DummyConfig:\n    def __init__(self, vocab_size):\n        self.vocab_size = vocab_size\n\nmodel_name = \"google/electra-small-discriminator\"\n# In real use, you would load the config from HuggingFace or similar.\n# Here, we just set vocab_size to a typical value for demonstration.\nvocab_size = 30522\nconfig = DummyConfig(vocab_size)\nsequence_length = 32\nbatch_size = 1024\n\ndef get_inputs():\n    inputs = jax.random.randint(\n        jax.random.PRNGKey(0),\n        (batch_size, sequence_length),\n        minval=0,\n        maxval=vocab_size\n    )\n    return [inputs]\n\ndef get_init_inputs():\n    return [model_name, config]"}
{"kb_id": "kb_level_4_0003", "level": "level_4", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h42_level_4_gpt41_strict_full_v2_n20/pytorch_samples/kb_level_4_0003.py", "jax_path": "results/runs/2025-11-23-18h42_level_4_gpt41_strict_full_v2_n20/jax_outputs/kb_level_4_0003_jax.py", "pytorch_code": "\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoConfig\n\nclass Model(torch.nn.Module):\n    def __init__(self, model_name, config):\n        super().__init__()\n        self.model_name = model_name\n        self.config = config\n        self.model = AutoModelForCausalLM.from_pretrained(self.model_name, config=self.config)\n\n    def forward(self, x):\n        return self.model(x).logits\n\nmodel_name = \"google/reformer-enwik8\"\nconfig = AutoConfig.from_pretrained(model_name)\nvocab_size = config.vocab_size\nsequence_length = 256\nbatch_size = 32\n\ndef get_inputs():\n    inputs = torch.randint(0, vocab_size, (batch_size, sequence_length))\n    return [inputs]\n\ndef get_init_inputs():\n    return [model_name, config]", "jax_code": "import jax\nimport jax.numpy as jnp\n\n# Placeholder for a Flax-compatible model.\n# In practice, you would use a Flax/transformers model here.\nclass Model:\n    def __init__(self, model_name, config):\n        self.model_name = model_name\n        self.config = config\n        # Placeholder: In real use, load a Flax model here.\n        self.vocab_size = config.vocab_size\n\n    def __call__(self, x):\n        # Placeholder: Replace with actual model logic.\n        # For demonstration, return random logits of shape (batch, seq, vocab)\n        batch_size, seq_len = x.shape\n        logits = jax.random.normal(jax.random.PRNGKey(0), (batch_size, seq_len, self.vocab_size))\n        return logits\n\n# Simulate HuggingFace config loading\nclass DummyConfig:\n    def __init__(self, vocab_size):\n        self.vocab_size = vocab_size\n\n# Simulate config loading\nmodel_name = \"google/reformer-enwik8\"\n# In real use, load config with transformers.FlaxAutoConfig.from_pretrained\nconfig = DummyConfig(vocab_size=258)  # Example vocab size; adjust as needed\nvocab_size = config.vocab_size\nsequence_length = 256\nbatch_size = 32\n\ndef get_inputs():\n    # JAX random integer generation\n    key = jax.random.PRNGKey(0)\n    inputs = jax.random.randint(key, (batch_size, sequence_length), 0, vocab_size)\n    return [inputs]\n\ndef get_init_inputs():\n    return [model_name, config]"}
{"kb_id": "kb_level_4_0004", "level": "level_4", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.92063492063491, "success": true, "pytorch_path": "results/runs/2025-11-23-18h42_level_4_gpt41_strict_full_v2_n20/pytorch_samples/kb_level_4_0004.py", "jax_path": "results/runs/2025-11-23-18h42_level_4_gpt41_strict_full_v2_n20/jax_outputs/kb_level_4_0004_jax.py", "pytorch_code": "\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoConfig\n\nclass Model(torch.nn.Module):\n    def __init__(self, model_name, config):\n        super().__init__()\n        self.model_name = model_name\n        self.config = config\n        self.model = AutoModelForCausalLM.from_pretrained(self.model_name, config=self.config)\n\n    def forward(self, x):\n        return self.model(x).logits\n\nmodel_name = \"google/electra-small-discriminator\"\nconfig = AutoConfig.from_pretrained(model_name)\nvocab_size = config.vocab_size\nsequence_length = 256\nbatch_size = 32\n\ndef get_inputs():\n    inputs = torch.randint(0, vocab_size, (batch_size, sequence_length))\n    return [inputs]\n\ndef get_init_inputs():\n    return [model_name, config]", "jax_code": "import jax\nimport jax.numpy as jnp\n\n# Placeholder for HuggingFace model loading in JAX/Flax.\n# In practice, you would use transformers.FlaxAutoModelForCausalLM, but here we mock the interface.\nclass DummyCausalLM:\n    def __init__(self, config):\n        self.config = config\n        self.vocab_size = getattr(config, \"vocab_size\", 30522)\n\n    def __call__(self, x):\n        # Simulate logits output: (batch, seq_len, vocab_size)\n        batch_size, seq_len = x.shape\n        logits = jnp.zeros((batch_size, seq_len, self.vocab_size))\n        class Output:\n            def __init__(self, logits):\n                self.logits = logits\n        return Output(logits)\n\nclass Model:\n    def __init__(self, model_name, config):\n        self.model_name = model_name\n        self.config = config\n        self.model = DummyCausalLM(config)\n\n    def __call__(self, x):\n        return self.model(x).logits\n\n# Simulate HuggingFace config\nclass DummyConfig:\n    def __init__(self, vocab_size=30522):\n        self.vocab_size = vocab_size\n\n# In real code, use: from transformers import AutoConfig\ndef load_config(model_name):\n    # Simulate config loading\n    return DummyConfig(vocab_size=30522)\n\nmodel_name = \"google/electra-small-discriminator\"\nconfig = load_config(model_name)\nvocab_size = config.vocab_size\nsequence_length = 256\nbatch_size = 32\n\ndef get_inputs():\n    inputs = jax.random.randint(\n        jax.random.PRNGKey(0), (batch_size, sequence_length), 0, vocab_size\n    )\n    return [inputs]\n\ndef get_init_inputs():\n    return [model_name, config]"}
{"kb_id": "kb_level_4_0005", "level": "level_4", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h42_level_4_gpt41_strict_full_v2_n20/pytorch_samples/kb_level_4_0005.py", "jax_path": "results/runs/2025-11-23-18h42_level_4_gpt41_strict_full_v2_n20/jax_outputs/kb_level_4_0005_jax.py", "pytorch_code": "\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoConfig\n\nclass Model(torch.nn.Module):\n    def __init__(self, model_name, config):\n        super().__init__()\n        self.model_name = model_name\n        self.config = config\n        self.model = AutoModelForCausalLM.from_pretrained(self.model_name, config=self.config)\n\n    def forward(self, x):\n        return self.model(x).logits\n\nmodel_name = \"google/reformer-enwik8\"\nconfig = AutoConfig.from_pretrained(model_name)\nvocab_size = config.vocab_size\nsequence_length = 32\nbatch_size = 1024\n\ndef get_inputs():\n    inputs = torch.randint(0, vocab_size, (batch_size, sequence_length))\n    return [inputs]\n\ndef get_init_inputs():\n    return [model_name, config]", "jax_code": "import jax\nimport jax.numpy as jnp\n\n# Placeholder for HuggingFace model loading in JAX/Flax.\n# In practice, you would use transformers.FlaxAutoModelForCausalLM, but here we mock the interface.\nclass DummyCausalLM:\n    def __init__(self, config):\n        self.config = config\n        self.vocab_size = config.vocab_size\n\n    def __call__(self, x):\n        # Simulate logits output: (batch, seq_len, vocab_size)\n        batch_size, seq_len = x.shape\n        logits = jnp.zeros((batch_size, seq_len, self.vocab_size))\n        class Output:\n            def __init__(self, logits):\n                self.logits = logits\n        return Output(logits)\n\nclass Model:\n    def __init__(self, model_name, config):\n        self.model_name = model_name\n        self.config = config\n        self.model = DummyCausalLM(config)\n\n    def __call__(self, x):\n        return self.model(x).logits\n\n# Simulate HuggingFace config\nclass DummyConfig:\n    def __init__(self, vocab_size):\n        self.vocab_size = vocab_size\n\n# Simulate loading config\nmodel_name = \"google/reformer-enwik8\"\nvocab_size = 258  # Example vocab size; adjust as needed\nconfig = DummyConfig(vocab_size)\nsequence_length = 32\nbatch_size = 1024\n\ndef get_inputs():\n    key = jax.random.PRNGKey(0)\n    inputs = jax.random.randint(key, (batch_size, sequence_length), 0, vocab_size)\n    return [inputs]\n\ndef get_init_inputs():\n    return [model_name, config]"}
{"kb_id": "kb_level_4_0006", "level": "level_4", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.29213483146067, "success": true, "pytorch_path": "results/runs/2025-11-23-18h42_level_4_gpt41_strict_full_v2_n20/pytorch_samples/kb_level_4_0006.py", "jax_path": "results/runs/2025-11-23-18h42_level_4_gpt41_strict_full_v2_n20/jax_outputs/kb_level_4_0006_jax.py", "pytorch_code": "\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoConfig\n\nclass Model(torch.nn.Module):\n    def __init__(self, model_name, config):\n        super().__init__()\n        self.model_name = model_name\n        self.config = config\n        self.model = AutoModelForCausalLM.from_pretrained(self.model_name, config=self.config)\n\n    def forward(self, x):\n        return self.model(x).logits\n\nmodel_name = \"gpt2\"\nconfig = AutoConfig.from_pretrained(model_name)\nvocab_size = config.vocab_size\nsequence_length = 1023\nbatch_size = 1\n\ndef get_inputs():\n    inputs = torch.randint(0, vocab_size, (batch_size, sequence_length))\n    return [inputs]\n\ndef get_init_inputs():\n    return [model_name, config]", "jax_code": "import jax\nimport jax.numpy as jnp\n\n# Placeholder for HuggingFace model loading in JAX.\n# In practice, you would use a Flax model from transformers, e.g., FlaxAutoModelForCausalLM.\n# Here, we provide a minimal stub to match the interface.\n\nclass DummyCausalLM:\n    def __init__(self, vocab_size):\n        self.vocab_size = vocab_size\n\n    def __call__(self, x):\n        # Simulate logits output: shape (batch, seq_len, vocab_size)\n        batch, seq_len = x.shape\n        logits = jnp.zeros((batch, seq_len, self.vocab_size))\n        class Output:\n            def __init__(self, logits):\n                self.logits = logits\n        return Output(logits)\n\nclass Model:\n    def __init__(self, model_name, config):\n        self.model_name = model_name\n        self.config = config\n        self.model = DummyCausalLM(self.config['vocab_size'])\n\n    def __call__(self, x):\n        return self.model(x).logits\n\nmodel_name = \"gpt2\"\n# Simulate config as a dict with vocab_size\nconfig = {'vocab_size': 50257}\nvocab_size = config['vocab_size']\nsequence_length = 1023\nbatch_size = 1\n\ndef get_inputs():\n    inputs = jax.random.randint(\n        jax.random.PRNGKey(0),\n        (batch_size, sequence_length),\n        minval=0,\n        maxval=vocab_size\n    )\n    return [inputs]\n\ndef get_init_inputs():\n    return [model_name, config]"}
{"kb_id": "kb_level_4_0007", "level": "level_4", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h42_level_4_gpt41_strict_full_v2_n20/pytorch_samples/kb_level_4_0007.py", "jax_path": "results/runs/2025-11-23-18h42_level_4_gpt41_strict_full_v2_n20/jax_outputs/kb_level_4_0007_jax.py", "pytorch_code": "\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoConfig\n\nclass Model(torch.nn.Module):\n    def __init__(self, model_name, config):\n        super().__init__()\n        self.model_name = model_name\n        self.config = config\n        self.model = AutoModelForCausalLM.from_pretrained(self.model_name, config=self.config)\n\n    def forward(self, x):\n        return self.model(x).logits\n\nmodel_name = \"facebook/bart-large\"\nconfig = AutoConfig.from_pretrained(model_name)\nvocab_size = config.vocab_size\nsequence_length = 32\nbatch_size = 1024\n\ndef get_inputs():\n    inputs = torch.randint(0, vocab_size, (batch_size, sequence_length))\n    return [inputs]\n\ndef get_init_inputs():\n    return [model_name, config]", "jax_code": "import jax\nimport jax.numpy as jnp\n\n# Placeholder for HuggingFace model loading in JAX/Flax.\n# In practice, you would use transformers.FlaxAutoModelForCausalLM, but here we use a stub.\nclass DummyCausalLM:\n    def __init__(self, config):\n        self.config = config\n        self.vocab_size = getattr(config, \"vocab_size\", 50265)\n\n    def __call__(self, x):\n        # Simulate logits output: (batch, seq_len, vocab_size)\n        batch_size, seq_len = x.shape\n        logits = jnp.zeros((batch_size, seq_len, self.vocab_size))\n        class Output:\n            def __init__(self, logits):\n                self.logits = logits\n        return Output(logits)\n\n# Dummy config to mimic HuggingFace config object\nclass DummyConfig:\n    def __init__(self, vocab_size):\n        self.vocab_size = vocab_size\n\ndef from_pretrained(model_name, config=None):\n    # In real code, use transformers.FlaxAutoModelForCausalLM.from_pretrained\n    return DummyCausalLM(config)\n\ndef config_from_pretrained(model_name):\n    # In real code, use transformers.AutoConfig.from_pretrained\n    return DummyConfig(vocab_size=50265)\n\nclass Model:\n    def __init__(self, model_name, config):\n        self.model_name = model_name\n        self.config = config\n        self.model = from_pretrained(self.model_name, config=self.config)\n\n    def __call__(self, x):\n        return self.model(x).logits\n\nmodel_name = \"facebook/bart-large\"\nconfig = config_from_pretrained(model_name)\nvocab_size = config.vocab_size\nsequence_length = 32\nbatch_size = 1024\n\ndef get_inputs():\n    inputs = jax.random.randint(jax.random.PRNGKey(0), (batch_size, sequence_length), 0, vocab_size)\n    return [inputs]\n\ndef get_init_inputs():\n    return [model_name, config]"}
{"kb_id": "kb_level_4_0008", "level": "level_4", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h42_level_4_gpt41_strict_full_v2_n20/pytorch_samples/kb_level_4_0008.py", "jax_path": "results/runs/2025-11-23-18h42_level_4_gpt41_strict_full_v2_n20/jax_outputs/kb_level_4_0008_jax.py", "pytorch_code": "\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoConfig\n\nclass Model(torch.nn.Module):\n    def __init__(self, model_name, config):\n        super().__init__()\n        self.model_name = model_name\n        self.config = config\n        self.model = AutoModelForCausalLM.from_pretrained(self.model_name, config=self.config)\n\n    def forward(self, x):\n        return self.model(x).logits\n\nmodel_name = \"EleutherAI/gpt-neo-2.7B\"\nconfig = AutoConfig.from_pretrained(model_name)\nvocab_size = config.vocab_size\nsequence_length = 32\nbatch_size = 512\n\ndef get_inputs():\n    inputs = torch.randint(0, vocab_size, (batch_size, sequence_length))\n    return [inputs]\n\ndef get_init_inputs():\n    return [model_name, config]", "jax_code": "import jax\nimport jax.numpy as jnp\n\n# Placeholder for a causal language model.\n# In practice, you would implement or import a Flax model here.\nclass Model:\n    def __init__(self, model_name, config):\n        self.model_name = model_name\n        self.config = config\n        # Placeholder: In real use, load or define your Flax model here.\n        self.vocab_size = config[\"vocab_size\"]\n        self.sequence_length = config.get(\"n_positions\", 32)\n        self.hidden_size = config.get(\"hidden_size\", 768)\n\n    def __call__(self, x):\n        # Dummy logits: [batch, seq, vocab_size]\n        batch_size, seq_len = x.shape\n        logits = jnp.zeros((batch_size, seq_len, self.vocab_size))\n        return logits\n\n# Dummy config mimicking HuggingFace's AutoConfig\ndef load_config(model_name):\n    # In practice, load from a file or define as needed.\n    return {\n        \"vocab_size\": 50257,\n        \"n_positions\": 32,\n        \"hidden_size\": 768,\n    }\n\nmodel_name = \"EleutherAI/gpt-neo-2.7B\"\nconfig = load_config(model_name)\nvocab_size = config[\"vocab_size\"]\nsequence_length = 32\nbatch_size = 512\n\ndef get_inputs():\n    key = jax.random.PRNGKey(0)\n    inputs = jax.random.randint(key, (batch_size, sequence_length), 0, vocab_size)\n    return [inputs]\n\ndef get_init_inputs():\n    return [model_name, config]"}
{"kb_id": "kb_level_4_0009", "level": "level_4", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h42_level_4_gpt41_strict_full_v2_n20/pytorch_samples/kb_level_4_0009.py", "jax_path": "results/runs/2025-11-23-18h42_level_4_gpt41_strict_full_v2_n20/jax_outputs/kb_level_4_0009_jax.py", "pytorch_code": "\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoConfig\n\nclass Model(torch.nn.Module):\n    def __init__(self, model_name, config):\n        super().__init__()\n        self.model_name = model_name\n        self.config = config\n        self.model = AutoModelForCausalLM.from_pretrained(self.model_name, config=self.config)\n\n    def forward(self, x):\n        return self.model(x).logits\n\nmodel_name = \"gpt2\"\nconfig = AutoConfig.from_pretrained(model_name)\nvocab_size = config.vocab_size\nsequence_length = 32\nbatch_size = 1024\n\ndef get_inputs():\n    inputs = torch.randint(0, vocab_size, (batch_size, sequence_length))\n    return [inputs]\n\ndef get_init_inputs():\n    return [model_name, config]", "jax_code": "import jax\nimport jax.numpy as jnp\n\n# Placeholder for a causal language model.\n# In practice, you would use a Flax model or a pre-trained model from HuggingFace's Flax library.\n# Here, we define a minimal stub to match the interface.\n\nclass Model:\n    def __init__(self, model_name, config):\n        self.model_name = model_name\n        self.config = config\n        # In a real scenario, load a Flax model here.\n        # For demonstration, we just store vocab_size.\n        self.vocab_size = config['vocab_size']\n\n    def __call__(self, x):\n        # Dummy logits: shape (batch, seq, vocab_size)\n        batch_size, seq_len = x.shape\n        # For demonstration, return zeros.\n        logits = jnp.zeros((batch_size, seq_len, self.vocab_size))\n        return logits\n\n# Dummy config mimicking HuggingFace's config object\ndef load_config(model_name):\n    # For demonstration, hardcode GPT-2's vocab size.\n    return {'vocab_size': 50257}\n\nmodel_name = \"gpt2\"\nconfig = load_config(model_name)\nvocab_size = config['vocab_size']\nsequence_length = 32\nbatch_size = 1024\n\ndef get_inputs():\n    key = jax.random.PRNGKey(0)\n    inputs = jax.random.randint(key, (batch_size, sequence_length), 0, vocab_size)\n    return [inputs]\n\ndef get_init_inputs():\n    return [model_name, config]"}
{"kb_id": "kb_level_4_0010", "level": "level_4", "prompt_tag": "gpt41_strict_full_v2", "aqs": 68.52222222222221, "success": true, "pytorch_path": "results/runs/2025-11-23-18h42_level_4_gpt41_strict_full_v2_n20/pytorch_samples/kb_level_4_0010.py", "jax_path": "results/runs/2025-11-23-18h42_level_4_gpt41_strict_full_v2_n20/jax_outputs/kb_level_4_0010_jax.py", "pytorch_code": "\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoConfig\n\nclass Model(torch.nn.Module):\n    def __init__(self, model_name, config):\n        super().__init__()\n        self.model_name = model_name\n        self.config = config\n        self.model = AutoModelForCausalLM.from_pretrained(self.model_name, config=self.config)\n\n    def forward(self, x):\n        return self.model(x).logits\n\nmodel_name = \"EleutherAI/gpt-neo-2.7B\"\nconfig = AutoConfig.from_pretrained(model_name)\nvocab_size = config.vocab_size\nsequence_length = 256\nbatch_size = 32\n\ndef get_inputs():\n    inputs = torch.randint(0, vocab_size, (batch_size, sequence_length))\n    return [inputs]\n\ndef get_init_inputs():\n    return [model_name, config]", "jax_code": "import jax\nimport jax.numpy as jnp\n\n# Placeholder for a causal LM model.\n# In practice, you would use a Flax/transformers model here.\nclass Model:\n    def __init__(self, model_name, config):\n        self.model_name = model_name\n        self.config = config\n        # Placeholder: In real use, load a Flax model here.\n        self.vocab_size = config['vocab_size']\n\n    def __call__(self, x):\n        # Dummy logits: shape (batch, seq, vocab_size)\n        batch_size, seq_len = x.shape\n        logits = jnp.zeros((batch_size, seq_len, self.vocab_size))\n        return logits\n\nmodel_name = \"EleutherAI/gpt-neo-2.7B\"\n# Simulate config as a dict for this example\nconfig = {'vocab_size': 50257}\nvocab_size = config['vocab_size']\nsequence_length = 256\nbatch_size = 32\n\ndef get_inputs():\n    inputs = jax.random.randint(\n        jax.random.PRNGKey(0),\n        (batch_size, sequence_length),\n        minval=0,\n        maxval=vocab_size\n    )\n    return [inputs]\n\ndef get_init_inputs():\n    return [model_name, config]"}
{"kb_id": "kb_level_4_0011", "level": "level_4", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.92063492063491, "success": true, "pytorch_path": "results/runs/2025-11-23-18h42_level_4_gpt41_strict_full_v2_n20/pytorch_samples/kb_level_4_0011.py", "jax_path": "results/runs/2025-11-23-18h42_level_4_gpt41_strict_full_v2_n20/jax_outputs/kb_level_4_0011_jax.py", "pytorch_code": "\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoConfig\n\nclass Model(torch.nn.Module):\n    def __init__(self, model_name, config):\n        super().__init__()\n        self.model_name = model_name\n        self.config = config\n        self.model = AutoModelForCausalLM.from_pretrained(self.model_name, config=self.config)\n\n    def forward(self, x):\n        return self.model(x).logits\n\nmodel_name = \"facebook/bart-large\"\nconfig = AutoConfig.from_pretrained(model_name)\nvocab_size = config.vocab_size\nsequence_length = 256\nbatch_size = 32\n\ndef get_inputs():\n    inputs = torch.randint(0, vocab_size, (batch_size, sequence_length))\n    return [inputs]\n\ndef get_init_inputs():\n    return [model_name, config]", "jax_code": "import jax\nimport jax.numpy as jnp\n\n# Placeholder for HuggingFace model loading in JAX/Flax.\n# In practice, you would use transformers.FlaxAutoModelForCausalLM, but here we mock the interface.\nclass DummyFlaxCausalLM:\n    def __init__(self, config):\n        self.config = config\n\n    def __call__(self, x):\n        # Simulate logits output: (batch, seq_len, vocab_size)\n        batch_size, seq_len = x.shape\n        vocab_size = self.config.vocab_size\n        logits = jnp.zeros((batch_size, seq_len, vocab_size))\n        class Output:\n            def __init__(self, logits):\n                self.logits = logits\n        return Output(logits)\n\n# Dummy config to mimic HuggingFace config\nclass DummyConfig:\n    def __init__(self, vocab_size):\n        self.vocab_size = vocab_size\n\n# Model definition\nclass Model:\n    def __init__(self, model_name, config):\n        self.model_name = model_name\n        self.config = config\n        self.model = DummyFlaxCausalLM(self.config)\n\n    def __call__(self, x):\n        return self.model(x).logits\n\nmodel_name = \"facebook/bart-large\"\nconfig = DummyConfig(vocab_size=50265)  # Example vocab size for BART\nvocab_size = config.vocab_size\nsequence_length = 256\nbatch_size = 32\n\ndef get_inputs():\n    inputs = jax.random.randint(\n        jax.random.PRNGKey(0),\n        (batch_size, sequence_length),\n        minval=0,\n        maxval=vocab_size\n    )\n    return [inputs]\n\ndef get_init_inputs():\n    return [model_name, config]"}
{"kb_id": "kb_level_4_0012", "level": "level_4", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h42_level_4_gpt41_strict_full_v2_n20/pytorch_samples/kb_level_4_0012.py", "jax_path": "results/runs/2025-11-23-18h42_level_4_gpt41_strict_full_v2_n20/jax_outputs/kb_level_4_0012_jax.py", "pytorch_code": "\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoConfig\n\nclass Model(torch.nn.Module):\n    def __init__(self, model_name, config):\n        super().__init__()\n        self.model_name = model_name\n        self.config = config\n        self.model = AutoModelForCausalLM.from_pretrained(self.model_name, config=self.config)\n\n    def forward(self, x):\n        return self.model(x).logits\n\nmodel_name = \"facebook/opt-1.3b\"\nconfig = AutoConfig.from_pretrained(model_name)\nvocab_size = config.vocab_size\nsequence_length = 2047\nbatch_size = 1\n\ndef get_inputs():\n    inputs = torch.randint(0, vocab_size, (batch_size, sequence_length))\n    return [inputs]\n\ndef get_init_inputs():\n    return [model_name, config]", "jax_code": "import jax\nimport jax.numpy as jnp\n\n# Placeholder for HuggingFace model loading in JAX.\n# In practice, you would use FlaxAutoModelForCausalLM from transformers.\n# Here, we define a dummy model for demonstration.\n\nclass DummyCausalLM:\n    def __init__(self, config):\n        self.config = config\n        self.vocab_size = config.vocab_size\n\n    def __call__(self, x):\n        # Simulate logits output: (batch, seq_len, vocab_size)\n        batch_size, seq_len = x.shape\n        logits = jnp.zeros((batch_size, seq_len, self.vocab_size))\n        class Output:\n            def __init__(self, logits):\n                self.logits = logits\n        return Output(logits)\n\nclass Model:\n    def __init__(self, model_name, config):\n        self.model_name = model_name\n        self.config = config\n        self.model = DummyCausalLM(self.config)\n\n    def __call__(self, x):\n        return self.model(x).logits\n\n# Simulate HuggingFace config\nclass DummyConfig:\n    def __init__(self, vocab_size):\n        self.vocab_size = vocab_size\n\n    @classmethod\n    def from_pretrained(cls, model_name):\n        # For demonstration, set vocab_size to a typical value\n        return cls(vocab_size=50272)\n\nmodel_name = \"facebook/opt-1.3b\"\nconfig = DummyConfig.from_pretrained(model_name)\nvocab_size = config.vocab_size\nsequence_length = 2047\nbatch_size = 1\n\ndef get_inputs():\n    inputs = jax.random.randint(\n        jax.random.PRNGKey(0),\n        (batch_size, sequence_length),\n        minval=0,\n        maxval=vocab_size\n    )\n    return [inputs]\n\ndef get_init_inputs():\n    return [model_name, config]"}
{"kb_id": "kb_level_4_0013", "level": "level_4", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h42_level_4_gpt41_strict_full_v2_n20/pytorch_samples/kb_level_4_0013.py", "jax_path": "results/runs/2025-11-23-18h42_level_4_gpt41_strict_full_v2_n20/jax_outputs/kb_level_4_0013_jax.py", "pytorch_code": "\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoConfig\n\nclass Model(torch.nn.Module):\n    def __init__(self, model_name, config):\n        super().__init__()\n        self.model_name = model_name\n        self.config = config\n        self.model = AutoModelForCausalLM.from_pretrained(self.model_name, config=self.config)\n\n    def forward(self, x):\n        return self.model(x).logits\n\nmodel_name = \"EleutherAI/gpt-neo-2.7B\"\nconfig = AutoConfig.from_pretrained(model_name)\nvocab_size = config.vocab_size\nsequence_length = 2047\nbatch_size = 1\n\ndef get_inputs():\n    inputs = torch.randint(0, vocab_size, (batch_size, sequence_length))\n    return [inputs]\n\ndef get_init_inputs():\n    return [model_name, config]", "jax_code": "import jax\nimport jax.numpy as jnp\n\n# Placeholder for HuggingFace model loading in JAX/Flax.\n# In practice, you would use transformers.FlaxAutoModelForCausalLM, but here we use a stub.\nclass DummyCausalLM:\n    def __init__(self, config):\n        self.config = config\n        self.vocab_size = config.vocab_size\n\n    def __call__(self, x):\n        # Simulate logits output: shape (batch, seq_len, vocab_size)\n        batch_size, seq_len = x.shape\n        logits = jnp.zeros((batch_size, seq_len, self.vocab_size))\n        class Output:\n            def __init__(self, logits):\n                self.logits = logits\n        return Output(logits)\n\nclass Model:\n    def __init__(self, model_name, config):\n        self.model_name = model_name\n        self.config = config\n        self.model = DummyCausalLM(self.config)\n\n    def __call__(self, x):\n        return self.model(x).logits\n\n# Simulate HuggingFace config\nclass DummyConfig:\n    def __init__(self, vocab_size):\n        self.vocab_size = vocab_size\n\n    @classmethod\n    def from_pretrained(cls, model_name):\n        # For demo, set vocab_size to a typical GPT-Neo value\n        return cls(vocab_size=50257)\n\nmodel_name = \"EleutherAI/gpt-neo-2.7B\"\nconfig = DummyConfig.from_pretrained(model_name)\nvocab_size = config.vocab_size\nsequence_length = 2047\nbatch_size = 1\n\ndef get_inputs():\n    # Random integer input in [0, vocab_size)\n    key = jax.random.PRNGKey(0)\n    inputs = jax.random.randint(key, (batch_size, sequence_length), 0, vocab_size)\n    return [inputs]\n\ndef get_init_inputs():\n    return [model_name, config]"}
{"kb_id": "kb_level_4_0014", "level": "level_4", "prompt_tag": "gpt41_strict_full_v2", "aqs": 68.828125, "success": true, "pytorch_path": "results/runs/2025-11-23-18h42_level_4_gpt41_strict_full_v2_n20/pytorch_samples/kb_level_4_0014.py", "jax_path": "results/runs/2025-11-23-18h42_level_4_gpt41_strict_full_v2_n20/jax_outputs/kb_level_4_0014_jax.py", "pytorch_code": "\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoConfig\n\nclass Model(torch.nn.Module):\n    def __init__(self, model_name, config):\n        super().__init__()\n        self.model_name = model_name\n        self.config = config\n        self.model = AutoModelForCausalLM.from_pretrained(self.model_name, config=self.config)\n\n    def forward(self, x):\n        return self.model(x).logits\n\nmodel_name = \"facebook/opt-1.3b\"\nconfig = AutoConfig.from_pretrained(model_name)\nvocab_size = config.vocab_size\nsequence_length = 256\nbatch_size = 32\n\ndef get_inputs():\n    inputs = torch.randint(0, vocab_size, (batch_size, sequence_length))\n    return [inputs]\n\ndef get_init_inputs():\n    return [model_name, config]", "jax_code": "import jax\nimport jax.numpy as jnp\n\n# Placeholder for a causal language model.\n# In practice, you would use a Flax model from HuggingFace or implement your own.\nclass Model:\n    def __init__(self, model_name, config):\n        self.model_name = model_name\n        self.config = config\n        # Placeholder: In real use, load a Flax model here.\n        self.vocab_size = config[\"vocab_size\"]\n        self.hidden_size = config.get(\"hidden_size\", 768)\n\n    def __call__(self, x):\n        # Dummy logits: [batch, seq, vocab_size]\n        batch_size, seq_len = x.shape\n        # For demonstration, just return zeros\n        logits = jnp.zeros((batch_size, seq_len, self.vocab_size))\n        return logits\n\n# Dummy config mimicking HuggingFace AutoConfig\ndef load_config(model_name):\n    # In real use, load from HuggingFace or your own config\n    return {\n        \"vocab_size\": 50272,\n        \"hidden_size\": 2048,\n    }\n\nmodel_name = \"facebook/opt-1.3b\"\nconfig = load_config(model_name)\nvocab_size = config[\"vocab_size\"]\nsequence_length = 256\nbatch_size = 32\n\ndef get_inputs():\n    key = jax.random.PRNGKey(0)\n    inputs = jax.random.randint(key, (batch_size, sequence_length), 0, vocab_size)\n    return [inputs]\n\ndef get_init_inputs():\n    return [model_name, config]"}
{"kb_id": "kb_level_4_0016", "level": "level_4", "prompt_tag": "gpt41_strict_full_v2", "aqs": 68.06843267108167, "success": true, "pytorch_path": "results/runs/2025-11-23-18h42_level_4_gpt41_strict_full_v2_n20/pytorch_samples/kb_level_4_0016.py", "jax_path": "results/runs/2025-11-23-18h42_level_4_gpt41_strict_full_v2_n20/jax_outputs/kb_level_4_0016_jax.py", "pytorch_code": "\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoConfig\n\nclass Model(torch.nn.Module):\n    def __init__(self, model_name, config):\n        super().__init__()\n        self.model_name = model_name\n        self.config = config\n        self.model = AutoModelForCausalLM.from_pretrained(self.model_name, config=self.config)\n\n    def forward(self, x):\n        return self.model(x).logits\n\nmodel_name = \"facebook/bart-large\"\nconfig = AutoConfig.from_pretrained(model_name)\nvocab_size = config.vocab_size\nsequence_length = 1023\nbatch_size = 1\n\ndef get_inputs():\n    inputs = torch.randint(0, vocab_size, (batch_size, sequence_length))\n    return [inputs]\n\ndef get_init_inputs():\n    return [model_name, config]", "jax_code": "import jax\nimport jax.numpy as jnp\n\n# Placeholder for a causal language model.\n# In practice, you would implement or import a Flax model here.\nclass Model:\n    def __init__(self, model_name, config):\n        self.model_name = model_name\n        self.config = config\n        # Placeholder: In real use, load or define your Flax model here.\n        self.vocab_size = config['vocab_size']\n\n    def __call__(self, x):\n        # Placeholder: Replace with actual model logic.\n        # For demonstration, return random logits of shape (batch, seq_len, vocab_size)\n        batch_size, seq_len = x.shape\n        key = jax.random.PRNGKey(0)\n        logits = jax.random.normal(key, (batch_size, seq_len, self.vocab_size))\n        return logits\n\n# Simulate HuggingFace config\ndef load_config(model_name):\n    # In practice, load config from file or define as needed.\n    # Here, we use a minimal dict for demonstration.\n    return {'vocab_size': 50265}\n\nmodel_name = \"facebook/bart-large\"\nconfig = load_config(model_name)\nvocab_size = config['vocab_size']\nsequence_length = 1023\nbatch_size = 1\n\ndef get_inputs():\n    key = jax.random.PRNGKey(42)\n    inputs = jax.random.randint(key, (batch_size, sequence_length), 0, vocab_size)\n    return [inputs]\n\ndef get_init_inputs():\n    return [model_name, config]"}
{"kb_id": "kb_level_4_0017", "level": "level_4", "prompt_tag": "gpt41_strict_full_v2", "aqs": 69.60496613995485, "success": true, "pytorch_path": "results/runs/2025-11-23-18h42_level_4_gpt41_strict_full_v2_n20/pytorch_samples/kb_level_4_0017.py", "jax_path": "results/runs/2025-11-23-18h42_level_4_gpt41_strict_full_v2_n20/jax_outputs/kb_level_4_0017_jax.py", "pytorch_code": "\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoConfig\n\nclass Model(torch.nn.Module):\n    def __init__(self, model_name, config):\n        super().__init__()\n        self.model_name = model_name\n        self.config = config\n        self.model = AutoModelForCausalLM.from_pretrained(self.model_name, config=self.config)\n\n    def forward(self, x):\n        return self.model(x).logits\n\nmodel_name = \"gpt2\"\nconfig = AutoConfig.from_pretrained(model_name)\nvocab_size = config.vocab_size\nsequence_length = 256\nbatch_size = 32\n\ndef get_inputs():\n    inputs = torch.randint(0, vocab_size, (batch_size, sequence_length))\n    return [inputs]\n\ndef get_init_inputs():\n    return [model_name, config]", "jax_code": "import jax\nimport jax.numpy as jnp\n\n# Placeholder for a causal language model.\n# In practice, you would use a Flax model or implement your own.\nclass DummyCausalLM:\n    def __init__(self, vocab_size):\n        self.vocab_size = vocab_size\n\n    def __call__(self, x):\n        # Simulate logits output: (batch, seq_len, vocab_size)\n        batch_size, seq_len = x.shape\n        # For demonstration, return zeros\n        logits = jnp.zeros((batch_size, seq_len, self.vocab_size))\n        return type('Output', (), {'logits': logits})()\n\nclass Model:\n    def __init__(self, model_name, config):\n        self.model_name = model_name\n        self.config = config\n        self.model = DummyCausalLM(self.config['vocab_size'])\n\n    def __call__(self, x):\n        return self.model(x).logits\n\nmodel_name = \"gpt2\"\n# Simulate config as a dict\nconfig = {\n    'vocab_size': 50257  # GPT-2 default vocab size\n}\nvocab_size = config['vocab_size']\nsequence_length = 256\nbatch_size = 32\n\ndef get_inputs():\n    # Random integer inputs in [0, vocab_size)\n    key = jax.random.PRNGKey(0)\n    inputs = jax.random.randint(key, (batch_size, sequence_length), 0, vocab_size)\n    return [inputs]\n\ndef get_init_inputs():\n    return [model_name, config]"}
{"kb_id": "kb_level_4_0018", "level": "level_4", "prompt_tag": "gpt41_strict_full_v2", "aqs": 70.0, "success": true, "pytorch_path": "results/runs/2025-11-23-18h42_level_4_gpt41_strict_full_v2_n20/pytorch_samples/kb_level_4_0018.py", "jax_path": "results/runs/2025-11-23-18h42_level_4_gpt41_strict_full_v2_n20/jax_outputs/kb_level_4_0018_jax.py", "pytorch_code": "\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoConfig\n\nclass Model(torch.nn.Module):\n    def __init__(self, model_name, config):\n        super().__init__()\n        self.model_name = model_name\n        self.config = config\n        self.model = AutoModelForCausalLM.from_pretrained(self.model_name, config=self.config)\n\n    def forward(self, x):\n        return self.model(x).logits\n\nmodel_name = \"facebook/opt-1.3b\"\nconfig = AutoConfig.from_pretrained(model_name)\nvocab_size = config.vocab_size\nsequence_length = 32\nbatch_size = 512\n\ndef get_inputs():\n    inputs = torch.randint(0, vocab_size, (batch_size, sequence_length))\n    return [inputs]\n\ndef get_init_inputs():\n    return [model_name, config]", "jax_code": "import jax\nimport jax.numpy as jnp\n\n# Placeholder for a causal language model.\n# In practice, you would implement or import a Flax/JAX model here.\nclass Model:\n    def __init__(self, model_name, config):\n        self.model_name = model_name\n        self.config = config\n        # Placeholder: In real use, load or define your Flax model here.\n        self.vocab_size = config['vocab_size']\n        self.sequence_length = config.get('sequence_length', 32)\n\n    def __call__(self, x):\n        # Placeholder: Simulate logits output with random values.\n        # Shape: (batch_size, sequence_length, vocab_size)\n        batch_size, sequence_length = x.shape\n        logits = jnp.zeros((batch_size, sequence_length, self.vocab_size))\n        return logits\n\n# Simulate config loading (since transformers is not used in JAX/Flax).\nmodel_name = \"facebook/opt-1.3b\"\nconfig = {\n    'vocab_size': 50272,  # Example vocab size for OPT-1.3b\n    'sequence_length': 32\n}\nvocab_size = config['vocab_size']\nsequence_length = 32\nbatch_size = 512\n\ndef get_inputs():\n    # Random integer inputs in [0, vocab_size)\n    key = jax.random.PRNGKey(0)\n    inputs = jax.random.randint(key, (batch_size, sequence_length), 0, vocab_size)\n    return [inputs]\n\ndef get_init_inputs():\n    return [model_name, config]"}
